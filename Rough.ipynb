{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.path_utils import project_root\n",
    "from utils.loader import initialize_experiment, make_loader, get_train_test_indicies, DatasetWithPadding\n",
    "\n",
    "import os\n",
    "\n",
    "from train_gtn import load_model, GatedTransformerNetwork, train_model\n",
    "from utils.config import gtn_param\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting train and test indicies\n",
    "# train_indicies, test_indicies = get_train_test_indicies()\n",
    "\n",
    "# # training_examples, lengths_list, is_sepsis \n",
    "# training_examples, lengths_list, is_sepsis = initialize_experiment()\n",
    "\n",
    "# # Train and test samples\n",
    "# train_samples = [training_examples[idx] for idx in train_indicies]\n",
    "# test_samples = [training_examples[idx] for idx in test_indicies]\n",
    "\n",
    "# train_lengths_list = [lengths_list[idx] for idx in train_indicies]\n",
    "# test_lengths_list = [lengths_list[idx] for idx in test_indicies]\n",
    "\n",
    "# is_sepsis_train = [is_sepsis[idx] for idx in train_indicies]\n",
    "# is_sepsis_test = [is_sepsis[idx] for idx in test_indicies]\n",
    "\n",
    "# # Converting data to train and test sets\n",
    "# train_dataset = DatasetWithPadding(training_examples_list=train_samples, lengths_list=train_lengths_list, is_sepsis=is_sepsis_train)\n",
    "# test_dataset = DatasetWithPadding(training_examples_list=test_samples, lengths_list=test_lengths_list, is_sepsis=is_sepsis_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collate Fn\n",
    "# def collate_fn(batch):\n",
    "    \n",
    "#     # Sequeneces and Lengths\n",
    "#     sequences, labels = zip(*batch)\n",
    "#     lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "\n",
    "#     # Padding\n",
    "#     sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    \n",
    "#     # Creating masks\n",
    "#     masks = torch.zeros(sequences_padded.size(0), sequences_padded.size(1), dtype=torch.bool)\n",
    "#     for i, length in enumerate(lengths):\n",
    "#         masks[i, :length] = 1\n",
    "\n",
    "#     return sequences_padded, masks, torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "# # Loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True, num_workers=10, collate_fn=collate_fn)\n",
    "\n",
    "# for inputs, masks, targets in train_loader:\n",
    "#     print(inputs.shape, masks.shape, targets.shape)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset used: final_dataset.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding...: 100%|██████████| 32268/32268 [01:29<00:00, 359.08it/s]\n",
      "Padding...: 100%|██████████| 8067/8067 [00:22<00:00, 365.15it/s]\n"
     ]
    }
   ],
   "source": [
    "training_examples, lengths_list, is_sepsis = initialize_experiment()\n",
    "train_loader, test_loader, train_indicies, test_indicies = make_loader(training_examples, lengths_list, is_sepsis, batch_size=3, mode=\"padding_masking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 336, 63]) torch.Size([3]) torch.Size([3, 336, 63])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels, masks in train_loader:\n",
    "    print(inputs.shape, labels.shape, masks.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 85.0000,  97.0000,  37.7800,  ...,  18.0000,   0.0000,   0.0000],\n",
      "        [100.0000,  97.0000,  37.7800,  ...,  18.0000,   0.0000,   0.0000],\n",
      "        [105.0000,  97.0000,  37.7800,  ...,  18.0000,   0.0000,   0.0000],\n",
      "        ...,\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
      "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.9083e-01, 8.2371e-01, 4.6799e-01,  ..., 3.5503e-01, 6.4325e-02,\n",
       "         3.8016e-01],\n",
       "        [9.6057e-01, 7.7230e-04, 6.2426e-01,  ..., 4.2475e-02, 2.4482e-01,\n",
       "         4.5093e-01],\n",
       "        [9.4241e-01, 9.0948e-01, 3.5272e-01,  ..., 6.2881e-01, 4.0796e-01,\n",
       "         1.5484e-01],\n",
       "        ...,\n",
       "        [      -inf,       -inf,       -inf,  ...,       -inf,       -inf,\n",
       "               -inf],\n",
       "        [      -inf,       -inf,       -inf,  ...,       -inf,       -inf,\n",
       "               -inf],\n",
       "        [      -inf,       -inf,       -inf,  ...,       -inf,       -inf,\n",
       "               -inf]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = torch.rand(336, 63)\n",
    "score.masked_fill(~masks[0], float('-inf'))  # New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(CPUBoolType{[3, 1, 336, 63]}, size=[3, 336, 336]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m masks\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand(\u001b[39m3\u001b[39m, \u001b[39m336\u001b[39m, \u001b[39m336\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(CPUBoolType{[3, 1, 336, 63]}, size=[3, 336, 336]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "masks.unsqueeze(1).expand(3, 336, 336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from utils.evaluate_helper_methods import *\n",
    "from utils.path_utils import project_root\n",
    "from utils.evaluate_sepsis_score import evaluate_sepsis_score\n",
    "from utils.get_true_labels import get_true_labels\n",
    "\n",
    "from utils.helpers import get_features\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def get_sepsis_score(data, model):\n",
    "    columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp',\n",
    "               'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST',\n",
    "               'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "               'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate',\n",
    "               'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "               'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
    "               'HospAdmTime', 'ICULOS']\n",
    "\n",
    "    # Reformatting data into DataFrame to add features\n",
    "    patient_data = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Handling Missing values\n",
    "    # patient_data[vital_signs] = patient_data[vital_signs].rolling(window=6, min_periods=1).mean().bfill()\n",
    "    patient_data = patient_data.bfill()\n",
    "    patient_data = patient_data.ffill()\n",
    "    patient_data = patient_data.fillna(0)\n",
    "\n",
    "    # patient_data['MAP_SOFA'] = patient_data['MAP'].apply(map_sofa)\n",
    "    patient_data['MAP_SOFA'] = map_sofa(patient_data['MAP'])\n",
    "    patient_data['Bilirubin_total_SOFA'] = patient_data['Bilirubin_total'].apply(total_bilirubin_sofa)\n",
    "    patient_data['Platelets_SOFA'] = patient_data['Platelets'].apply(platelets_sofa)\n",
    "    patient_data['SOFA_score'] = patient_data.apply(sofa_score, axis=1)\n",
    "    patient_data = detect_sofa_change(patient_data)\n",
    "\n",
    "    patient_data['ResP_qSOFA'] = patient_data['Resp'].apply(respiratory_rate_qsofa)\n",
    "    patient_data['SBP_qSOFA'] = patient_data['SBP'].apply(sbp_qsofa)\n",
    "    patient_data['qSOFA_score'] = patient_data.apply(qsofa_score, axis=1)\n",
    "    patient_data = detect_qsofa_change(patient_data)\n",
    "\n",
    "    patient_data['qSOFA_indicator'] = patient_data.apply(q_sofa_indicator, axis=1)  # Sepsis detected\n",
    "    patient_data['SOFA_indicator'] = patient_data.apply(sofa_indicator, axis=1)  # Organ Dysfunction occurred\n",
    "    patient_data['Mortality_sofa'] = patient_data.apply(mortality_sofa, axis=1)  # Morality rate\n",
    "\n",
    "    patient_data['Temp_sirs'] = patient_data['Temp'].apply(temp_sirs)\n",
    "    patient_data['HR_sirs'] = patient_data['HR'].apply(heart_rate_sirs)\n",
    "    patient_data['Resp_sirs'] = patient_data['Resp'].apply(resp_sirs)\n",
    "    patient_data['paco2_sirs'] = patient_data['PaCO2'].apply(resp_sirs)\n",
    "    patient_data['wbc_sirs'] = patient_data['WBC'].apply(wbc_sirs)\n",
    "\n",
    "    # patient_data = t_suspicion(patient_data)\n",
    "    # patient_data = t_sofa(patient_data)\n",
    "    # patient_data['t_sepsis'] = patient_data.apply(t_sepsis, axis=1)\n",
    "\n",
    "    # patient_data = patient_data[final_features]\n",
    "\n",
    "    max_rows = 8\n",
    "    num_features = patient_data.shape[1]\n",
    "    if len(patient_data) < max_rows:\n",
    "        padding = np.zeros((max_rows - len(patient_data), num_features))\n",
    "        patient_data = np.vstack((patient_data.values, padding)).astype(np.float32)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # If patient data is > window_size ?\n",
    "        segments = []\n",
    "        max_rows = 8\n",
    "\n",
    "        for start in range(0, len(patient_data) - max_rows + 1):\n",
    "            segment = patient_data.iloc[start: start + max_rows].values\n",
    "            segments.append(segment.astype(np.float32))\n",
    "\n",
    "        # Making predictions for every segment\n",
    "        segment_predictions = []\n",
    "        segment_probs = []\n",
    "        for segment in segments:\n",
    "            segment = torch.from_numpy(segment).unsqueeze(0)\n",
    "\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                segment = segment.to(torch.float32).to(device)\n",
    "                outputs, _, _, _, _, _, _ = model(segment, stage='test')\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "            predicted_class = predicted.detach().cpu().numpy()[0]\n",
    "            probabilities = probabilities.detach().cpu().numpy()[0][predicted_class]\n",
    "\n",
    "            segment_predictions.append(predicted_class)\n",
    "            segment_probs.append(probabilities)\n",
    "        \n",
    "        print(np.mean(segment_predictions), segment_probs)\n",
    "        predictions = [torch.tensor(segment_predictions).mode()[0].detach().cpu().numpy().item()]\n",
    "        probas = [torch.tensor(segment_probs).mean().detach().cpu().numpy().item()]\n",
    "        \n",
    "        return predictions, probas, patient_data\n",
    "\n",
    "    # This code executes when patient_data is within the window_size\n",
    "    patient_data = torch.from_numpy(patient_data).unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    probas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        patient_data = patient_data.to(torch.float32).to(device)\n",
    "        outputs, _, _, _, _, _, _ = model(patient_data, stage='test')\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "        predicted_class = predicted.detach().cpu().numpy()[0]\n",
    "\n",
    "        predictions.append(predicted_class)\n",
    "        probas.append(probabilities.detach().cpu().numpy()[0][predicted_class])\n",
    "\n",
    "    return predictions, probas, patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/localscratch/neeresh/data/physionet2019/physionet.org/files/challenge-2019/1.0.0/training/training_setA/p000034.psv', sep='|')\n",
    "sample = sample.drop(['SepsisLabel'], axis=1).values\n",
    "\n",
    "num_rows = len(sample)  # Number of patient recordings\n",
    "scores = np.zeros(num_rows)\n",
    "labels = np.zeros(num_rows)\n",
    "\n",
    "for t in range(num_rows):\n",
    "    current_data = sample[:t + 1]\n",
    "    current_labels, current_score, data_df = get_sepsis_score(current_data, model)\n",
    "    scores[t] = current_score[0]\n",
    "    labels[t] = current_labels[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores), len(labels), sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
