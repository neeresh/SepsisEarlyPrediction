{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.path_utils import project_root\n",
    "from utils.loader import initialize_experiment, make_loader, get_train_test_indicies, DatasetWithPadding\n",
    "\n",
    "import os\n",
    "\n",
    "from train_gtn import load_model, GatedTransformerNetwork, train_model\n",
    "from utils.config import gtn_param\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = os.path.join(os.path.join(project_root(), 'data', 'processed', 'test_final_dataset.pickle'))\n",
    "all_data = pd.read_pickle(training_examples)\n",
    "data = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1552210, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
       "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
       "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
       "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
       "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
       "       'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
       "       'HospAdmTime', 'ICULOS', 'SepsisLabel', 'PatientID', 'MAP_SOFA',\n",
       "       'Bilirubin_total_SOFA', 'Platelets_SOFA', 'SOFA_score',\n",
       "       'SOFA_score_diff', 'SOFA_deterioration', 'ResP_qSOFA', 'SBP_qSOFA',\n",
       "       'qSOFA_score', 'qSOFA_score_diff', 'qSOFA_deterioration',\n",
       "       'qSOFA_indicator', 'SOFA_indicator', 'Mortality_sofa', 'Temp_sirs',\n",
       "       'HR_sirs', 'Resp_sirs', 'paco2_sirs', 'wbc_sirs', 'infection_proxy',\n",
       "       't_suspicion', 't_sofa', 't_sepsis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>BaseExcess</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Fibrinogen</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.0</td>\n",
       "      <td>91.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HR  O2Sat  Temp    SBP    MAP  DBP  Resp  EtCO2  BaseExcess  HCO3  ...  \\\n",
       "0    NaN    NaN   NaN    NaN    NaN  NaN   NaN    NaN         NaN   NaN  ...   \n",
       "1   97.0   95.0   NaN   98.0  75.33  NaN  19.0    NaN         NaN   NaN  ...   \n",
       "2   89.0   99.0   NaN  122.0  86.00  NaN  22.0    NaN         NaN   NaN  ...   \n",
       "3   90.0   95.0   NaN    NaN    NaN  NaN  30.0    NaN        24.0   NaN  ...   \n",
       "4  103.0   88.5   NaN  122.0  91.33  NaN  24.5    NaN         NaN   NaN  ...   \n",
       "\n",
       "   WBC  Fibrinogen  Platelets    Age  Gender  Unit1  Unit2  HospAdmTime  \\\n",
       "0  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "1  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "2  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "3  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "4  NaN         NaN        NaN  83.14       0    NaN    NaN        -0.03   \n",
       "\n",
       "   ICULOS  SepsisLabel  \n",
       "0       1            0  \n",
       "1       2            0  \n",
       "2       3            0  \n",
       "3       4            0  \n",
       "4       5            0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = pd.read_csv(os.path.join(project_root(), 'physionet.org', 'files', 'challenge-2019', '1.0.0', 'training', 'training_setA', 'p000001.psv'), sep='|')\n",
    "print(sample_data.shape)\n",
    "\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (40336,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(all_data)\n",
      "File \u001b[0;32m/localscratch/neeresh/envs/timeseries/lib/python3.11/site-packages/pandas/core/frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    859\u001b[0m         mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m             arrays,\n\u001b[1;32m    861\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 867\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    868\u001b[0m             data,\n\u001b[1;32m    869\u001b[0m             index,\n\u001b[1;32m    870\u001b[0m             columns,\n\u001b[1;32m    871\u001b[0m             dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    872\u001b[0m             copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m    873\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    874\u001b[0m         )\n\u001b[1;32m    875\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    876\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    877\u001b[0m         {},\n\u001b[1;32m    878\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    882\u001b[0m     )\n",
      "File \u001b[0;32m/localscratch/neeresh/envs/timeseries/lib/python3.11/site-packages/pandas/core/internals/construction.py:319\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    314\u001b[0m     values \u001b[39m=\u001b[39m _ensure_2d(values)\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarraylike(values, copy\u001b[39m=\u001b[39mcopy_on_sanitize)\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m values\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m dtype:\n\u001b[1;32m    322\u001b[0m     \u001b[39m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     values \u001b[39m=\u001b[39m sanitize_array(\n\u001b[1;32m    324\u001b[0m         values,\n\u001b[1;32m    325\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m         allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m     )\n",
      "File \u001b[0;32m/localscratch/neeresh/envs/timeseries/lib/python3.11/site-packages/pandas/core/internals/construction.py:575\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39m# we could have a 1-dim or 2-dim list here\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39m# this is equiv of np.asarray, but does object conversion\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[39m# and platform dtype preservation\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39m# does not convert e.g. [1, \"a\", True] to [\"1\", \"a\", \"True\"] like\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39m#  np.asarray would\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(values[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 575\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([convert(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n\u001b[1;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(values[\u001b[39m0\u001b[39m], np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m values[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    577\u001b[0m     \u001b[39m# GH#21861 see test_constructor_list_of_lists\u001b[39;00m\n\u001b[1;32m    578\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([convert(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values])\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (40336,) + inhomogeneous part."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting train and test indicies\n",
    "# train_indicies, test_indicies = get_train_test_indicies()\n",
    "\n",
    "# # training_examples, lengths_list, is_sepsis \n",
    "# training_examples, lengths_list, is_sepsis = initialize_experiment()\n",
    "\n",
    "# # Train and test samples\n",
    "# train_samples = [training_examples[idx] for idx in train_indicies]\n",
    "# test_samples = [training_examples[idx] for idx in test_indicies]\n",
    "\n",
    "# train_lengths_list = [lengths_list[idx] for idx in train_indicies]\n",
    "# test_lengths_list = [lengths_list[idx] for idx in test_indicies]\n",
    "\n",
    "# is_sepsis_train = [is_sepsis[idx] for idx in train_indicies]\n",
    "# is_sepsis_test = [is_sepsis[idx] for idx in test_indicies]\n",
    "\n",
    "# # Converting data to train and test sets\n",
    "# train_dataset = DatasetWithPadding(training_examples_list=train_samples, lengths_list=train_lengths_list, is_sepsis=is_sepsis_train)\n",
    "# test_dataset = DatasetWithPadding(training_examples_list=test_samples, lengths_list=test_lengths_list, is_sepsis=is_sepsis_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collate Fn\n",
    "# def collate_fn(batch):\n",
    "    \n",
    "#     # Sequeneces and Lengths\n",
    "#     sequences, labels = zip(*batch)\n",
    "#     lengths = torch.tensor([len(seq) for seq in sequences])\n",
    "\n",
    "#     # Padding\n",
    "#     sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "    \n",
    "#     # Creating masks\n",
    "#     masks = torch.zeros(sequences_padded.size(0), sequences_padded.size(1), dtype=torch.bool)\n",
    "#     for i, length in enumerate(lengths):\n",
    "#         masks[i, :length] = 1\n",
    "\n",
    "#     return sequences_padded, masks, torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "\n",
    "# # Loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True, num_workers=10, collate_fn=collate_fn)\n",
    "\n",
    "# for inputs, masks, targets in train_loader:\n",
    "#     print(inputs.shape, masks.shape, targets.shape)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples, lengths_list, is_sepsis = initialize_experiment()\n",
    "train_loader, test_loader, train_indicies, test_indicies = make_loader(training_examples, lengths_list, is_sepsis, batch_size=3, mode=\"padding_masking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels, masks in train_loader:\n",
    "    print(inputs.shape, labels.shape, masks.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.rand(336, 63)\n",
    "score.masked_fill(~masks[0], float('-inf'))  # New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.unsqueeze(1).expand(3, 336, 336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from utils.evaluate_helper_methods import *\n",
    "from utils.path_utils import project_root\n",
    "from utils.evaluate_sepsis_score import evaluate_sepsis_score\n",
    "from utils.get_true_labels import get_true_labels\n",
    "\n",
    "from utils.helpers import get_features\n",
    "\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def get_sepsis_score(data, model):\n",
    "    columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp',\n",
    "               'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST',\n",
    "               'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "               'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate',\n",
    "               'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "               'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
    "               'HospAdmTime', 'ICULOS']\n",
    "\n",
    "    # Reformatting data into DataFrame to add features\n",
    "    patient_data = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Handling Missing values\n",
    "    # patient_data[vital_signs] = patient_data[vital_signs].rolling(window=6, min_periods=1).mean().bfill()\n",
    "    patient_data = patient_data.bfill()\n",
    "    patient_data = patient_data.ffill()\n",
    "    patient_data = patient_data.fillna(0)\n",
    "\n",
    "    # patient_data['MAP_SOFA'] = patient_data['MAP'].apply(map_sofa)\n",
    "    patient_data['MAP_SOFA'] = map_sofa(patient_data['MAP'])\n",
    "    patient_data['Bilirubin_total_SOFA'] = patient_data['Bilirubin_total'].apply(total_bilirubin_sofa)\n",
    "    patient_data['Platelets_SOFA'] = patient_data['Platelets'].apply(platelets_sofa)\n",
    "    patient_data['SOFA_score'] = patient_data.apply(sofa_score, axis=1)\n",
    "    patient_data = detect_sofa_change(patient_data)\n",
    "\n",
    "    patient_data['ResP_qSOFA'] = patient_data['Resp'].apply(respiratory_rate_qsofa)\n",
    "    patient_data['SBP_qSOFA'] = patient_data['SBP'].apply(sbp_qsofa)\n",
    "    patient_data['qSOFA_score'] = patient_data.apply(qsofa_score, axis=1)\n",
    "    patient_data = detect_qsofa_change(patient_data)\n",
    "\n",
    "    patient_data['qSOFA_indicator'] = patient_data.apply(q_sofa_indicator, axis=1)  # Sepsis detected\n",
    "    patient_data['SOFA_indicator'] = patient_data.apply(sofa_indicator, axis=1)  # Organ Dysfunction occurred\n",
    "    patient_data['Mortality_sofa'] = patient_data.apply(mortality_sofa, axis=1)  # Morality rate\n",
    "\n",
    "    patient_data['Temp_sirs'] = patient_data['Temp'].apply(temp_sirs)\n",
    "    patient_data['HR_sirs'] = patient_data['HR'].apply(heart_rate_sirs)\n",
    "    patient_data['Resp_sirs'] = patient_data['Resp'].apply(resp_sirs)\n",
    "    patient_data['paco2_sirs'] = patient_data['PaCO2'].apply(resp_sirs)\n",
    "    patient_data['wbc_sirs'] = patient_data['WBC'].apply(wbc_sirs)\n",
    "\n",
    "    # patient_data = t_suspicion(patient_data)\n",
    "    # patient_data = t_sofa(patient_data)\n",
    "    # patient_data['t_sepsis'] = patient_data.apply(t_sepsis, axis=1)\n",
    "\n",
    "    # patient_data = patient_data[final_features]\n",
    "\n",
    "    max_rows = 8\n",
    "    num_features = patient_data.shape[1]\n",
    "    if len(patient_data) < max_rows:\n",
    "        padding = np.zeros((max_rows - len(patient_data), num_features))\n",
    "        patient_data = np.vstack((patient_data.values, padding)).astype(np.float32)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # If patient data is > window_size ?\n",
    "        segments = []\n",
    "        max_rows = 8\n",
    "\n",
    "        for start in range(0, len(patient_data) - max_rows + 1):\n",
    "            segment = patient_data.iloc[start: start + max_rows].values\n",
    "            segments.append(segment.astype(np.float32))\n",
    "\n",
    "        # Making predictions for every segment\n",
    "        segment_predictions = []\n",
    "        segment_probs = []\n",
    "        for segment in segments:\n",
    "            segment = torch.from_numpy(segment).unsqueeze(0)\n",
    "\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                segment = segment.to(torch.float32).to(device)\n",
    "                outputs, _, _, _, _, _, _ = model(segment, stage='test')\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "            predicted_class = predicted.detach().cpu().numpy()[0]\n",
    "            probabilities = probabilities.detach().cpu().numpy()[0][predicted_class]\n",
    "\n",
    "            segment_predictions.append(predicted_class)\n",
    "            segment_probs.append(probabilities)\n",
    "        \n",
    "        print(np.mean(segment_predictions), segment_probs)\n",
    "        predictions = [torch.tensor(segment_predictions).mode()[0].detach().cpu().numpy().item()]\n",
    "        probas = [torch.tensor(segment_probs).mean().detach().cpu().numpy().item()]\n",
    "        \n",
    "        return predictions, probas, patient_data\n",
    "\n",
    "    # This code executes when patient_data is within the window_size\n",
    "    patient_data = torch.from_numpy(patient_data).unsqueeze(0)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    probas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        patient_data = patient_data.to(torch.float32).to(device)\n",
    "        outputs, _, _, _, _, _, _ = model(patient_data, stage='test')\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "        predicted_class = predicted.detach().cpu().numpy()[0]\n",
    "\n",
    "        predictions.append(predicted_class)\n",
    "        probas.append(probabilities.detach().cpu().numpy()[0][predicted_class])\n",
    "\n",
    "    return predictions, probas, patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('/localscratch/neeresh/data/physionet2019/physionet.org/files/challenge-2019/1.0.0/training/training_setA/p000034.psv', sep='|')\n",
    "sample = sample.drop(['SepsisLabel'], axis=1).values\n",
    "\n",
    "num_rows = len(sample)  # Number of patient recordings\n",
    "scores = np.zeros(num_rows)\n",
    "labels = np.zeros(num_rows)\n",
    "\n",
    "for t in range(num_rows):\n",
    "    current_data = sample[:t + 1]\n",
    "    current_labels, current_score, data_df = get_sepsis_score(current_data, model)\n",
    "    scores[t] = current_score[0]\n",
    "    labels[t] = current_labels[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores), len(labels), sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
