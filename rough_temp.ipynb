{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-15T15:39:08.067214Z",
     "start_time": "2024-06-15T15:39:06.769662Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from setup_data import DataSetup\n",
    "\n",
    "from utils.config import gtn_param\n",
    "\n",
    "from train_gtn import GatedTransformerNetwork, load_model, initialize_experiment\n",
    "from utils.loader import make_loader\n",
    "\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import tqdm"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:39:08.072118Z",
     "start_time": "2024-06-15T15:39:08.070025Z"
    }
   },
   "cell_type": "code",
   "source": "device = 'mps'",
   "id": "7f7cb9a987eeb1d5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:39:28.241311Z",
     "start_time": "2024-06-15T15:39:08.072872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_file = \"final_dataset.pickle\"\n",
    "training_examples, lengths_list, is_sepsis, writer, destination_path = initialize_experiment(data_file)\n",
    "train_loader, test_loader = make_loader(training_examples, lengths_list, is_sepsis, 128, mode='padding')"
   ],
   "id": "8b529548759bb41b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datafile used: final_dataset.pickle\n",
      "Total number of patients: 40336\n",
      "Min recordings: 8 & Max recordings: 336\n",
      "Distribution of the SepsisLabel: \n",
      "0    37404\n",
      "1     2932\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding...: 100%|██████████| 32268/32268 [00:10<00:00, 3109.89it/s]\n",
      "Padding...: 100%|██████████| 8067/8067 [00:02<00:00, 3169.91it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:39:34.852058Z",
     "start_time": "2024-06-15T15:39:34.745492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_sepsis_model():\n",
    "    config = gtn_param\n",
    "    d_input, d_channel, d_output = 336, 63, 2  # (time_steps (window_size), channels, num_classes)\n",
    "    model = GatedTransformerNetwork(d_model=config['d_model'], d_input=d_input, d_channel=d_channel,\n",
    "                                    d_output=d_output, d_hidden=config['d_hidden'], q=config['q'],\n",
    "                                    v=config['v'], h=config['h'], N=config['N'], dropout=config['dropout'],\n",
    "                                    pe=config['pe'], mask=config['mask'], device='cpu').to('cpu')\n",
    "    \n",
    "    return load_model(model)\n",
    "\n",
    "model = load_sepsis_model()"
   ],
   "id": "b108dee749030855",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 11\u001B[0m\n\u001B[1;32m      4\u001B[0m     model \u001B[38;5;241m=\u001B[39m GatedTransformerNetwork(d_model\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124md_model\u001B[39m\u001B[38;5;124m'\u001B[39m], d_input\u001B[38;5;241m=\u001B[39md_input, d_channel\u001B[38;5;241m=\u001B[39md_channel,\n\u001B[1;32m      5\u001B[0m                                     d_output\u001B[38;5;241m=\u001B[39md_output, d_hidden\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124md_hidden\u001B[39m\u001B[38;5;124m'\u001B[39m], q\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      6\u001B[0m                                     v\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mv\u001B[39m\u001B[38;5;124m'\u001B[39m], h\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m'\u001B[39m], N\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m'\u001B[39m], dropout\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdropout\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      7\u001B[0m                                     pe\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpe\u001B[39m\u001B[38;5;124m'\u001B[39m], mask\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m], device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m load_model(model)\n\u001B[0;32m---> 11\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mload_sepsis_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 9\u001B[0m, in \u001B[0;36mload_sepsis_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m d_input, d_channel, d_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m336\u001B[39m, \u001B[38;5;241m63\u001B[39m, \u001B[38;5;241m2\u001B[39m  \u001B[38;5;66;03m# (time_steps (window_size), channels, num_classes)\u001B[39;00m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m GatedTransformerNetwork(d_model\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124md_model\u001B[39m\u001B[38;5;124m'\u001B[39m], d_input\u001B[38;5;241m=\u001B[39md_input, d_channel\u001B[38;5;241m=\u001B[39md_channel,\n\u001B[1;32m      5\u001B[0m                                 d_output\u001B[38;5;241m=\u001B[39md_output, d_hidden\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124md_hidden\u001B[39m\u001B[38;5;124m'\u001B[39m], q\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mq\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      6\u001B[0m                                 v\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mv\u001B[39m\u001B[38;5;124m'\u001B[39m], h\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m'\u001B[39m], N\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m'\u001B[39m], dropout\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdropout\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m      7\u001B[0m                                 pe\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpe\u001B[39m\u001B[38;5;124m'\u001B[39m], mask\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmask\u001B[39m\u001B[38;5;124m'\u001B[39m], device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/SepsisEarlyPrediction/train_gtn.py:168\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(model):\n\u001B[0;32m--> 168\u001B[0m     model\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_gtn.pkl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    169\u001B[0m     model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    170\u001B[0m     model\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.8/site-packages/torch/serialization.py:1026\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1024\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1025\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1026\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m                     \u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverall_storage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmap can only be used with files saved with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1033\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1034\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.8/site-packages/torch/serialization.py:1438\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1436\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m   1437\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m-> 1438\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1440\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m   1441\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[1;32m   1442\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[1;32m   1443\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.8/site-packages/torch/serialization.py:1408\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m   1406\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1407\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[0;32m-> 1408\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1410\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.8/site-packages/torch/serialization.py:1382\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(dtype, numel, key, location)\u001B[0m\n\u001B[1;32m   1377\u001B[0m         storage\u001B[38;5;241m.\u001B[39mbyteswap(dtype)\n\u001B[1;32m   1379\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[1;32m   1380\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[1;32m   1381\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[0;32m-> 1382\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39m\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1383\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   1384\u001B[0m     _internal\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1386\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typed_storage\u001B[38;5;241m.\u001B[39m_data_ptr() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1387\u001B[0m     loaded_storages[key] \u001B[38;5;241m=\u001B[39m typed_storage\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.8/site-packages/torch/serialization.py:391\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_restore_location\u001B[39m(storage, location):\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[0;32m--> 391\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    393\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.8/site-packages/torch/serialization.py:266\u001B[0m, in \u001B[0;36m_cuda_deserialize\u001B[0;34m(obj, location)\u001B[0m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_deserialize\u001B[39m(obj, location):\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 266\u001B[0m         device \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_cuda_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    267\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_torch_load_uninitialized\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    268\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice(device):\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.8/site-packages/torch/serialization.py:250\u001B[0m, in \u001B[0;36mvalidate_cuda_device\u001B[0;34m(location)\u001B[0m\n\u001B[1;32m    247\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_get_device_index(location, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m--> 250\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a CUDA \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    251\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdevice but torch.cuda.is_available() is False. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    252\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    253\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;130;01m\\'\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    254\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    255\u001B[0m device_count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:38:09.337404Z",
     "start_time": "2024-06-15T15:38:09.334879Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "68eff9def360d05",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "75e17e2936118ea0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5bcf8d408f30e66c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1a2b49288ec85710"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "585ed078845f4c06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5a067e91e5c5cf16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27b0a629ec638617"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T15:36:53.999395Z",
     "start_time": "2024-06-15T15:36:53.997878Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6db84551a34f87ed",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:20.712408Z",
     "start_time": "2024-06-15T07:33:20.703391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def platelets_sofa(platelets):\n",
    "    s_score = 0\n",
    "    if platelets > 150:\n",
    "        s_score += 0\n",
    "    elif platelets >= 101 and platelets <= 150:\n",
    "        s_score += 1\n",
    "    elif platelets >= 51 and platelets <= 100:\n",
    "        s_score += 2\n",
    "    elif platelets >= 21 and platelets <= 50:\n",
    "        s_score += 3\n",
    "    elif platelets <= 20:\n",
    "        s_score += 4\n",
    "\n",
    "    return s_score\n",
    "\n",
    "\n",
    "def total_bilirubin_sofa(bilirubin):\n",
    "    s_score = 0\n",
    "    if bilirubin < 1.2:\n",
    "        s_score += 0\n",
    "    elif bilirubin >= 1.2 and bilirubin <= 1.9:\n",
    "        s_score += 1\n",
    "    elif bilirubin >= 2.0 and bilirubin <= 5.9:\n",
    "        s_score += 2\n",
    "    elif bilirubin >= 6 and bilirubin <= 11.9:\n",
    "        s_score += 3\n",
    "    elif bilirubin >= 12.0:\n",
    "        s_score += 4\n",
    "\n",
    "    return s_score\n",
    "\n",
    "\n",
    "def map_sofa(map):\n",
    "    s_score = 0\n",
    "    if map >= 70:\n",
    "        s_score += 0\n",
    "    elif map < 70:\n",
    "        s_score += 1\n",
    "\n",
    "    return s_score\n",
    "\n",
    "\n",
    "def sofa_score(row):\n",
    "    platelets_score = row['Platelets_SOFA']\n",
    "    bilirubin_score = row['Bilirubin_total_SOFA']\n",
    "    map_sofa = row['MAP_SOFA']\n",
    "\n",
    "    return platelets_score + bilirubin_score + map_sofa\n",
    "\n",
    "\n",
    "def detect_sofa_change(data, time_window=24):\n",
    "    data['SOFA_score_diff'] = data['SOFA_score'].diff(periods=time_window)\n",
    "    data['SOFA_deterioration'] = (data['SOFA_score_diff'] >= 2).astype(int)\n",
    "    data['SOFA_score_diff'] = data['SOFA_score_diff'].fillna(value=0)\n",
    "    # data['SOFA_score_diff'].fillna(value=0, inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "def respiratory_rate_qsofa(respiratory_rate):\n",
    "    q_score = 0\n",
    "    if respiratory_rate >= 22.0:\n",
    "        q_score += 1\n",
    "\n",
    "    return q_score\n",
    "\n",
    "\n",
    "def sbp_qsofa(sbp):\n",
    "    q_score = 0\n",
    "    if sbp < 100.0:\n",
    "        q_score += 1\n",
    "\n",
    "    return q_score\n",
    "\n",
    "\n",
    "def qsofa_score(row):\n",
    "    resp_score = row['ResP_qSOFA']\n",
    "    sbp_score = row['SBP_qSOFA']\n",
    "\n",
    "    return sbp_score + resp_score\n",
    "\n",
    "\n",
    "def q_sofa_indicator(row):\n",
    "    resp = row['ResP_qSOFA']\n",
    "    sbp = row['SBP_qSOFA']\n",
    "    q_score = 0\n",
    "    if resp > 0 and sbp > 0:\n",
    "        q_score += 1\n",
    "    return q_score\n",
    "\n",
    "\n",
    "def sofa_indicator(row):\n",
    "    # 2+ points indicates organ dysfunction\n",
    "    platelets = row['Platelets_SOFA']\n",
    "    bilirubin_total = row['Bilirubin_total_SOFA']\n",
    "    map = row['MAP_SOFA']\n",
    "\n",
    "    total_points = platelets + bilirubin_total + map\n",
    "\n",
    "    q_score = 0\n",
    "    if total_points > 2:\n",
    "        q_score += 1\n",
    "    return q_score\n",
    "\n",
    "\n",
    "def detect_qsofa_change(data, time_window=24):\n",
    "    data['qSOFA_score_diff'] = data['qSOFA_score'].diff(periods=time_window)\n",
    "    data['qSOFA_deterioration'] = (data['qSOFA_score_diff'] >= 2).astype(int)\n",
    "\n",
    "    data['qSOFA_score_diff'] = data['qSOFA_score_diff'].fillna(value=0)\n",
    "    # data['qSOFA_score_diff'].fillna(value=0, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def mortality_sofa(row):\n",
    "    # 2+ points indicates organ dysfunction\n",
    "    platelets = row['Platelets_SOFA']\n",
    "    bilirubin_total = row['Bilirubin_total_SOFA']\n",
    "    map = row['MAP_SOFA']\n",
    "\n",
    "    total_points = platelets + bilirubin_total + map\n",
    "\n",
    "    mortality_rate = 0\n",
    "    if total_points > 1 and total_points <= 9:\n",
    "        mortality_rate += 0.30\n",
    "    elif total_points >= 10 and total_points < 14:\n",
    "        mortality_rate += 0.50\n",
    "    elif total_points >= 14:\n",
    "        mortality_rate += 0.95\n",
    "\n",
    "    return mortality_rate\n",
    "\n",
    "\n",
    "def temp_sirs(temp):\n",
    "    sirs_score = 0\n",
    "    if temp < 36 or temp >= 38:\n",
    "        sirs_score += 1\n",
    "\n",
    "    return sirs_score\n",
    "\n",
    "\n",
    "def heart_rate_sirs(heart_rate):\n",
    "    sirs_score = 0\n",
    "    if heart_rate > 90:\n",
    "        sirs_score += 1\n",
    "\n",
    "    return sirs_score\n",
    "\n",
    "\n",
    "def resp_sirs(resp):\n",
    "    sirs_score = 0\n",
    "    if resp > 20:\n",
    "        sirs_score += 1\n",
    "\n",
    "    return sirs_score\n",
    "\n",
    "\n",
    "def paco2_sirs(paco2):\n",
    "    sirs_score = 0\n",
    "    if paco2 < 32:\n",
    "        sirs_score += 1\n",
    "\n",
    "    return sirs_score\n",
    "\n",
    "\n",
    "def wbc_sirs(wbc):\n",
    "    sirs_score = 0\n",
    "    if wbc * 1000 < 4000 or wbc * 1000 > 12000:\n",
    "        sirs_score += 1\n",
    "    return sirs_score\n",
    "\n",
    "\n",
    "def t_suspicion(patient_data):\n",
    "    \"\"\"\n",
    "    Since we don't have information about IV antibiotics and blood cultures,\n",
    "    we are is considering that patient have infection if any 2 SIRS criteria are met\n",
    "    \"\"\"\n",
    "    patient_data['PatientID'] = 0\n",
    "    patient_data['infection_proxy'] = (patient_data[['Temp_sirs', 'HR_sirs', 'Resp_sirs']].eq(1).sum(axis=1) >= 2).astype(int)\n",
    "    # t_suspicion is the first hour of (ICULOS) where infection proxy is positive at time t\n",
    "    patient_data['t_suspicion'] = patient_data.groupby(['PatientID'])['ICULOS'].transform(\n",
    "        lambda x: x[patient_data['infection_proxy'] == 1].min() if (patient_data['infection_proxy'] == 1).any() else 0)\n",
    "    \n",
    "    patient_data = patient_data.drop(['PatientID'], axis=1)\n",
    "\n",
    "    return patient_data\n",
    "\n",
    "\n",
    "def t_sofa(data):\n",
    "    \"\"\"\n",
    "    Two-point deterioration in SOFA score at time t but within a 24-hour period.\n",
    "    \"\"\"\n",
    "    data['t_sofa'] = data['SOFA_score_diff'].where((abs(data['SOFA_score_diff']) >= 2) & (data['ICULOS'] <= 24),\n",
    "                                                   other=0)\n",
    "    return data\n",
    "\n",
    "\n",
    "def t_sepsis(row):\n",
    "    if pd.isna(row['t_suspicion']) or row['t_suspicion'] == 0 or row['t_sofa'] == 0:\n",
    "        return 0\n",
    "    if row['t_suspicion'] - 24 <= row['t_sofa'] <= row['t_suspicion'] + 12:\n",
    "        return min(row['t_suspicion'], row['t_sofa'])"
   ],
   "id": "6b4099310c537fda",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:41.157680Z",
     "start_time": "2024-06-15T07:33:41.148334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_sepsis_model():\n",
    "    config = gtn_param\n",
    "    d_input, d_channel, d_output = 336, 63, 2  # (time_steps (window_size), channels, num_classes)\n",
    "    model = GatedTransformerNetwork(d_model=config['d_model'], d_input=d_input, d_channel=d_channel,\n",
    "                                    d_output=d_output, d_hidden=config['d_hidden'], q=config['q'],\n",
    "                                    v=config['v'], h=config['h'], N=config['N'], dropout=config['dropout'],\n",
    "                                    pe=config['pe'], mask=config['mask'], device=device).to(device)\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_challenge_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "        header = f.readline().strip()\n",
    "        column_names = header.split('|')\n",
    "        data = np.loadtxt(f, delimiter='|')\n",
    "\n",
    "    # Ignore SepsisLabel column if present.\n",
    "    if column_names[-1] == 'SepsisLabel':\n",
    "        column_names = column_names[:-1]\n",
    "        data = data[:, :-1]\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_sepsis_score(data, model):\n",
    "\n",
    "    columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp',\n",
    "       'EtCO2', 'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST',\n",
    "       'BUN', 'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine',\n",
    "       'Bilirubin_direct', 'Glucose', 'Lactate', 'Magnesium', 'Phosphate',\n",
    "       'Potassium', 'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "       'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
    "       'HospAdmTime', 'ICULOS']\n",
    "\n",
    "    # Reformatting data into DataFrame to add features\n",
    "    patient_data = pd.DataFrame(data, columns=columns)\n",
    "    patient_data = patient_data.fillna(0)\n",
    "    \n",
    "    patient_data['MAP_SOFA'] = patient_data['MAP'].apply(map_sofa)\n",
    "    patient_data['Bilirubin_total_SOFA'] = patient_data['Bilirubin_total'].apply(total_bilirubin_sofa)\n",
    "    patient_data['Platelets_SOFA'] = patient_data['Platelets'].apply(platelets_sofa)\n",
    "    patient_data['SOFA_score'] = patient_data.apply(sofa_score, axis=1)\n",
    "    patient_data = detect_sofa_change(patient_data)\n",
    "\n",
    "    patient_data['ResP_qSOFA'] = patient_data['Resp'].apply(respiratory_rate_qsofa)\n",
    "    patient_data['SBP_qSOFA'] = patient_data['SBP'].apply(sbp_qsofa)\n",
    "    patient_data['qSOFA_score'] = patient_data.apply(qsofa_score, axis=1)\n",
    "    patient_data = detect_qsofa_change(patient_data)\n",
    "\n",
    "    patient_data['qSOFA_indicator'] = patient_data.apply(q_sofa_indicator, axis=1)  # Sepsis detected\n",
    "    patient_data['SOFA_indicator'] = patient_data.apply(sofa_indicator, axis=1)  # Organ Dysfunction occurred\n",
    "    patient_data['Mortality_sofa'] = patient_data.apply(mortality_sofa, axis=1)  # Morality rate\n",
    "\n",
    "    patient_data['Temp_sirs'] = patient_data['Temp'].apply(temp_sirs)\n",
    "    patient_data['HR_sirs'] = patient_data['HR'].apply(heart_rate_sirs)\n",
    "    patient_data['Resp_sirs'] = patient_data['Resp'].apply(resp_sirs)\n",
    "    patient_data['paco2_sirs'] = patient_data['PaCO2'].apply(resp_sirs)\n",
    "    patient_data['wbc_sirs'] = patient_data['WBC'].apply(wbc_sirs)\n",
    "\n",
    "    patient_data = t_suspicion(patient_data)\n",
    "    patient_data = t_sofa(patient_data)\n",
    "    patient_data['t_sepsis'] = patient_data.apply(t_sepsis, axis=1)\n",
    "    \n",
    "    max_rows = 336\n",
    "    num_features = patient_data.shape[1]\n",
    "    if len(patient_data) < max_rows:\n",
    "        padding = np.zeros((max_rows - len(patient_data), num_features))\n",
    "        patient_data = np.vstack((patient_data, padding))\n",
    "    elif len(patient_data) > max_rows:\n",
    "        patient_data = patient_data.iloc[:max_rows]\n",
    "\n",
    "    patient_data = torch.tensor(patient_data).unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    probas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        patient_data = patient_data.to(torch.float32).to(device)\n",
    "        outputs, _, _, _, _, _, _ = model(patient_data, stage='test')\n",
    "    \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        probas.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    return predictions, probas, patient_data"
   ],
   "id": "2edfeb3ab43f433",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:44:09.546411Z",
     "start_time": "2024-06-15T07:44:09.295166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.path_utils import project_root\n",
    "\n",
    "def save_challenge_predictions(file, scores, labels):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write('PredictedProbability|PredictedLabel\\n')\n",
    "        for (s, l) in zip(scores, labels):\n",
    "            f.write('%g|%d\\n' % (s, l))\n",
    "\n",
    "def evaluate():\n",
    "    input_directory = os.path.join(project_root(), 'physionet.org', 'files', 'challenge-2019', '1.0.0', 'training',\n",
    "                                        'training_setA')\n",
    "    # input_directory = \"/localscratch/neeresh/data/physionet2019/physionet.org/files/challenge-2019/1.0.0/training/training_setA/\"\n",
    "    # input_directory = \"/localscratch/neeresh/data/physionet2019/physionet.org/files/challenge-2019/1.0.0/training/training_setB/\"\n",
    "    output_directory = \"./data/test_output/\"\n",
    "\n",
    "    # Find files.\n",
    "    files = []\n",
    "    for f in os.listdir(input_directory):\n",
    "        if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('psv'):\n",
    "            files.append(f)\n",
    "    \n",
    "    # files.sort()\n",
    "    if not os.path.isdir(output_directory):\n",
    "        os.mkdir(output_directory)\n",
    "    \n",
    "    # Load model.\n",
    "    print('Loading sepsis model...')\n",
    "    model = load_sepsis_model()\n",
    "\n",
    "    # Iterate over files.\n",
    "    print('Predicting sepsis labels...')\n",
    "    num_files = len(files)\n",
    "    for i, f in enumerate(files):\n",
    "        print('    {}/{}...'.format(i+1, num_files))\n",
    "\n",
    "        # Load data.\n",
    "        input_file = os.path.join(input_directory, f)\n",
    "        data = load_challenge_data(input_file)\n",
    "\n",
    "        # Make predictions.\n",
    "        num_rows = len(data)  # Number of patient recordings\n",
    "        scores = np.zeros(num_rows)\n",
    "        labels = np.zeros(num_rows)\n",
    "        \n",
    "        for t in range(num_rows):\n",
    "            current_data = data[:t+1]\n",
    "            current_labels, current_score, data_df = get_sepsis_score(current_data, model)\n",
    "            scores[t] = current_score[0]\n",
    "            labels[t] = current_labels[0]\n",
    "            \n",
    "            # break\n",
    "        # break\n",
    "        \n",
    "        output_file = os.path.join(output_directory, f)\n",
    "        save_challenge_predictions(output_file, scores, labels)\n",
    "    \n",
    "    return model, data, current_data, predictions, probs, data_df\n",
    "\n",
    "model, data, current_data, predictions, probs, data_df = evaluate()"
   ],
   "id": "7b5b86445cebc3a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sepsis model...\n",
      "Predicting sepsis labels...\n",
      "    1/20336...\n",
      "1 [0.46612144 0.5338786 ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;31mTypeError\u001B[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 60\u001B[0m\n\u001B[1;32m     56\u001B[0m         save_challenge_predictions(output_file, scores, labels)\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model, data, current_data, predictions, probs, data_df\n\u001B[0;32m---> 60\u001B[0m model, data, current_data, predictions, probs, data_df \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 49\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m()\u001B[0m\n\u001B[1;32m     47\u001B[0m     current_labels, current_score, data_df \u001B[38;5;241m=\u001B[39m get_sepsis_score(current_data, model)\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mprint\u001B[39m(current_labels[\u001B[38;5;241m0\u001B[39m], current_score[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m---> 49\u001B[0m     scores[t] \u001B[38;5;241m=\u001B[39m current_score[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     50\u001B[0m     labels[t] \u001B[38;5;241m=\u001B[39m current_labels[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# break\u001B[39;00m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m# break\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence."
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:42.921579Z",
     "start_time": "2024-06-15T07:33:42.920147Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c4d948b978ff3e29",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.326651Z",
     "start_time": "2024-06-15T07:33:22.325317Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2332edade7132d29",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.328968Z",
     "start_time": "2024-06-15T07:33:22.327498Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "785134d7a8d7fc76",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.330952Z",
     "start_time": "2024-06-15T07:33:22.329663Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "41dc2c458c15b85e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.335205Z",
     "start_time": "2024-06-15T07:33:22.333655Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5f1d95a6525fdae1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.337202Z",
     "start_time": "2024-06-15T07:33:22.335851Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "28f1870eeb818a3b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.339497Z",
     "start_time": "2024-06-15T07:33:22.338041Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6e5fbb28babe7f4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.341754Z",
     "start_time": "2024-06-15T07:33:22.340324Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f6766edbf1ab13c5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.343711Z",
     "start_time": "2024-06-15T07:33:22.342337Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "76e29e0da68c0826",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:33:22.345890Z",
     "start_time": "2024-06-15T07:33:22.344628Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "40d85baa8cb78ddb",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
