{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T01:14:07.630584Z",
     "start_time": "2024-09-24T01:14:07.628803Z"
    }
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:14:14.170020Z",
     "start_time": "2024-09-24T01:14:07.631634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from utils.path_utils import project_root\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load data\n",
    "from adatime.load_data import load_data\n",
    "from adatime.configs.get_configs import get_configs\n"
   ],
   "id": "94a471beaa5744b1",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:14:14.172977Z",
     "start_time": "2024-09-24T01:14:14.171045Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1fdc6ba083cf8142",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "987f01e0c873aad0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:17:00.887859Z",
     "start_time": "2024-09-24T01:14:14.173939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from adatime.utils import AverageMeter, fix_randomness, save_checkpoint, calculate_metrics, calculate_risks, \\\n",
    "    append_results_to_tables, add_mean_std_table, save_tables_to_file\n",
    "import collections\n",
    "from adatime.log_utils.log_experiment import starting_logs\n",
    "from adatime.da.models import get_backbone_class\n",
    "from adatime.da.algorithms import get_algorithm_class\n",
    "\n",
    "data_path = os.path.join(project_root(), 'data', 'adatime_datasets', 'HHAR', 'HHAR_SA')\n",
    "print(f\"Data loading from {data_path}\")\n",
    "\n",
    "dataset_name = 'HHAR'\n",
    "dataset_configs, hparams = get_configs(dataset_name)\n",
    "\n",
    "results_columns = [\"scenario\", \"run\", \"acc\", \"f1_score\", \"auroc\"]\n",
    "risks_columns = [\"scenario\", \"run\", \"src_risk\", \"few_shot_risk\", \"trg_risk\"]\n",
    "\n",
    "# table with metrics\n",
    "table_results = pd.DataFrame(columns=results_columns)\n",
    "# table with risks\n",
    "table_risks = pd.DataFrame(columns=risks_columns)\n",
    "\n",
    "device = 'cuda:0'\n",
    "num_runs = 1\n",
    "for src_id, trg_id in dataset_configs.scenarios:\n",
    "    \n",
    "    for run_id in range(num_runs):\n",
    "        \n",
    "        fix_randomness(run_id)\n",
    "        \n",
    "        # Loading Data\n",
    "        src_train, src_test, tgt_train, tgt_test, few_shot_dl_5 = load_data(\n",
    "            data_path=data_path, src_id=src_id, trg_id=trg_id, dataset_configs=dataset_configs, \n",
    "            hparams=hparams)\n",
    "        \n",
    "        # Setting up DA algorithm\n",
    "        da_algorithm_name = 'HoMM'\n",
    "        da_algorithm = get_algorithm_class(da_algorithm_name)\n",
    "        \n",
    "        # Setting up backbone\n",
    "        backbone_name = 'CNN'\n",
    "        da_backbone = get_backbone_class(backbone_name) \n",
    "        \n",
    "        # Initializing algorithm\n",
    "        algorithm = da_algorithm(da_backbone, dataset_configs, hparams, device, \n",
    "                                 da_algorithm_name)\n",
    "        algorithm.to(device)\n",
    "        \n",
    "        # Train the domain adaptation algorithm\n",
    "        home_path =  os.getcwd()\n",
    "        save_dir = 'experiment_logs'\n",
    "        experiment_description = dataset_name\n",
    "        exp_name = 'testing_da_framework'\n",
    "        run_description = f\"{da_algorithm_name}_{exp_name}\"\n",
    "        \n",
    "        exp_log_dir = os.path.join(home_path, save_dir, experiment_description, f\"{run_description}\")\n",
    "        \n",
    "        logger, scenario_log_dir = starting_logs(dataset_name, da_algorithm_name, \n",
    "                                                 exp_log_dir, src_id, trg_id, run_id)\n",
    "        \n",
    "        loss_avg_meters = collections.defaultdict(lambda: AverageMeter())\n",
    "        last_model, best_model = algorithm.update(src_train, tgt_train, loss_avg_meters, logger)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(home_path, scenario_log_dir, last_model, best_model)\n",
    "        \n",
    "        # Calculate risks and metrics\n",
    "        metrics = calculate_metrics(algorithm, tgt_test, dataset_configs, device)\n",
    "        risks = calculate_risks(algorithm, src_test, tgt_test, few_shot_dl_5, device)\n",
    "        \n",
    "        # Append results to tables\n",
    "        scenario = f\"{src_id}_to_{trg_id}\"\n",
    "        table_results = append_results_to_tables(table_results, scenario, run_id, metrics)\n",
    "        table_risks = append_results_to_tables(table_risks, scenario, run_id, risks)\n",
    "    \n",
    "# Calculate and append mean and std to tables\n",
    "print(\"add_mean_std_table for table\")\n",
    "table_results = add_mean_std_table(table_results, results_columns)\n",
    "\n",
    "print(\"add_mean_std_table for risks\")\n",
    "table_risks = add_mean_std_table(table_risks, risks_columns)\n",
    "\n",
    "# Save tables to file if needed\n",
    "save_tables_to_file(exp_log_dir, table_results, 'results')\n",
    "save_tables_to_file(exp_log_dir, table_risks, 'risks')\n",
    "    "
   ],
   "id": "5affbb83e80ff586",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:17:00.899292Z",
     "start_time": "2024-09-24T01:17:00.897375Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "72081611534e2a65",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "33774a38a2df0dfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:17:05.539990Z",
     "start_time": "2024-09-24T01:17:00.900214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from adatime.utils import load_checkpoint, evaluate\n",
    "\n",
    "# Results dataframes\n",
    "last_results = pd.DataFrame(columns=results_columns)\n",
    "best_results = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "# Cross-domain scenarios\n",
    "for src_id, trg_id in dataset_configs.scenarios:\n",
    "    for run_id in range(num_runs):\n",
    "        # fixing random seed\n",
    "        fix_randomness(run_id)\n",
    "        \n",
    "        # Logging\n",
    "        scenario_log_dir = os.path.join(exp_log_dir, src_id + \"_to_\" + trg_id + \"_run_\" + str(run_id))\n",
    "        loss_avg_meters = collections.defaultdict(lambda: AverageMeter())\n",
    "        \n",
    "        # Load data\n",
    "        src_train, src_test, tgt_train, tgt_test, few_shot_dl_5 = load_data(\n",
    "        data_path=data_path, src_id=src_id, trg_id=trg_id, dataset_configs=dataset_configs, \n",
    "        hparams=hparams)\n",
    "        \n",
    "        # Setting up DA algorithm\n",
    "        da_algorithm_name = 'HoMM'\n",
    "        da_algorithm = get_algorithm_class(da_algorithm_name)\n",
    "        \n",
    "        # Setting up backbone\n",
    "        backbone_name = 'CNN'\n",
    "        da_backbone = get_backbone_class(backbone_name) \n",
    "        \n",
    "        # Initializing algorithm\n",
    "        algorithm = da_algorithm(da_backbone, dataset_configs, hparams, device, \n",
    "                                 da_algorithm_name)\n",
    "        algorithm.to(device)\n",
    "        \n",
    "        # Loading checkpoint\n",
    "        last_chk, best_chk = load_checkpoint(scenario_log_dir)\n",
    "        \n",
    "        # Testing the last model\n",
    "        algorithm.network.load_state_dict(last_chk)\n",
    "        loss, full_preds, full_labels = evaluate(algorithm, tgt_test, device)\n",
    "        last_metrics = calculate_metrics(algorithm, tgt_test, dataset_configs, device)\n",
    "        last_results = append_results_to_tables(last_results, f\"{src_id}_to_{trg_id}\", run_id,\n",
    "                                                     last_metrics)\n",
    "        \n",
    "        # Testing the best model\n",
    "        algorithm.network.load_state_dict(best_chk)\n",
    "        loss, full_preds, full_labels = evaluate(algorithm, tgt_test, device)\n",
    "        best_metrics = calculate_metrics(algorithm, tgt_test, dataset_configs, device)\n",
    "        \n",
    "        # Append results to tables\n",
    "        best_results = append_results_to_tables(best_results, f\"{src_id}_to_{trg_id}\", run_id,\n",
    "                                                     best_metrics)\n",
    "        \n",
    "last_scenario_mean_std = last_results.groupby('scenario')[['acc', 'f1_score', 'auroc']].agg(['mean', 'std'])\n",
    "best_scenario_mean_std = best_results.groupby('scenario')[['acc', 'f1_score', 'auroc']].agg(['mean', 'std'])\n",
    "\n",
    "# Save tables to file if needed\n",
    "save_tables_to_file(exp_log_dir, last_scenario_mean_std, 'last_results')\n",
    "save_tables_to_file(exp_log_dir, best_scenario_mean_std, 'best_results')\n",
    "\n",
    "# printing summary \n",
    "summary_last = {metric: np.mean(last_results[metric]) for metric in results_columns[2:]}\n",
    "summary_best = {metric: np.mean(best_results[metric]) for metric in results_columns[2:]}\n",
    "for summary_name, summary in [('Last', summary_last), ('Best', summary_best)]:\n",
    "    for key, val in summary.items():\n",
    "        print(f'{summary_name}: {key}\\t: {val:2.4f}')\n",
    "        \n",
    "    # break\n",
    "    "
   ],
   "id": "6b217d970a4e5c69",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:17:05.542436Z",
     "start_time": "2024-09-24T01:17:05.540906Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "18ea39b7cf72b27d",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T01:17:05.544411Z",
     "start_time": "2024-09-24T01:17:05.543073Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a1675f113c9bb2e6",
   "execution_count": 3,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
