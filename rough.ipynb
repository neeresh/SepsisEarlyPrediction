{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b4600521d42e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:41:59.365899Z",
     "start_time": "2024-07-31T21:41:58.306741Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from models.custom_models.gtn import GatedTransformerNetwork\n",
    "from models.gtn.transformer import Transformer\n",
    "from utils.config import gtn_param\n",
    "from utils.loader import make_loader\n",
    "from utils.path_utils import project_root\n",
    "from utils.plot_metrics import plot_losses_and_accuracies\n",
    "\n",
    "from utils.config import masked_gtn_param\n",
    "from models.custom_models.gtn_mask import MaskedGatedTransformerNetwork\n",
    "device = 'cuda'\n",
    "config = gtn_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d12c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "config = masked_gtn_param\n",
    "d_input, d_channel, d_output = 336, 191, 2\n",
    "\n",
    "model = MaskedGatedTransformerNetwork(d_model=config['d_model'], d_input=d_input, d_channel=d_channel,\n",
    "                                          d_output=d_output, d_hidden=config['d_hidden'], q=config['q'],\n",
    "                                          v=config['v'], h=config['h'], N=config['N'], dropout=config['dropout'],\n",
    "                                          pe=config['pe'], mask=config['mask'], device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b065dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 193.365MB\n"
     ]
    }
   ],
   "source": [
    "param_size = 0\n",
    "\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5cd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e339bec58e5fe8a",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf0229ead3ca41a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T16:20:09.972136Z",
     "start_time": "2024-08-01T16:20:09.968587Z"
    }
   },
   "outputs": [],
   "source": [
    "def power(a, b):\n",
    "    return a**b\n",
    "\n",
    "from functools import partial, partialmethod\n",
    "\n",
    "a_square = partial(power, b=2)\n",
    "b_square = partialmethod(power, a=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "648e6649fb4461bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-01T16:20:30.532568Z",
     "start_time": "2024-08-01T16:20:30.527786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partialmethod(<function power at 0x78e8ae250900>, , a=2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff1e950892954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34f58b55bc0d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22188adaa09998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ddabcb24def64b1",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df682875108f634c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:58:45.179362Z",
     "start_time": "2024-07-31T21:57:53.325007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datafile used: final_dataset.pickle\n",
      "Total number of patients: 40336\n",
      "Min recordings: 8 & Max recordings: 336\n",
      "Distribution of the SepsisLabel: \n",
      "0    37404\n",
      "1     2932\n",
      "Name: count, dtype: int64\n",
      "Number of positive samples: 2932\n",
      "Number of negative samples: 7481\n",
      "Batch size: 3\n",
      "Total samples: 10413\n",
      "Loading train and test from given indicies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding...: 100%|██████████| 8330/8330 [00:27<00:00, 304.48it/s]\n",
      "Padding...: 100%|██████████| 1042/1042 [00:03<00:00, 299.42it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 32\u001b[0m\n\u001b[1;32m     24\u001b[0m val_indicies, test_indicies \u001b[38;5;241m=\u001b[39m train_test_split(temp_indicies, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# 10 10\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# train_indicies, test_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# train_loader, test_loader, train_indicies, test_indicies = make_loader(training_examples, lengths_list, is_sepsis,\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#                                                                        batch_size=batch_size, mode='padding',\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#                                                                        num_workers=4, train_indicies=train_indicies,\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#                                                                        test_indicies=test_indicies, include_val=True)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m train_loader, val_loader, test_loader, train_indicies, val_indices, test_indicies \u001b[38;5;241m=\u001b[39m make_loader(\n\u001b[1;32m     33\u001b[0m     training_examples, lengths_list, is_sepsis, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding\u001b[39m\u001b[38;5;124m'\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m     34\u001b[0m     train_indicies\u001b[38;5;241m=\u001b[39mtrain_indicies, test_indicies\u001b[38;5;241m=\u001b[39mtest_indicies, val_indicies\u001b[38;5;241m=\u001b[39mval_indicies,\n\u001b[1;32m     35\u001b[0m     select_important_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, include_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "source": [
    "from train_gtn import initialize_experiment\n",
    "\n",
    "data_file = \"final_dataset.pickle\"\n",
    "training_examples, lengths_list, is_sepsis, writer, destination_path = initialize_experiment(data_file)\n",
    "\n",
    "sepsis = pd.Series(is_sepsis)\n",
    "positive_sepsis_idxs = sepsis[sepsis == 1].index\n",
    "negative_sepsis_idxs = sepsis[sepsis == 0].sample(frac=0.20).index\n",
    "all_samples = list(positive_sepsis_idxs) + list(negative_sepsis_idxs)\n",
    "np.random.shuffle(all_samples)\n",
    "\n",
    "print(f\"Number of positive samples: {len(positive_sepsis_idxs)}\")\n",
    "print(f\"Number of negative samples: {len(negative_sepsis_idxs)}\")\n",
    "\n",
    "# Reducing the samples to have balanced dataset\n",
    "batch_size = config['batch_size'] * torch.cuda.device_count()\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "logging.info(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Splitting dataset into train and test\n",
    "print(f\"Total samples: {len(all_samples)}\")\n",
    "\n",
    "train_indicies, temp_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)  # 80 20\n",
    "val_indicies, test_indicies = train_test_split(temp_indicies, test_size=0.5, random_state=42)  # 10 10\n",
    "\n",
    "# train_indicies, test_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)\n",
    "# train_loader, test_loader, train_indicies, test_indicies = make_loader(training_examples, lengths_list, is_sepsis,\n",
    "#                                                                        batch_size=batch_size, mode='padding',\n",
    "#                                                                        num_workers=4, train_indicies=train_indicies,\n",
    "#                                                                        test_indicies=test_indicies, include_val=True)\n",
    "\n",
    "train_loader, val_loader, test_loader, train_indicies, val_indices, test_indicies = make_loader(\n",
    "    training_examples, lengths_list, is_sepsis, batch_size=batch_size, mode='padding', num_workers=4,\n",
    "    train_indicies=train_indicies, test_indicies=test_indicies, val_indicies=val_indicies,\n",
    "    select_important_features=False, include_val=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ecfb77893c693c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e5bd12b226d91c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:51:57.149397Z",
     "start_time": "2024-07-31T21:51:55.635578Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = torch.stack([train_loader.dataset[i][0] for i in range(len(train_loader.dataset))])\n",
    "labels = torch.tensor([train_loader.dataset[i][1] for i in range(len(train_loader.dataset))])\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kfold.split(data):\n",
    "    \n",
    "    train_index = torch.tensor(train_index)\n",
    "    test_index = torch.tensor(test_index)\n",
    "    \n",
    "    X_train_fold = data[train_index]\n",
    "    y_train_fold = labels[train_index]\n",
    "    X_test_fold = data[test_index]\n",
    "    y_test_fold = labels[test_index]\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train_fold, y_train_fold), batch_size=3, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_fold, y_test_fold), batch_size=3, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf9b60fd596757ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:52:20.329957Z",
     "start_time": "2024-07-31T21:52:20.326873Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3c799f9da660755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:52:18.341874Z",
     "start_time": "2024-07-31T21:52:18.338976Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beb4aa61917bf718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:49:27.949814Z",
     "start_time": "2024-07-31T21:49:27.946561Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1696638fb5b8fa48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:49:12.950302Z",
     "start_time": "2024-07-31T21:49:12.949046Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "878ef6207dad6b3f",
   "metadata": {},
   "source": [
    "# TARNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4966ddb06fcf56e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:45.425151Z",
     "start_time": "2024-07-31T20:34:45.423390Z"
    }
   },
   "outputs": [],
   "source": [
    "# from models.tarnet.multitask_transformer_class import MultitaskTransformerModel\n",
    "# from train_tarnet import load_model\n",
    "# from utils.config import tarnet_param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6de76148dab21f25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:46.953439Z",
     "start_time": "2024-07-31T20:34:46.951277Z"
    }
   },
   "outputs": [],
   "source": [
    "# config = tarnet_param\n",
    "# (d_input, d_channel), d_output = (336, 191), 2\n",
    "# \n",
    "# model = MultitaskTransformerModel(task_type=config['task_type'], device=config['device'],\n",
    "#                                       nclasses=d_output, seq_len=d_input, batch=16,\n",
    "#                                       input_size=d_channel, emb_size=config['emb_size'],\n",
    "#                                       nhead=config['nhead'], nhid=config['nhid'], nhid_tar=config['nhid_tar'],\n",
    "#                                       nhid_task=config['nhid_task'], nlayers=config['nlayers'],\n",
    "#                                       dropout=config['dropout'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4b7dc0a583314b40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:48.536921Z",
     "start_time": "2024-07-31T20:34:48.535247Z"
    }
   },
   "outputs": [],
   "source": [
    "# load_model(model, model_name='./saved_models/tarnet/tarnet_final_2_val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "10e9c4fd2b2f5dec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:50.266070Z",
     "start_time": "2024-07-31T20:34:50.263642Z"
    }
   },
   "outputs": [],
   "source": [
    "# from train_tarnet import initialize_experiment\n",
    "# \n",
    "# # Getting Data and Loaders\n",
    "# data_file = \"final_dataset.pickle\"\n",
    "# training_examples, lengths_list, is_sepsis, writer, destination_path = initialize_experiment(data_file)\n",
    "# \n",
    "# sepsis = pd.Series(is_sepsis)\n",
    "# positive_sepsis_idxs = sepsis[sepsis == 1].index\n",
    "# negative_sepsis_idxs = sepsis[sepsis == 0].sample(frac=0.20).index\n",
    "# all_samples = list(positive_sepsis_idxs) + list(negative_sepsis_idxs)\n",
    "# np.random.shuffle(all_samples)\n",
    "# \n",
    "# logging.info(f\"Number of positive samples: {len(positive_sepsis_idxs)}\")\n",
    "# logging.info(f\"Number of negative samples: {len(negative_sepsis_idxs)}\")\n",
    "# \n",
    "# # Reducing the samples to have balanced dataset\n",
    "# batch_size = config['batch'] * torch.cuda.device_count()\n",
    "# print(f\"Batch size: {batch_size}\")\n",
    "# logging.info(f\"Batch size: {batch_size}\")\n",
    "# \n",
    "# # Splitting dataset into train and test\n",
    "# logging.info(f\"Total samples: {len(all_samples)}\")\n",
    "# \n",
    "# train_indicies, temp_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)  # 80 20\n",
    "# val_indicies, test_indicies = train_test_split(temp_indicies, test_size=0.5, random_state=42)  # 10 10\n",
    "# \n",
    "# train_loader, val_loader, test_loader, train_indicies, val_indices, test_indicies = make_loader(\n",
    "#     training_examples, lengths_list, is_sepsis, batch_size=1, mode='padding', num_workers=4,\n",
    "#     train_indicies=train_indicies, test_indicies=test_indicies, val_indicies=val_indicies,\n",
    "#     select_important_features=False, include_val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2892a08a6454f9ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:51.858107Z",
     "start_time": "2024-07-31T20:34:51.856193Z"
    }
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "# import torch.nn.functional as F\n",
    "# \n",
    "# targets_list = []\n",
    "# predictions = []\n",
    "# probas = []\n",
    "# \n",
    "# def make_perfect_batch(X, num_inst, num_samples):\n",
    "#     extension = np.zeros((num_samples - num_inst, X.shape[1], X.shape[2]))\n",
    "#     X = np.concatenate((X, extension), axis=0)\n",
    "#     return X\n",
    "# \n",
    "# def tarnet_preprocessing(patient_data):\n",
    "#     # print(patient_data.shape, type(patient_data))\n",
    "#     patient_data = patient_data.detach().cpu().numpy()\n",
    "#     # print(patient_data.shape, type(patient_data))\n",
    "#     num_train_inst = patient_data.shape[0]\n",
    "#     num_train_samples = math.ceil(num_train_inst / 16) * 16  # Original model batch_size was 16\n",
    "#     patient_data = make_perfect_batch(patient_data, num_train_inst, num_train_samples)\n",
    "#     # print(patient_data.shape, type(patient_data))\n",
    "#     \n",
    "#     return torch.as_tensor(patient_data).float()\n",
    "# \n",
    "# for patient_data, targets in tqdm.tqdm(val_loader):\n",
    "#     patient_data = tarnet_preprocessing(patient_data)\n",
    "#     with torch.no_grad():\n",
    "#         patient_data = patient_data.to(device)\n",
    "#         outputs, _ = model(patient_data, task_type='classification')\n",
    "#         # outputs = outputs[0]\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         probabilities = F.softmax(outputs, dim=1)\n",
    "#     \n",
    "#         predicted_class = predicted.detach().cpu().numpy()[0]\n",
    "# \n",
    "#         predictions.append(predicted_class)\n",
    "#         targets_list.append(targets.detach().cpu().numpy()[0])\n",
    "#         probas.append(probabilities.detach().cpu().numpy()[0][predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "feaa3cf2a7b64fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:25:25.361007Z",
     "start_time": "2024-07-31T20:25:25.359639Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
