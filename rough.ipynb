{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T16:19:26.655511Z",
     "start_time": "2024-09-02T16:19:26.653489Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:19:28.720191Z",
     "start_time": "2024-09-02T16:19:26.657340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from utils.path_utils import project_root\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n"
   ],
   "id": "e26363a27c9bea16",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:19:28.723130Z",
     "start_time": "2024-09-02T16:19:28.721470Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "147b2445b4d4320e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:20:20.111693Z",
     "start_time": "2024-09-02T16:19:28.723928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def csv_to_pt():\n",
    "    patient_dir = os.path.join(project_root(), 'data', 'pt_files')\n",
    "    patient_files = sorted(os.listdir(patient_dir))\n",
    "    \n",
    "    lengths = pd.read_csv(os.path.join(project_root(), 'data', 'processed', 'lengths.txt'), header=None).values\n",
    "    is_sepsis = pd.read_csv(os.path.join(project_root(), 'data', 'processed', 'is_sepsis.txt'), header=None).values\n",
    "    \n",
    "    all_patients = {'samples': [], 'labels': []}\n",
    "    \n",
    "    max_time_step = 336\n",
    "    for idx, (file_name, length, sepsis) in tqdm.tqdm(enumerate(zip(patient_files, lengths, is_sepsis)), \n",
    "                                                      desc=\"Converting csv to .pt format: \", \n",
    "                                                      total=len(patient_files)):\n",
    "        \n",
    "        file = pd.read_csv(os.path.join(patient_dir, file_name))\n",
    "        \n",
    "        pad_width = ((0, max_time_step - len(file)), (0, 0))\n",
    "        file = np.pad(file, pad_width=pad_width, mode='constant').astype(np.float32)\n",
    "        \n",
    "        if len(file) == max_time_step:\n",
    "            all_patients['samples'].append(torch.from_numpy(file).unsqueeze(0))\n",
    "            all_patients['labels'].append(torch.tensor(sepsis[0], dtype=torch.float32).unsqueeze(0))\n",
    "        else:\n",
    "            raise ValueError(f\"Length {length} does not match length of patient {file_name} with length {len(file)}\")\n",
    "    \n",
    "    print('samples: ', type(all_patients['samples']), 'labels: ', type(all_patients['labels']))\n",
    "    \n",
    "    all_patients['samples'] = torch.cat(all_patients['samples'], dim=0)\n",
    "    all_patients['labels'] = torch.cat(all_patients['labels'], dim=0)\n",
    "    \n",
    "    return {'samples': all_patients['samples'], 'labels': all_patients['labels']}, lengths, is_sepsis\n",
    "\n",
    "all_patients, lengths, is_sepsis = csv_to_pt()\n"
   ],
   "id": "2ad9bf660da0bf34",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting csv to .pt format: 100%|██████████| 20336/20336 [00:49<00:00, 407.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples:  <class 'list'> labels:  <class 'list'>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:20:20.114982Z",
     "start_time": "2024-09-02T16:20:20.113213Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ece82e7182676bb3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:20:20.117047Z",
     "start_time": "2024-09-02T16:20:20.115686Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "88ed86241acaedcf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Masking Original TimeSeries",
   "id": "c17ac44d92cc8dcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:20:20.125589Z",
     "start_time": "2024-09-02T16:20:20.117769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def geom_noise_mask_single(L, lm, masking_ratio):\n",
    "    \"\"\"\n",
    "    Randomly create a boolean mask of length `L`, consisting of subsequences of average length lm, masking with 0s a `masking_ratio`\n",
    "    proportion of the sequence L. The length of masking subsequences and intervals follow a geometric distribution.\n",
    "    Args:\n",
    "        L: length of mask and sequence to be masked\n",
    "        lm: average length of masking subsequences (streaks of 0s)\n",
    "        masking_ratio: proportion of L to be masked\n",
    "    Returns:\n",
    "        (L, ) boolean numpy array intended to mask ('drop') with 0s a sequence of length L\n",
    "    \"\"\"\n",
    "    keep_mask = np.ones(L, dtype=bool)\n",
    "    p_m = 1 / lm  # probability of each masking sequence stopping. parameter of geometric distribution.\n",
    "    p_u = p_m * masking_ratio / (\n",
    "            1 - masking_ratio)  # probability of each unmasked sequence stopping. parameter of geometric distribution.\n",
    "    p = [p_m, p_u]\n",
    "\n",
    "    # Start in state 0 with masking_ratio probability\n",
    "    state = int(np.random.rand() > masking_ratio)  # state 0 means masking, 1 means not masking\n",
    "    for i in range(L):\n",
    "        keep_mask[i] = state  # here it happens that state and masking value corresponding to state are identical\n",
    "        if np.random.rand() < p[state]:\n",
    "            state = 1 - state\n",
    "\n",
    "    return keep_mask\n",
    "\n",
    "\n",
    "def noise_mask(X, masking_ratio=0.25, lm=3, distribution='geometric', exclude_feats=None):\n",
    "    \"\"\"\n",
    "    Creates a random boolean mask of the same shape as X, with 0s at places where a feature should be masked.\n",
    "    Args:\n",
    "        X: (seq_length, feat_dim) numpy array of features corresponding to a single sample\n",
    "        masking_ratio: proportion of seq_length to be masked. At each time step, will also be the proportion of\n",
    "            feat_dim that will be masked on average\n",
    "        lm: average length of masking subsequences (streaks of 0s). Used only when `distribution` is 'geometric'.\n",
    "        distribution: whether each mask sequence element is sampled independently at random, or whether\n",
    "            sampling follows a markov chain (and thus is stateful), resulting in geometric distributions of\n",
    "            masked squences of a desired mean length `lm`\n",
    "        exclude_feats: iterable of indices corresponding to features to be excluded from masking (i.e. to remain all 1s)\n",
    "    Returns:\n",
    "        boolean numpy array with the same shape as X, with 0s at places where a feature should be masked\n",
    "    \"\"\"\n",
    "    if exclude_feats is not None:\n",
    "        exclude_feats = set(exclude_feats)\n",
    "\n",
    "    if distribution == 'geometric':  # stateful (Markov chain)\n",
    "        mask = geom_noise_mask_single(X.shape[0] * X.shape[1] * X.shape[2], lm, masking_ratio)\n",
    "        mask = mask.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "        \n",
    "    elif distribution == 'masked_tail':\n",
    "        mask = np.ones(X.shape, dtype=bool)\n",
    "        for m in range(X.shape[0]):  # feature dimension\n",
    "\n",
    "            keep_mask = np.zeros_like(mask[m, :], dtype=bool)\n",
    "            n = math.ceil(keep_mask.shape[1] * (1 - masking_ratio))\n",
    "            keep_mask[:, :n] = True\n",
    "            mask[m, :] = keep_mask  # time dimension\n",
    "            \n",
    "    elif distribution == 'masked_head':\n",
    "        mask = np.ones(X.shape, dtype=bool)\n",
    "        for m in range(X.shape[0]):  # feature dimension\n",
    "\n",
    "            keep_mask = np.zeros_like(mask[m, :], dtype=bool)\n",
    "            n = math.ceil(keep_mask.shape[1] * masking_ratio)\n",
    "            keep_mask[:, n:] = True\n",
    "            mask[m, :] = keep_mask  # time dimension\n",
    "    else:  # each position is independent Bernoulli with p = 1 - masking_ratio\n",
    "        mask = np.random.choice(np.array([True, False]), size=X.shape, replace=True,\n",
    "                                p=(1 - masking_ratio, masking_ratio))\n",
    "\n",
    "    return torch.tensor(mask)\n",
    "\n",
    "def data_transform_masked4cl(sample, masking_ratio, lm, positive_nums=None, distribution='geometric'):\n",
    "    \"\"\"Masked time series in time dimension\"\"\"\n",
    "\n",
    "    if positive_nums is None:\n",
    "        positive_nums = math.ceil(1.5 / (1 - masking_ratio))\n",
    "        \n",
    "    sample = sample.permute(0, 2, 1)  # (batch_size, channels, time_steps)\n",
    "    \n",
    "    # Creating the batch in #positive_nums sets\n",
    "    sample_repeat = sample.repeat(positive_nums, 1, 1)  # (batch_size*positive_num, channels, time steps)\n",
    "\n",
    "    mask = noise_mask(sample_repeat, masking_ratio, lm, distribution=distribution)\n",
    "    x_masked = mask * sample_repeat\n",
    "\n",
    "    return x_masked.permute(0, 2, 1), mask.permute(0, 2, 1)\n",
    "\n",
    "# data_masked_m, mask = data_transform_masked4cl(all_patients['samples'][:32], 0.5, 3, positive_nums=1, distribution='geometric')\n"
   ],
   "id": "39b99ebf08996363",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:20:20.127680Z",
     "start_time": "2024-09-02T16:20:20.126305Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "301347dc5cda9e71",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T16:20:20.142242Z",
     "start_time": "2024-09-02T16:20:20.128347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Load_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, TSlength_aligned, training_mode, target_dataset_size=64, subset=False):\n",
    "        \n",
    "        super(Load_Dataset, self).__init__()\n",
    "        self.training_mode = training_mode\n",
    "        \n",
    "        X_train = dataset[\"samples\"]\n",
    "        y_train = dataset[\"labels\"]\n",
    "        \n",
    "        # shuffle\n",
    "        data = list(zip(X_train, y_train))\n",
    "        np.random.shuffle(data)\n",
    "        \n",
    "        X_train, y_train = zip(*data)\n",
    "        X_train, y_train = torch.stack(list(X_train), dim=0), torch.stack(list(y_train), dim=0)\n",
    "\n",
    "        if len(X_train.shape) < 3:\n",
    "            X_train = X_train.unsqueeze(2)\n",
    "\n",
    "        if X_train.shape.index(min(X_train.shape)) != 1:  # make sure the Channels in second dim\n",
    "            X_train = X_train.permute(0, 2, 1)\n",
    "\n",
    "        \"\"\"Align the TS length between source and target datasets\"\"\"\n",
    "        # X_train = X_train[:, :1, :int(config.TSlength_aligned)] # take the first 178 samples\n",
    "        X_train = X_train[:, :, :int(TSlength_aligned)]\n",
    "\n",
    "        \"\"\"Subset for debugging\"\"\"\n",
    "        if subset == True:\n",
    "            \n",
    "            subset_size = target_dataset_size *10\n",
    "            \n",
    "            \"\"\"if the dimension is larger than 178, take the first 178 dimensions. \n",
    "                If multiple channels, take the first channel\"\"\"\n",
    "            X_train = X_train[:subset_size] \n",
    "            y_train = y_train[:subset_size]\n",
    "\n",
    "        if isinstance(X_train, np.ndarray):\n",
    "            self.x_data = torch.from_numpy(X_train)\n",
    "            self.y_data = torch.from_numpy(y_train).long()\n",
    "        else:\n",
    "            self.x_data = X_train\n",
    "            self.y_data = y_train\n",
    "\n",
    "        self.len = X_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    "
   ],
   "id": "deddd883436b6d11",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:03:21.230107Z",
     "start_time": "2024-09-02T17:03:21.228278Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8195ca24684c25d1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:03:26.083433Z",
     "start_time": "2024-09-02T17:03:23.696376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sepsis_data = Load_Dataset(all_patients, TSlength_aligned=300, training_mode='pre_train', \n",
    "                           target_dataset_size=64, subset=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=sepsis_data, batch_size=32, shuffle=True, \n",
    "                                           drop_last=True, num_workers=4)\n",
    "\n",
    "for i, j in train_loader:\n",
    "    \n",
    "    break\n",
    "\n",
    "print(i.shape)\n"
   ],
   "id": "609f3108110422e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 133, 300])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b3c53277fbd6e071",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Args",
   "id": "66c8d4e9473a73ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:10:21.371693Z",
     "start_time": "2024-09-02T17:10:21.364915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "parser.add_argument('--run_description', default='run1', type=str, help='Experiment Description')\n",
    "parser.add_argument('--seed', default=2023, type=int, help='seed value')\n",
    "\n",
    "parser.add_argument('--training_mode', default='pre_train', type=str, help='pre_train, fine_tune')\n",
    "parser.add_argument('--pretrain_dataset', default='SleepEEG', type=str,\n",
    "                    help='Dataset of choice: SleepEEG, FD_A, HAR, ECG')\n",
    "parser.add_argument('--target_dataset', default='Epilepsy', type=str,\n",
    "                    help='Dataset of choice: Epilepsy, FD_B, Gesture, EMG')\n",
    "\n",
    "parser.add_argument('--logs_save_dir', default='experiments_logs', type=str, help='saving directory')\n",
    "parser.add_argument('--device', default='cuda', type=str, help='cpu or cuda')\n",
    "parser.add_argument('--home_path', default=home_dir, type=str, help='Project home directory')\n",
    "parser.add_argument('--subset', action='store_true', default=False, help='use the subset of datasets')\n",
    "parser.add_argument('--log_epoch', default=5, type=int, help='print loss and metrix')\n",
    "parser.add_argument('--draw_similar_matrix', default=10, type=int, help='draw similarity matrix')\n",
    "parser.add_argument('--pretrain_lr', default=0.0001, type=float, help='pretrain learning rate')\n",
    "parser.add_argument('--lr', default=0.0001, type=float, help='learning rate')\n",
    "parser.add_argument('--use_pretrain_epoch_dir', default=None, type=str,\n",
    "                    help='choose the pretrain checkpoint to finetune')\n",
    "parser.add_argument('--pretrain_epoch', default=10, type=int, help='pretrain epochs')\n",
    "parser.add_argument('--finetune_epoch', default=300, type=int, help='finetune epochs')\n",
    "\n",
    "parser.add_argument('--masking_ratio', default=0.5, type=float, help='masking ratio')\n",
    "parser.add_argument('--positive_nums', default=3, type=int, help='positive series numbers')\n",
    "parser.add_argument('--lm', default=3, type=int, help='average masked lenght')\n",
    "\n",
    "parser.add_argument('--finetune_result_file_name', default=\"finetune_result.json\", type=str,\n",
    "                    help='finetune result json name')\n",
    "parser.add_argument('--temperature', type=float, default=0.2, help='temperature')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n"
   ],
   "id": "d55b734acc0f3b19",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:51:59.793685Z",
     "start_time": "2024-09-02T17:51:59.790909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Pre-training\n",
    "        self.input_channels = 133\n",
    "        self.kernel_size = 3\n",
    "        self.stride = 3\n",
    "        self.dropout = 0.2\n",
    "        self.final_out_channels = 2\n",
    "        self.CNNoutput_channel = 10\n",
    "        \n",
    "        # Optimizer\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.99\n",
    "    "
   ],
   "id": "fff3a558ae05f7ca",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:51:59.952261Z",
     "start_time": "2024-09-02T17:51:59.950737Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1b3a67e06cbe3348",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:52:00.116723Z",
     "start_time": "2024-09-02T17:52:00.115256Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5d967ff710ae5592",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Pre-Training",
   "id": "13dc8785031975e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:52:00.408941Z",
     "start_time": "2024-09-02T17:52:00.405328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model_pretrain(model, model_optimizer, model_scheduler, train_loader, configs, args, device):\n",
    "    total_loss = []\n",
    "    total_cl_loss = []\n",
    "    total_rb_loss = []\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):  # data shape: (batch_size, seqs, channels)\n",
    "\n",
    "        model_optimizer.zero_grad()\n",
    "\n",
    "        # When masking, data is reshaped to (batch_size, channel, seqs) - Inside the data_transform_masked4cl()\n",
    "        data_masked_m, mask = data_transform_masked4cl(data, args.masking_ratio, args.lm, args.positive_nums)\n",
    "        data_masked_om = torch.cat([data, data_masked_m], 0)  # (batch_size, seqs, channels)\n",
    "\n",
    "        data, labels, data_masked_om = data.float().to(device), labels.float().to(device), data_masked_om.float().to(\n",
    "            device)\n",
    "\n",
    "        # Produce embeddings of original and masked samples  (data_masked_om = data samples + masked samples)\n",
    "        loss, loss_cl, loss_rb = model(data_masked_om, pretrain=True)\n",
    "        \n",
    "        return loss, loss_cl, loss_rb\n",
    "\n",
    "    #     loss.backward()\n",
    "    #     model_optimizer.step()\n",
    "    # \n",
    "    #     total_loss.append(loss.item())\n",
    "    #     total_cl_loss.append(loss_cl.item())\n",
    "    #     total_rb_loss.append(loss_rb.item())\n",
    "    # \n",
    "    # total_loss = torch.tensor(total_loss).mean()\n",
    "    # total_cl_loss = torch.tensor(total_cl_loss).mean()\n",
    "    # total_rb_loss = torch.tensor(total_rb_loss).mean()\n",
    "    # \n",
    "    # model_scheduler.step()\n",
    "    # \n",
    "    # return total_loss, total_cl_loss, total_rb_loss\n"
   ],
   "id": "c1a18f67ea45e27f",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:52:00.543056Z",
     "start_time": "2024-09-02T17:52:00.541523Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d2e21d8f9785d6ec",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:52:03.033891Z",
     "start_time": "2024-09-02T17:52:00.666736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from simmtm.model import TFC\n",
    "\n",
    "configs = Config()\n",
    "\n",
    "model = TFC(configs, args).to('cuda')\n",
    "# print(model)\n",
    "\n",
    "# Pre-Training\n",
    "params_group = [{'params': model.parameters()}]\n",
    "model_optimizer = torch.optim.Adam(params_group, lr=args.pretrain_lr, betas=(configs.beta1, configs.beta2),\n",
    "                                       weight_decay=0)\n",
    "model_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=model_optimizer, T_max=args.pretrain_epoch)\n",
    "loss, loss_cl, loss_rb = model_pretrain(model=model, model_optimizer=model_optimizer, model_scheduler=model_scheduler, \n",
    "               train_loader=train_loader, configs=configs, args=args, device='cuda')\n",
    "\n"
   ],
   "id": "89389fe792518b1c",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x450 and 30x256)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[82], line 13\u001B[0m\n\u001B[1;32m     10\u001B[0m model_optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(params_group, lr\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mpretrain_lr, betas\u001B[38;5;241m=\u001B[39m(configs\u001B[38;5;241m.\u001B[39mbeta1, configs\u001B[38;5;241m.\u001B[39mbeta2),\n\u001B[1;32m     11\u001B[0m                                        weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     12\u001B[0m model_scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mCosineAnnealingLR(optimizer\u001B[38;5;241m=\u001B[39mmodel_optimizer, T_max\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mpretrain_epoch)\n\u001B[0;32m---> 13\u001B[0m loss, loss_cl, loss_rb \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_pretrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_optimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_scheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_scheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m               \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfigs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfigs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[81], line 19\u001B[0m, in \u001B[0;36mmodel_pretrain\u001B[0;34m(model, model_optimizer, model_scheduler, train_loader, configs, args, device)\u001B[0m\n\u001B[1;32m     15\u001B[0m data, labels, data_masked_om \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device), data_masked_om\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(\n\u001B[1;32m     16\u001B[0m     device)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Produce embeddings of original and masked samples  (data_masked_om = data samples + masked samples)\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m loss, loss_cl, loss_rb \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_masked_om\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss, loss_cl, loss_rb\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/SepsisEarlyPrediction/simmtm/model.py:56\u001B[0m, in \u001B[0;36mTFC.forward\u001B[0;34m(self, x_in_t, pretrain)\u001B[0m\n\u001B[1;32m     53\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv_block3(x)\n\u001B[1;32m     55\u001B[0m h \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 56\u001B[0m z \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m loss_cl, similarity_matrix, logits, positives_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrastive(z)\n\u001B[1;32m     59\u001B[0m rebuild_weight_matrix, agg_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregation(similarity_matrix, x)\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/work/pi_mshao_umassd_edu/neeresh/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (128x450 and 30x256)"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:52:23.010931Z",
     "start_time": "2024-09-02T17:52:23.007632Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "94794824ffd50059",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFC(\n",
       "  (conv_block1): Sequential(\n",
       "    (0): Conv1d(133, 32, kernel_size=(3,), stride=(3,), padding=(1,), bias=False)\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (conv_block2): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(8,), stride=(1,), padding=(4,), bias=False)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block3): Sequential(\n",
       "    (0): Conv1d(64, 30, kernel_size=(8,), stride=(1,), padding=(4,), bias=False)\n",
       "    (1): BatchNorm1d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (awl): AutomaticWeightedLoss()\n",
       "  (contrastive): ContrastiveWeight(\n",
       "    (bce): BCELoss()\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (log_softmax): LogSoftmax(dim=-1)\n",
       "    (kl): KLDivLoss()\n",
       "  )\n",
       "  (aggregation): AggregationRebuild(\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (mse): MSELoss()\n",
       "  )\n",
       "  (head): Linear(in_features=1280, out_features=178, bias=True)\n",
       "  (mse): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a08a769ea41bc7a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:22:08.003548Z",
     "start_time": "2024-09-02T17:22:08.001942Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b4e4fda35fd0973b",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:22:03.836194Z",
     "start_time": "2024-09-02T17:22:03.834459Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e09ad1aa068e7d8b",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:22:04.672032Z",
     "start_time": "2024-09-02T17:22:04.670301Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6e6b8b9870bb54d0",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "39a003fd38a238b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SleepEEG",
   "id": "4ef30dea811e5cba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T17:47:28.511159Z",
     "start_time": "2024-09-02T17:47:28.508951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from simmtm.config_files.SleepEEG_Configs import Config \n",
    "# \n",
    "# original_configs = Config()\n",
    "# model = TFC(original_configs, args)\n",
    "# \n",
    "# model"
   ],
   "id": "62d530a67b8fdcbb",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3f026f25f30fc783",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# datasetpath = os.path.join(project_root(), 'data', 'simmtm_datasets', 'datasets', 'classification', 'dataset', 'Gesture', 'train.pt')\n",
    "# print(datasetpath)\n",
    "# \n",
    "# samples = torch.load(datasetpath)['samples']\n",
    "# labels = torch.load(datasetpath)['labels']\n",
    "# \n",
    "# print(type(samples), samples.shape)\n",
    "# print(type(labels), labels.shape)\n",
    "\n",
    "# data=Load_Dataset(dataset=torch.load(datasetpath), TSlength_aligned=178, training_mode='', target_dataset_size=64, subset=False)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=data, batch_size=32, shuffle=True, \n",
    "#                                            drop_last=True, num_workers=0)\n",
    "# for i, j in train_loader:\n",
    "#     break\n",
    "#     \n",
    "# print(i.shape)\n"
   ],
   "id": "ea9d9cd093f0a7dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ad4d8ac82a718218",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e6a276889fd6b55",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
