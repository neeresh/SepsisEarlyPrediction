{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-15T07:21:16.528424Z",
     "start_time": "2024-09-15T07:21:16.526913Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "initial_id",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T03:05:41.742040Z",
     "start_time": "2024-09-17T03:05:37.831713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from utils.path_utils import project_root\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n"
   ],
   "id": "e26363a27c9bea16",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T07:21:20.002992Z",
     "start_time": "2024-09-15T07:21:20.001272Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "35310e36b03c6b19",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T06:35:31.802255Z",
     "start_time": "2024-09-15T06:34:08.242344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.pretrain_utils.data import get_pretrain_finetune_test_datasets\n",
    "\n",
    "pt_train, finetune, test = get_pretrain_finetune_test_datasets()"
   ],
   "id": "9a29c339fca5d558",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T06:37:22.441190Z",
     "start_time": "2024-09-15T06:37:22.439357Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9b37998e87bf5872",
   "execution_count": 44,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T06:49:52.473939Z",
     "start_time": "2024-09-15T06:49:52.472098Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5233f8fc26cbe6fb",
   "execution_count": 51,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T06:40:11.194256Z",
     "start_time": "2024-09-15T06:40:11.192537Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e2a43b014aa8152d",
   "execution_count": 50,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T18:22:15.389626Z",
     "start_time": "2024-09-23T18:22:15.136683Z"
    }
   },
   "cell_type": "code",
   "source": "!sbatch eval_simmtm.job",
   "id": "2f58dbfac2ed3df3",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:06:47.919688Z",
     "start_time": "2024-09-15T02:06:47.917946Z"
    }
   },
   "cell_type": "code",
   "source": "-",
   "id": "26f22e2c11ae962d",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "711daf7b9fb53cc3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Args",
   "id": "f4d653dde45d4dc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "parser.add_argument('--run_description', default='run1', type=str, help='Experiment Description')\n",
    "parser.add_argument('--seed', default=2023, type=int, help='seed value')\n",
    "\n",
    "parser.add_argument('--training_mode', default='pre_train', type=str, help='pre_train, fine_tune')\n",
    "parser.add_argument('--pretrain_dataset', default='SleepEEG', type=str,\n",
    "                    help='Dataset of choice: SleepEEG, FD_A, HAR, ECG')\n",
    "parser.add_argument('--target_dataset', default='Epilepsy', type=str,\n",
    "                    help='Dataset of choice: Epilepsy, FD_B, Gesture, EMG')\n",
    "\n",
    "parser.add_argument('--logs_save_dir', default='experiments_logs', type=str, help='saving directory')\n",
    "parser.add_argument('--device', default='cuda', type=str, help='cpu or cuda')\n",
    "parser.add_argument('--home_path', default=home_dir, type=str, help='Project home directory')\n",
    "parser.add_argument('--subset', action='store_true', default=False, help='use the subset of datasets')\n",
    "parser.add_argument('--log_epoch', default=5, type=int, help='print loss and metrix')\n",
    "parser.add_argument('--draw_similar_matrix', default=10, type=int, help='draw similarity matrix')\n",
    "parser.add_argument('--pretrain_lr', default=0.0001, type=float, help='pretrain learning rate')\n",
    "parser.add_argument('--lr', default=0.0001, type=float, help='learning rate')\n",
    "parser.add_argument('--use_pretrain_epoch_dir', default=None, type=str,\n",
    "                    help='choose the pretrain checkpoint to finetune')\n",
    "parser.add_argument('--pretrain_epoch', default=10, type=int, help='pretrain epochs')\n",
    "parser.add_argument('--finetune_epoch', default=300, type=int, help='finetune epochs')\n",
    "\n",
    "parser.add_argument('--masking_ratio', default=0.5, type=float, help='masking ratio')\n",
    "parser.add_argument('--positive_nums', default=3, type=int, help='positive series numbers')\n",
    "parser.add_argument('--lm', default=3, type=int, help='average masked lenght')\n",
    "\n",
    "parser.add_argument('--finetune_result_file_name', default=\"finetune_result.json\", type=str,\n",
    "                    help='finetune result json name')\n",
    "parser.add_argument('--temperature', type=float, default=0.2, help='temperature')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n"
   ],
   "id": "8f0f9109afd5d6f0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f43119c437903e8c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert csv to pt",
   "id": "2bae8b6156fcaa81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def csv_to_pt(patient_files, lengths, is_sepsis, desc):\n",
    "    \n",
    "    all_patients = {'samples': [], 'labels': []}\n",
    "    \n",
    "    max_time_step = 336\n",
    "    # print(len(patient_files), len(lengths), len(is_sepsis))\n",
    "    for idx, (file, length, sepsis) in tqdm.tqdm(enumerate(zip(patient_files, lengths, is_sepsis)), \n",
    "                                                      desc=f\"{desc}\", \n",
    "                                                      total=len(patient_files)):\n",
    "        \n",
    "        pad_width = ((0, max_time_step - len(file)), (0, 0))\n",
    "        file = np.pad(file, pad_width=pad_width, mode='constant').astype(np.float32)\n",
    "        \n",
    "        if len(file) == max_time_step:\n",
    "            all_patients['samples'].append(torch.from_numpy(file).unsqueeze(0))\n",
    "            all_patients['labels'].append(torch.tensor(sepsis, dtype=torch.float32).unsqueeze(0))\n",
    "        else:\n",
    "            raise ValueError(f\"Length {length} does not match length of patient {idx} with length {len(file)}\")\n",
    "    \n",
    "    # print('samples: ', type(all_patients['samples']), 'labels: ', type(all_patients['labels']))\n",
    "    \n",
    "    all_patients['samples'] = torch.cat(all_patients['samples'], dim=0)\n",
    "    all_patients['labels'] = torch.cat(all_patients['labels'], dim=0)\n",
    "    \n",
    "    return {'samples': all_patients['samples'], 'labels': all_patients['labels']}, lengths, is_sepsis\n",
    "\n",
    "# all_patients, lengths, is_sepsis = csv_to_pt()\n"
   ],
   "id": "123cbaf79652006c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "43753974148ee5d9",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_train_val_test_indices(sepsis_file, dset, save_distributions=True):\n",
    "    \n",
    "    sepsis = pd.read_csv(os.path.join(project_root(), 'data', 'tl_datasets', f'{sepsis_file}'), header=None)\n",
    "    \n",
    "    train_indices, val_indices = train_test_split(sepsis, test_size=0.2, random_state=2024)\n",
    "    \n",
    "    train_indices = train_indices.index.values\n",
    "    val_indices = val_indices.index.values\n",
    "    \n",
    "    \n",
    "    if save_distributions:\n",
    "        train_dist = sepsis.iloc[train_indices].value_counts()\n",
    "        val_dist = sepsis.iloc[val_indices].value_counts()\n",
    "        \n",
    "        train_dist_percentage = np.round(train_dist / len(sepsis.iloc[train_indices]), 2)\n",
    "        val_dist_percentage = np.round(val_dist / len(sepsis.iloc[val_indices]), 2)\n",
    "        \n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                'Train Images': train_dist, 'Validation Images': val_dist,\n",
    "                'Train Distribution Percentage': train_dist_percentage, 'Validation Distribution Percentage': val_dist_percentage,\n",
    "            }\n",
    "        ).to_csv(os.path.join(project_root(), 'results', f'distributions{dset}.csv'), index=False)\n",
    "        \n",
    "        # pd.read_csv(os.path.join(project_root(), 'results', 'distributions.csv'))\n",
    "        \n",
    "    return train_indices, val_indices\n"
   ],
   "id": "717b9505d28c8ee8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "10aee72c9dbf0a4a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Datasetup",
   "id": "fbb5c03280f398db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_pretrain_finetune_datasets():\n",
    "    \n",
    "    # Pre-training Indices\n",
    "    pt_train_indices, pt_val_indices = get_train_val_test_indices(\n",
    "        sepsis_file='is_sepsis_pretrain_A.txt', save_distributions=True,\n",
    "        dset='Aa')\n",
    "    \n",
    "    # Gathering files, lengths, and sepsis label\n",
    "    pt_files = pd.read_pickle(os.path.join(project_root(), 'data', 'tl_datasets', 'final_dataset_pretrain_A.pickle'))\n",
    "    pt_lengths = pd.read_csv(os.path.join(project_root(), 'data', 'tl_datasets', 'lengths_pretrain_A.txt'), \n",
    "                             header=None)\n",
    "    pt_sepsis = pd.read_csv(os.path.join(project_root(), 'data', 'tl_datasets', 'is_sepsis_pretrain_A.txt'),\n",
    "                            header=None)\n",
    "    \n",
    "    # Checking whether the files are in same order or not\n",
    "    pretrain_files = []\n",
    "    for pdata, length in tqdm.tqdm(zip(pt_files, pt_lengths.values), desc=\"Checking Pre-training & Validation Files\", \n",
    "                                   total=len(pt_files)):\n",
    "        plength = len(pdata) \n",
    "        assert plength == length[0], f\"{plength} doesn't match {length}\"\n",
    "        pretrain_files.append(pdata.drop(['PatientID', 'SepsisLabel'], axis=1))\n",
    "    \n",
    "    # Getting train and val\n",
    "    pt_train = [pretrain_files[i] for i in pt_train_indices]\n",
    "    pt_val = [pretrain_files[i] for i in pt_val_indices]\n",
    "    \n",
    "    pt_train_lengths = pt_lengths.iloc[pt_train_indices].values\n",
    "    pt_val_lengths = pt_lengths.iloc[pt_val_indices].values\n",
    "    \n",
    "    pt_train_sepsis = pt_sepsis.iloc[pt_train_indices].values\n",
    "    pt_val_sepsis = pt_sepsis.iloc[pt_val_indices].values\n",
    "    \n",
    "    pt_train, pt_train_lengths, pt_train_sepsis = csv_to_pt(pt_train, pt_train_lengths, pt_train_sepsis, desc='PT Train Set')\n",
    "    pt_val, pt_val_lengths, pt_val_sepsis = csv_to_pt(pt_val, pt_val_lengths, pt_val_sepsis, desc='PT Validation Set')\n",
    "    \n",
    "    # Fine-tuning\n",
    "    test_indices, finetune_indices = get_train_val_test_indices(\n",
    "        sepsis_file='is_sepsis_finetune_B.txt', save_distributions=True,\n",
    "        dset='Bb')\n",
    "    \n",
    "    # Gathering files, lengths, and sepsis label\n",
    "    test_setB = pd.read_pickle(os.path.join(project_root(), 'data', 'tl_datasets', 'final_dataset_finetune_B.pickle'))\n",
    "    test_setB_lengths = pd.read_csv(os.path.join(project_root(), 'data', 'tl_datasets', 'lengths_finetune_B.txt'), \n",
    "                             header=None)\n",
    "    test_setB_sepsis = pd.read_csv(os.path.join(project_root(), 'data', 'tl_datasets', 'is_sepsis_finetune_B.txt'),\n",
    "                            header=None)\n",
    "    \n",
    "    # Checking whether the files are in same order or not\n",
    "    test_files = []\n",
    "    for pdata, length in tqdm.tqdm(zip(test_setB, test_setB_lengths.values), desc=\"Checking Fine-tuning & Test Files\",\n",
    "                                   total=len(test_setB)):\n",
    "        plength = len(pdata) \n",
    "        assert plength == length[0], f\"{plength} doesn't match {length}\"\n",
    "        test_files.append(pdata.drop(['PatientID', 'SepsisLabel'], axis=1))\n",
    "    \n",
    "    # Getting finetune and test sets\n",
    "    finetune = [test_files[i] for i in finetune_indices]\n",
    "    test = [test_files[i] for i in test_indices]\n",
    "    \n",
    "    finetune_lengths = test_setB_lengths.iloc[finetune_indices].values\n",
    "    test_lengths = test_setB_lengths.iloc[test_indices].values\n",
    "    \n",
    "    finetune_sepsis = test_setB_sepsis.iloc[finetune_indices].values\n",
    "    test_sepsis = test_setB_sepsis.iloc[test_indices].values\n",
    "    \n",
    "    finetune, finetune_lengths, finetune_sepsis = csv_to_pt(finetune, finetune_lengths, finetune_sepsis, desc=\"Fine-tuning Set\")\n",
    "    test, test_lengths, test_sepsis = csv_to_pt(test, test_lengths, test_sepsis, desc=\"Test Set\")\n",
    "    \n",
    "    print(\"Pre-training samples: \", pt_train['samples'].shape, \"Validation samples: \", pt_val['samples'].shape)\n",
    "    print(\"Fine-tuning samples: \", finetune['samples'].shape, \"Test samples: \", test['samples'].shape)\n",
    "    \n",
    "    return pt_train, pt_val, finetune, test\n",
    "    \n",
    "pt_train, pt_val, finetune, test = get_pretrain_finetune_datasets()\n"
   ],
   "id": "687ad37dc749028d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b8503e477808e77e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def geom_noise_mask_single(L, lm, masking_ratio):\n",
    "    \"\"\"\n",
    "    Randomly create a boolean mask of length `L`, consisting of subsequences of average length lm, masking with 0s a `masking_ratio`\n",
    "    proportion of the sequence L. The length of masking subsequences and intervals follow a geometric distribution.\n",
    "    Args:\n",
    "        L: length of mask and sequence to be masked\n",
    "        lm: average length of masking subsequences (streaks of 0s)\n",
    "        masking_ratio: proportion of L to be masked\n",
    "    Returns:\n",
    "        (L, ) boolean numpy array intended to mask ('drop') with 0s a sequence of length L\n",
    "    \"\"\"\n",
    "    keep_mask = np.ones(L, dtype=bool)\n",
    "    p_m = 1 / lm  # probability of each masking sequence stopping. parameter of geometric distribution.\n",
    "    p_u = p_m * masking_ratio / (\n",
    "            1 - masking_ratio)  # probability of each unmasked sequence stopping. parameter of geometric distribution.\n",
    "    p = [p_m, p_u]\n",
    "\n",
    "    # Start in state 0 with masking_ratio probability\n",
    "    state = int(np.random.rand() > masking_ratio)  # state 0 means masking, 1 means not masking\n",
    "    for i in range(L):\n",
    "        keep_mask[i] = state  # here it happens that state and masking value corresponding to state are identical\n",
    "        if np.random.rand() < p[state]:\n",
    "            state = 1 - state\n",
    "\n",
    "    return keep_mask\n",
    "\n",
    "\n",
    "def noise_mask(X, masking_ratio=0.25, lm=3, distribution='geometric', exclude_feats=None):\n",
    "    \"\"\"\n",
    "    Creates a random boolean mask of the same shape as X, with 0s at places where a feature should be masked.\n",
    "    Args:\n",
    "        X: (seq_length, feat_dim) numpy array of features corresponding to a single sample\n",
    "        masking_ratio: proportion of seq_length to be masked. At each time step, will also be the proportion of\n",
    "            feat_dim that will be masked on average\n",
    "        lm: average length of masking subsequences (streaks of 0s). Used only when `distribution` is 'geometric'.\n",
    "        distribution: whether each mask sequence element is sampled independently at random, or whether\n",
    "            sampling follows a markov chain (and thus is stateful), resulting in geometric distributions of\n",
    "            masked squences of a desired mean length `lm`\n",
    "        exclude_feats: iterable of indices corresponding to features to be excluded from masking (i.e. to remain all 1s)\n",
    "    Returns:\n",
    "        boolean numpy array with the same shape as X, with 0s at places where a feature should be masked\n",
    "    \"\"\"\n",
    "    if exclude_feats is not None:\n",
    "        exclude_feats = set(exclude_feats)\n",
    "\n",
    "    if distribution == 'geometric':  # stateful (Markov chain)\n",
    "        mask = geom_noise_mask_single(X.shape[0] * X.shape[1] * X.shape[2], lm, masking_ratio)\n",
    "        mask = mask.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "        \n",
    "    elif distribution == 'masked_tail':\n",
    "        mask = np.ones(X.shape, dtype=bool)\n",
    "        for m in range(X.shape[0]):  # feature dimension\n",
    "\n",
    "            keep_mask = np.zeros_like(mask[m, :], dtype=bool)\n",
    "            n = math.ceil(keep_mask.shape[1] * (1 - masking_ratio))\n",
    "            keep_mask[:, :n] = True\n",
    "            mask[m, :] = keep_mask  # time dimension\n",
    "            \n",
    "    elif distribution == 'masked_head':\n",
    "        mask = np.ones(X.shape, dtype=bool)\n",
    "        for m in range(X.shape[0]):  # feature dimension\n",
    "\n",
    "            keep_mask = np.zeros_like(mask[m, :], dtype=bool)\n",
    "            n = math.ceil(keep_mask.shape[1] * masking_ratio)\n",
    "            keep_mask[:, n:] = True\n",
    "            mask[m, :] = keep_mask  # time dimension\n",
    "    else:  # each position is independent Bernoulli with p = 1 - masking_ratio\n",
    "        mask = np.random.choice(np.array([True, False]), size=X.shape, replace=True,\n",
    "                                p=(1 - masking_ratio, masking_ratio))\n",
    "\n",
    "    return torch.tensor(mask)\n",
    "\n",
    "def data_transform_masked4cl(sample, masking_ratio, lm, positive_nums=None, distribution='geometric'):\n",
    "    \"\"\"Masked time series in time dimension\"\"\"\n",
    "\n",
    "    if positive_nums is None:\n",
    "        positive_nums = math.ceil(1.5 / (1 - masking_ratio))\n",
    "        \n",
    "    sample = sample.permute(0, 2, 1)  # (batch_size, channels, time_steps)\n",
    "    \n",
    "    # Creating the batch in #positive_nums sets\n",
    "    sample_repeat = sample.repeat(positive_nums, 1, 1)  # (batch_size*positive_num, channels, time steps)\n",
    "\n",
    "    mask = noise_mask(sample_repeat, masking_ratio, lm, distribution=distribution)\n",
    "    x_masked = mask * sample_repeat\n",
    "\n",
    "    return x_masked.permute(0, 2, 1), mask.permute(0, 2, 1)\n",
    "\n",
    "# data_masked_m, mask = data_transform_masked4cl(all_patients['samples'][:32], 0.5, 3, positive_nums=1, distribution='geometric')\n"
   ],
   "id": "df2ee9f255cd3528",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e14802c72ae0ed5c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Load_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, TSlength_aligned, training_mode):\n",
    "        \n",
    "        super(Load_Dataset, self).__init__()\n",
    "        self.training_mode = training_mode\n",
    "        \n",
    "        X_train = dataset[\"samples\"]\n",
    "        y_train = dataset[\"labels\"]\n",
    "        \n",
    "        # shuffle\n",
    "        data = list(zip(X_train, y_train))\n",
    "        np.random.shuffle(data)\n",
    "        \n",
    "        X_train, y_train = zip(*data)\n",
    "        X_train, y_train = torch.stack(list(X_train), dim=0), torch.stack(list(y_train), dim=0)\n",
    "\n",
    "        if len(X_train.shape) < 3:\n",
    "            X_train = X_train.unsqueeze(2)\n",
    "\n",
    "        # if X_train.shape.index(min(X_train.shape)) != 1:  # make sure the Channels in second dim\n",
    "        #     X_train = X_train.permute(0, 2, 1)\n",
    "\n",
    "        \"\"\"Align the TS length between source and target datasets\"\"\"\n",
    "        # X_train = X_train[:, :1, :int(config.TSlength_aligned)] # take the first 178 samples\n",
    "        X_train = X_train[:, :, :int(TSlength_aligned)]\n",
    "        \n",
    "        if isinstance(X_train, np.ndarray):\n",
    "            self.x_data = torch.from_numpy(X_train)\n",
    "            self.y_data = torch.from_numpy(y_train).long()\n",
    "        else:\n",
    "            self.x_data = X_train\n",
    "            self.y_data = y_train\n",
    "\n",
    "        self.len = X_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    "
   ],
   "id": "813e977f40d98345",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a1a86d99d645f058",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.simmtm.gtn.encoder import Encoder\n",
    "from simmtm.loss import ContrastiveWeight, AggregationRebuild, AutomaticWeightedLoss\n",
    "\n",
    "\n",
    "class TFC(nn.Module):\n",
    "    def __init__(self, configs, args):\n",
    "        \n",
    "        super(TFC, self).__init__()\n",
    "        self.training_mode = 'pre_train'\n",
    "        \n",
    "        # Projecting input into deep representations\n",
    "        self.encoder_list_1 = ModuleList([Encoder(d_model=configs.d_model, d_hidden=configs.d_hidden, q=configs.q,\n",
    "                                                  v=configs.v, h=configs.h, mask=configs.mask, dropout=configs.dropout,\n",
    "                                                  device=configs.device) for _ in range(configs.N)])\n",
    "\n",
    "        self.encoder_list_2 = ModuleList([Encoder(d_model=configs.d_model, d_hidden=configs.d_hidden, q=configs.q,\n",
    "                                                  v=configs.v, h=configs.h, dropout=configs.dropout,\n",
    "                                                  device=configs.device) for _ in range(configs.N)])\n",
    "\n",
    "        self.embedding_channel = torch.nn.Linear(configs.d_channel, configs.d_model)\n",
    "        self.embedding_input = torch.nn.Linear(configs.d_input, configs.d_model)\n",
    "\n",
    "        self.gate = torch.nn.Linear(configs.d_model * configs.d_input + configs.d_model * configs.d_channel,\n",
    "                                    configs.d_output)\n",
    "\n",
    "        self.pe = configs.pe\n",
    "        self._d_input = configs.d_input\n",
    "        self._d_model = configs.d_model\n",
    "\n",
    "        # MLP Layer - To generate Projector(.); to Obtain series-wise representations\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(192512, 256),  # 240128 = encoder1 out features + encoder2 out features\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "        if self.training_mode == 'pre_train':\n",
    "            self.awl = AutomaticWeightedLoss(2)\n",
    "            self.contrastive = ContrastiveWeight(args)\n",
    "            self.aggregation = AggregationRebuild(args)\n",
    "            # self.head = nn.Linear(240128, 336)  # Reconstruction, we have 336 time steps\n",
    "            self.head = nn.Linear(192512, configs.d_input * configs.d_channel)  # Replaced to handle multi-variate\n",
    "            self.mse = torch.nn.MSELoss()\n",
    "            \n",
    "    def forward(self, stage, x_in_t, pre_train=False):\n",
    "\n",
    "        # x_in_t: (128, 336, 133)\n",
    "        encoding_1 = self.embedding_channel(x_in_t)  # (128, 336, 512)\n",
    "        input_to_gather = encoding_1 \n",
    "\n",
    "        if self.pe:\n",
    "            pe = torch.ones_like(encoding_1[0])\n",
    "            position = torch.arange(0, self._d_input).unsqueeze(-1)\n",
    "            temp = torch.Tensor(range(0, self._d_model, 2))\n",
    "            temp = temp * -(math.log(10000) / self._d_model)\n",
    "            temp = torch.exp(temp).unsqueeze(0)\n",
    "            temp = torch.matmul(position.float(), temp)  # shape:[input, d_model/2]\n",
    "            pe[:, 0::2] = torch.sin(temp)\n",
    "            pe[:, 1::2] = torch.cos(temp)\n",
    "\n",
    "            encoding_1 = encoding_1 + pe  # (128, 336, 512)\n",
    "\n",
    "        for encoder in self.encoder_list_1:\n",
    "            # encoding_1: (128, 336, 512)\n",
    "            encoding_1, score_input = encoder(encoding_1, stage)\n",
    "            \n",
    "        encoding_2 = self.embedding_input(x_in_t.transpose(-1, -2))  # encoding_2: (128, 133, 512)\n",
    "        channel_to_gather = encoding_2  \n",
    "\n",
    "        for encoder in self.encoder_list_2:\n",
    "            # encoding_2: (128, 133, 512)\n",
    "            encoding_2, score_channel = encoder(encoding_2, stage)\n",
    "\n",
    "        encoding_1 = encoding_1.reshape(encoding_1.shape[0], -1)  # (128, 172032)\n",
    "        encoding_2 = encoding_2.reshape(encoding_2.shape[0], -1)  # (128, 68096)\n",
    "        \n",
    "        encoding_concat = self.gate(torch.cat([encoding_1, encoding_2], dim=-1))  # (128, 2)\n",
    "        \n",
    "        # gate: torch.Size([128, 2])\n",
    "        gate = F.softmax(encoding_concat, dim=-1)  \n",
    "        encoding = torch.cat([encoding_1 * gate[:, 0:1], encoding_2 * gate[:, 1:2]], dim=-1)  # (128, 240128)\n",
    "        # print(encoding.shape)\n",
    "        \n",
    "        # Projections\n",
    "        projections = self.dense(encoding)  # (128, 128)\n",
    "\n",
    "        if pre_train:\n",
    "            # loss_cl: torch.Size([])\n",
    "            # similarity_matrix: torch.Size([128, 128])\n",
    "            # logits: torch.Size([128, 127])\n",
    "            # positives_mask: torch.Size([128, 128])\n",
    "            loss_cl, similarity_matrix, logits, positives_mask = self.contrastive(projections)           \n",
    "            \n",
    "            # rebuild_weight_matrix: torch.Size([128, 128])\n",
    "            # agg_x: torch.Size([128, 240128])\n",
    "            rebuild_weight_matrix, agg_x = self.aggregation(similarity_matrix, encoding)\n",
    "            \n",
    "            # pred_x: torch.Size([128, 336])\n",
    "            pred_x = self.head(agg_x.reshape(agg_x.size(0), -1))\n",
    "            \n",
    "            # x_in_t.shape: torch.Size([128, 336, 133])\n",
    "            # x_in_t.reshape(x_in_t.size(0), -1): torch.Size([128, 44688])\n",
    "            loss_rb = self.mse(pred_x, x_in_t.reshape(x_in_t.size(0), -1).detach())\n",
    "            loss = self.awl(loss_cl, loss_rb)\n",
    "\n",
    "            return loss, loss_cl, loss_rb\n",
    "\n",
    "        return encoding, encoding_concat\n",
    "    "
   ],
   "id": "5df8708066259139",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f16d7cef8d8db61f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def model_pretrain(model, model_optimizer, model_scheduler, train_loader, configs, args, device):\n",
    "    total_loss = []\n",
    "    total_cl_loss = []\n",
    "    total_rb_loss = []\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in tqdm.tqdm(enumerate(train_loader), desc=\"Pre-training model\", total=len(train_loader)):  # data shape: (batch_size, seqs, channels)\n",
    "\n",
    "        model_optimizer.zero_grad()\n",
    "        # When masking, data is reshaped to (batch_size, channel, seqs) - Inside the data_transform_masked4cl()\n",
    "        data_masked_m, mask = data_transform_masked4cl(data, args.masking_ratio, args.lm, args.positive_nums)\n",
    "        data_masked_om = torch.cat([data, data_masked_m], 0)  # (batch_size, seqs, channels)\n",
    "\n",
    "        data, labels = data.float().to('cpu'), labels.float().to('cpu')\n",
    "        data_masked_om = data_masked_om.float().to(device)\n",
    "\n",
    "        # Produce embeddings of original and masked samples  (data_masked_om = data samples + masked samples)\n",
    "        # loss, loss_cl, loss_rb = model(data_masked_om, pretrain=True)\n",
    "        # return loss, loss_cl, loss_rb\n",
    "        \n",
    "        loss, loss_cl, loss_rb = model(stage='train', x_in_t=data_masked_om, pre_train=True)\n",
    "        \n",
    "        # return loss, loss_cl, loss_rb\n",
    "\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "\n",
    "        total_loss.append(loss.item())\n",
    "        total_cl_loss.append(loss_cl.item())\n",
    "        total_rb_loss.append(loss_rb.item())\n",
    "\n",
    "    total_loss = torch.tensor(total_loss).mean()\n",
    "    total_cl_loss = torch.tensor(total_cl_loss).mean()\n",
    "    total_rb_loss = torch.tensor(total_rb_loss).mean()\n",
    "\n",
    "    model_scheduler.step()\n",
    "\n",
    "    return total_loss, total_cl_loss, total_rb_loss\n"
   ],
   "id": "53dd90f7b8f1d93c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "70fb02e9daf22921",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pt_dataset = Load_Dataset(pt_train, TSlength_aligned=336, training_mode='pretrain')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=pt_dataset, batch_size=32, shuffle=True, \n",
    "                                           drop_last=True, num_workers=4)  # (32, 336, 40)\n",
    "\n",
    "val_dataset = Load_Dataset(pt_val, TSlength_aligned=336, training_mode='pretrain')\n",
    "val_loader = torch.utils.data.DataLoader(dataset=pt_val, batch_size=32, shuffle=True, \n",
    "                                           drop_last=True, num_workers=4)\n",
    "\n",
    "finetune_dataset = Load_Dataset(finetune, TSlength_aligned=336, training_mode='finetune')\n",
    "finetune_loader = torch.utils.data.DataLoader(finetune_dataset, batch_size=32, shuffle=True, \n",
    "                                              drop_last=True, num_workers=4)\n",
    "\n"
   ],
   "id": "73cf01b5a50301d5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4791a78dc05d8fbe",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "66c8d4e9473a73ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def get_model_size(model):\n",
    "    \n",
    "    def convert_to_gigabytes(input_megabyte):\n",
    "        gigabyte = 1.0/1024\n",
    "        convert_gb = gigabyte * input_megabyte\n",
    "        return convert_gb\n",
    "    \n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "        \n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    \n",
    "    print('model size: {:.3f} GB'.format(convert_to_gigabytes(size_all_mb)))\n",
    "    \n",
    "    return convert_to_gigabytes(size_all_mb)\n"
   ],
   "id": "1ab5f8eefd0e3b18",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "794267d4978c96f8",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.simmtm.model import target_classifier\n",
    "\n",
    "from models.simmtm.config import Config\n",
    "\n",
    "def build_model(args, lr, configs, device='cuda', chkpoint=None):\n",
    "    \n",
    "    model = TFC(configs, args).to(device)\n",
    "    if chkpoint:\n",
    "        pretrained_dict = chkpoint[\"model_state_dict\"]\n",
    "        model_dict = model.state_dict()\n",
    "        model_dict.update(pretrained_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "    classifier = target_classifier(configs).to(device)\n",
    "    model_optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(configs.beta1, configs.beta2), weight_decay=0)\n",
    "    classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=lr, \n",
    "                                            betas=(configs.beta1, configs.beta2),\n",
    "                                            weight_decay=0)\n",
    "    model_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=model_optimizer, T_max=args.finetune_epoch)\n",
    "\n",
    "    return model, classifier, model_optimizer, classifier_optimizer, model_scheduler\n",
    "\n",
    "# model, classifier, model_optimizer, classifier_optimizer, model_scheduler = build_model(args, Config().lr, Config())\n"
   ],
   "id": "e77dd1109aeca00a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ea7f9946c0b9189d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, accuracy_score, \n",
    "                             precision_score, f1_score, recall_score)\n",
    "\n",
    "def model_finetune(model, val_dl, device, model_optimizer, model_scheduler, classifier=None, classifier_optimizer=None):\n",
    "    model.train()\n",
    "    classifier.train()\n",
    "\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "    total_auc = []\n",
    "    total_prc = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    outs = np.array([])\n",
    "    trgs = np.array([])\n",
    "\n",
    "    for data, labels in val_dl:\n",
    "        model_optimizer.zero_grad()\n",
    "        classifier_optimizer.zero_grad()\n",
    "\n",
    "        data, labels = data.float().to(device), labels.long().to(device)\n",
    "\n",
    "        # Produce embeddings\n",
    "        h, z = model(stage='train', x_in_t=data, pre_train=False)\n",
    "\n",
    "        # Add supervised classifier: 1) it's unique to finetuning. 2) this classifier will also be used in test\n",
    "        fea_concat = h\n",
    "\n",
    "        predictions = classifier(fea_concat)\n",
    "        fea_concat_flat = fea_concat.reshape(fea_concat.shape[0], -1)\n",
    "        print(predictions)\n",
    "        print(labels)\n",
    "        print(predictions.shape, labels.shape)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        acc_bs = labels.eq(predictions.detach().argmax(dim=1)).float().mean()\n",
    "        onehot_label = F.one_hot(labels)\n",
    "        pred_numpy = predictions.detach().cpu().numpy()\n",
    "\n",
    "        try:\n",
    "            auc_bs = roc_auc_score(onehot_label.detach().cpu().numpy(), pred_numpy, average=\"macro\", multi_class=\"ovr\")\n",
    "        except:\n",
    "            auc_bs = 0.0\n",
    "\n",
    "        try:\n",
    "            prc_bs = average_precision_score(onehot_label.detach().cpu().numpy(), pred_numpy)\n",
    "        except:\n",
    "            prc_bs = 0.0\n",
    "\n",
    "        total_acc.append(acc_bs)\n",
    "\n",
    "        if auc_bs != 0:\n",
    "            total_auc.append(auc_bs)\n",
    "        if prc_bs != 0:\n",
    "            total_prc.append(prc_bs)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "        classifier_optimizer.step()\n",
    "\n",
    "        pred = predictions.max(1, keepdim=True)[1]\n",
    "        outs = np.append(outs, pred.cpu().numpy())\n",
    "        trgs = np.append(trgs, labels.data.cpu().numpy())\n",
    "\n",
    "    labels_numpy = labels.detach().cpu().numpy()\n",
    "    pred_numpy = np.argmax(pred_numpy, axis=1)\n",
    "    F1 = f1_score(labels_numpy, pred_numpy, average='macro', )  # labels=np.unique(ypred))\n",
    "\n",
    "    total_loss = torch.tensor(total_loss).mean()  # average loss\n",
    "    total_acc = torch.tensor(total_acc).mean()  # average acc\n",
    "    total_auc = torch.tensor(total_auc).mean()  # average auc\n",
    "    total_prc = torch.tensor(total_prc).mean()\n",
    "\n",
    "    model_scheduler.step(total_loss)\n",
    "\n",
    "    return total_loss, total_acc, total_auc, total_prc, fea_concat_flat, trgs, F1\n"
   ],
   "id": "a094280591adf48d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b32855e4656dc272",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def train(train_loader, val_loader, finetune_loader, device='cuda'):\n",
    "    \n",
    "    model = TFC(configs=Config(), args=args)\n",
    "    params_group = [{'params': model.parameters()}]\n",
    "    model_optimizer = torch.optim.Adam(params_group, lr=args.pretrain_lr, \n",
    "                                       betas=(Config().beta1, Config().beta2),\n",
    "                                       weight_decay=0)\n",
    "    \n",
    "    model_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=model_optimizer, T_max=args.pretrain_epoch)\n",
    "\n",
    "    experiment_log_dir = os.path.join(project_root(), 'results', 'simmtm')\n",
    "    os.makedirs(os.path.join(experiment_log_dir, f\"saved_models\"), exist_ok=True)\n",
    "    \n",
    "    best_performance = None\n",
    "    seed = 2024\n",
    "    for epoch in range(Config().pretrain_epoch):\n",
    "        total_loss, total_cl_loss, total_rb_loss = model_pretrain(model=model, model_optimizer=model_optimizer,\n",
    "                                                              model_scheduler=model_scheduler, train_loader=train_loader, \n",
    "                                                              configs=Config(), args=args, device='cuda')\n",
    "        \n",
    "        print(f'Pre-training Epoch: {epoch}\\t Train Loss: {total_loss:.4f}\\t CL Loss: {total_cl_loss:.4f}\\t RB Loss: {total_rb_loss:.4f}\\n')\n",
    "        \n",
    "        chkpoint = {'seed': seed, 'epoch': epoch, 'train_loss': total_loss, 'model_state_dict': model.state_dict()}\n",
    "        torch.save(chkpoint, os.path.join(experiment_log_dir, f\"saved_models/\", f'ckp_ep{epoch}.pt'))\n",
    "        \n",
    "        # if epoch % 2 == 0:\n",
    "        for ep in range(1, Config().finetune_epoch+1):\n",
    "            print(f\"Fine-tuning started...\")\n",
    "            ft_model, ft_classifier, ft_model_optimizer, ft_classifier_optimizer, ft_scheduler = build_model(\n",
    "                args, args.lr, Config(), device=device, chkpoint=chkpoint)\n",
    "            \n",
    "            for ep in range(1, Config().finetune_epoch):\n",
    "                valid_loss, valid_acc, valid_auc, valid_prc, emb_finetune, label_finetune, F1 = model_finetune(\n",
    "                    ft_model, finetune_loader, device, ft_model_optimizer, ft_scheduler, classifier=ft_classifier,\n",
    "                    classifier_optimizer=ft_classifier_optimizer)\n",
    "        \n",
    "        \n",
    "        # # Loading the model\n",
    "        # temp_model = TFC(configs=Config(), args=args)\n",
    "        # \n",
    "        # pretrained_dict = chkpoint[\"model_state_dict\"]\n",
    "        # model_dict = temp_model.state_dict()\n",
    "        # model_dict.update(pretrained_dict)\n",
    "        # temp_model.load_state_dict(model_dict)\n",
    "\n",
    "train(train_loader, val_loader, finetune_loader)\n"
   ],
   "id": "1c828672c410828f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a1f7e59217a9043",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e71b3bc07f12b1e6",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T02:51:27.643052Z",
     "start_time": "2024-09-15T02:51:27.639944Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "12d17b3c2d404d16",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T15:28:33.536951Z",
     "start_time": "2024-09-15T15:28:33.534768Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6f6fa66123ca65a2",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T18:02:36.365948Z",
     "start_time": "2024-09-15T18:02:34.869333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.evaluate_helper_methods import load_sepsis_model\n",
    "from utils.path_utils import project_root\n",
    "import os\n",
    "\n",
    "model_path = os.path.join(project_root(), 'results', 'simmtm', 'saved_models', 'finetune_ep16.pt')\n",
    "model = load_sepsis_model(d_input=336, d_channel=40, d_output=2, model_name=model_path,\n",
    "                          pre_model=\"simmtm\")\n"
   ],
   "id": "d360583e1280b377",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T18:17:23.162317Z",
     "start_time": "2024-09-15T18:17:18.782160Z"
    }
   },
   "cell_type": "code",
   "source": "torch.load(model_path)['classifier']",
   "id": "79ca166a2a37eab",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "c4e9e917c22ff42e",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T18:22:52.533147Z",
     "start_time": "2024-09-15T18:22:52.460727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "configs = Config()\n",
    "classifier = target_classifier(configs=configs)"
   ],
   "id": "961ffb366fa00050",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T18:22:57.821371Z",
     "start_time": "2024-09-15T18:22:57.818362Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6e8d8d3503885f",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T15:59:22.920520Z",
     "start_time": "2024-09-15T15:59:22.918701Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "595708fecee6ba5f",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:00:16.200591Z",
     "start_time": "2024-09-15T16:00:15.891235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "test_data = torch.load(os.path.join(project_root(), 'data', 'test_data', 'simmtm', 'test.pt'))['samples']\n"
   ],
   "id": "f48564a2eeed9fcf",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:06:24.652829Z",
     "start_time": "2024-09-15T16:06:24.650902Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "75e91fc0e75291de",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:06:52.411708Z",
     "start_time": "2024-09-15T16:06:52.398669Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "1d47b53b411323e4",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:08:44.721676Z",
     "start_time": "2024-09-15T16:08:44.708916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_setB_all_files = os.path.join(project_root(), 'physionet.org', 'files', 'challenge-2019', '1.0.0', 'training',\n",
    "                         'training_setB')\n",
    "test_setB_files = os.listdir(test_setB_all_files)\n",
    "test_setB_files.sort()\n",
    "test_setB_files.remove('index.html')\n",
    "\n",
    "test_setB_files = [test_setB_files[i] for i in test_indices]\n"
   ],
   "id": "a7c2ccc8e4d4b26",
   "execution_count": 41,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:16:05.258640Z",
     "start_time": "2024-09-15T16:15:35.191282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = os.path.join(project_root(), 'data', 'test_data', 'simmtm', 'psv_files')\n",
    "for pidx in test_setB_files:\n",
    "    pdata = pd.read_csv(os.path.join(test_setB_all_files, pidx), sep='|')\n",
    "    pdata.to_csv(os.path.join(save_path, pidx), sep='|', index=False)\n"
   ],
   "id": "4c401801fd054fc2",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:16:05.261393Z",
     "start_time": "2024-09-15T16:16:05.259803Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d9210aa2d11c0419",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T17:06:28.556415Z",
     "start_time": "2024-09-16T17:06:23.059358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils.path_utils import project_root\n",
    "from utils.pretrain_utils.data import get_train_val_test_indices\n",
    "\n",
    "test_indices, finetune_indices = get_train_val_test_indices(\n",
    "        sepsis_file='is_sepsis_finetune_B.txt', save_distributions=True,\n",
    "        dset='Bb')\n",
    "\n",
    "test_setB_all_files = os.path.join(project_root(), 'physionet.org', 'files', 'challenge-2019', '1.0.0', 'training',\n",
    "                         'training_setB')\n",
    "test_setB_files = os.listdir(test_setB_all_files)\n",
    "test_setB_files.sort()\n",
    "test_setB_files.remove('index.html')\n",
    "\n",
    "test_setB_files = [test_setB_files[i] for i in test_indices]\n",
    "\n",
    "for pidx in test_setB_files:\n",
    "    break\n",
    "    \n",
    "save_path = os.path.join(project_root(), 'data', 'test_data', 'simmtm', 'psv_files')\n",
    "pd.read_csv(os.path.join(save_path, pidx), sep='|')"
   ],
   "id": "755d73d5d746dd79",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:15:31.666688Z",
     "start_time": "2024-09-15T16:15:31.665040Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6fdb9e3b02c4d350",
   "execution_count": 66,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:48:30.348775Z",
     "start_time": "2024-09-15T16:48:30.346546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# torch.load(os.path.join(project_root(), 'results', 'simmtm', 'saved_models', 'ckp_ep9.pt'))['model_state_dict']"
   ],
   "id": "ac9ec8ab87a8be4c",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:49:09.393511Z",
     "start_time": "2024-09-15T16:49:09.254354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.simmtm.config import Config\n",
    "from models.simmtm.model import TFC, target_classifier\n",
    "\n",
    "config = Config()\n",
    "classifier = target_classifier(config).to('cuda')\n"
   ],
   "id": "d9acb3ab57655c84",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T16:49:43.678359Z",
     "start_time": "2024-09-15T16:49:43.676184Z"
    }
   },
   "cell_type": "code",
   "source": "[8, 15 (0.89), 16 (1), 17 (1)]",
   "id": "6d2f46245e123e90",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:13:10.624175Z",
     "start_time": "2024-09-25T21:13:10.622430Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "134ec7bccf2a316f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:13:10.644859Z",
     "start_time": "2024-09-25T21:13:10.643192Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "34805629248d1a37",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:13:10.661855Z",
     "start_time": "2024-09-25T21:13:10.660104Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d07d72880ab1a5a1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:13:10.694270Z",
     "start_time": "2024-09-25T21:13:10.692806Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "696f3373125eff9a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:13:10.740038Z",
     "start_time": "2024-09-25T21:13:10.738678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "from models.adatime.gtn.encoder import Encoder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_backbone_class(backbone_name):\n",
    "    if backbone_name not in globals():\n",
    "        raise NotImplementedError(\"Algorithm not found: {}\".format(backbone_name))\n",
    "    return globals()[backbone_name]\n",
    "\n",
    "\n",
    "class GTN(nn.Module):\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        super(GTN, self).__init__()\n",
    "\n",
    "        self.encoder_list_1 = ModuleList([Encoder(d_model=configs.d_model, d_hidden=configs.d_hidden, q=configs.q,\n",
    "                                                  v=configs.v, h=configs.h, mask=configs.mask, dropout=configs.dropout,\n",
    "                                                  device=configs.device) for _ in range(configs.N)])\n",
    "\n",
    "        self.encoder_list_2 = ModuleList([Encoder(d_model=configs.d_model, d_hidden=configs.d_hidden, q=configs.q,\n",
    "                                                  v=configs.v, h=configs.h, dropout=configs.dropout,\n",
    "                                                  device=configs.device) for _ in range(configs.N)])\n",
    "\n",
    "        self.embedding_channel = torch.nn.Linear(configs.d_channel, configs.d_model)\n",
    "        self.embedding_input = torch.nn.Linear(configs.d_input, configs.d_model)\n",
    "\n",
    "        self.gate = torch.nn.Linear(configs.d_model * configs.d_input + configs.d_model * configs.d_channel,\n",
    "                                    configs.d_output)\n",
    "\n",
    "        self.pe = configs.pe\n",
    "        self._d_input = configs.d_input\n",
    "        self._d_model = configs.d_model\n",
    "\n",
    "        self.head = nn.Linear(192512, int((configs.d_input * configs.d_channel)/4))\n",
    "\n",
    "    def forward(self, stage, x_in_t):\n",
    "\n",
    "        encoding_1 = self.embedding_channel(x_in_t)\n",
    "\n",
    "        if self.pe:\n",
    "            pe = torch.ones_like(encoding_1[0])\n",
    "            position = torch.arange(0, self._d_input).unsqueeze(-1)\n",
    "            temp = torch.Tensor(range(0, self._d_model, 2))\n",
    "            temp = temp * -(math.log(10000) / self._d_model)\n",
    "            temp = torch.exp(temp).unsqueeze(0)\n",
    "            temp = torch.matmul(position.float(), temp)\n",
    "            pe[:, 0::2] = torch.sin(temp)\n",
    "            pe[:, 1::2] = torch.cos(temp)\n",
    "\n",
    "            encoding_1 = encoding_1 + pe\n",
    "\n",
    "        for encoder in self.encoder_list_1:\n",
    "            encoding_1, score_input = encoder(encoding_1, stage)\n",
    "\n",
    "        encoding_2 = self.embedding_input(x_in_t.transpose(-1, -2))\n",
    "\n",
    "        for encoder in self.encoder_list_2:\n",
    "            encoding_2, score_channel = encoder(encoding_2, stage)\n",
    "\n",
    "        encoding_1 = encoding_1.reshape(encoding_1.shape[0], -1)\n",
    "        encoding_2 = encoding_2.reshape(encoding_2.shape[0], -1)\n",
    "\n",
    "        encoding_concat = self.gate(torch.cat([encoding_1, encoding_2], dim=-1))\n",
    "\n",
    "        gate = F.softmax(encoding_concat, dim=-1)\n",
    "        encoding = torch.cat([encoding_1 * gate[:, 0:1], encoding_2 * gate[:, 1:2]], dim=-1)\n",
    "        encoding = self.head(encoding)\n",
    "\n",
    "        return encoding\n",
    "\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(classifier, self).__init__()\n",
    "        self.logits = nn.Linear(int((configs.d_input * configs.d_channel)/4), configs.num_classes)\n",
    "        self.configs = configs\n",
    "\n",
    "    def forward(self, x):\n",
    "        predictions = self.logits(x)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "#### Codes required by DANN ##############\n",
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        return output, None\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator model for source domain.\"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        \"\"\"Init discriminator.\"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(configs.features_len * configs.final_out_channels, configs.disc_hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.disc_hid_dim, configs.disc_hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.disc_hid_dim, 2)\n",
    "            # nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward the discriminator.\"\"\"\n",
    "        out = self.layer(input)\n",
    "        return out\n",
    "\n",
    "\n",
    "#### Codes required by CDAN ##############\n",
    "class RandomLayer(nn.Module):\n",
    "    def __init__(self, input_dim_list=[], output_dim=1024):\n",
    "        super(RandomLayer, self).__init__()\n",
    "        self.input_num = len(input_dim_list)\n",
    "        self.output_dim = output_dim\n",
    "        self.random_matrix = [torch.randn(input_dim_list[i], output_dim) for i in range(self.input_num)]\n",
    "\n",
    "    def forward(self, input_list):\n",
    "        return_list = [torch.mm(input_list[i], self.random_matrix[i]) for i in range(self.input_num)]\n",
    "        return_tensor = return_list[0] / math.pow(float(self.output_dim), 1.0 / len(return_list))\n",
    "        for single in return_list[1:]:\n",
    "            return_tensor = torch.mul(return_tensor, single)\n",
    "        return return_tensor\n",
    "\n",
    "    def cuda(self):\n",
    "        super(RandomLayer, self).cuda()\n",
    "        self.random_matrix = [val.cuda() for val in self.random_matrix]\n",
    "\n",
    "\n",
    "class Discriminator_CDAN(nn.Module):\n",
    "    \"\"\"Discriminator model for CDAN .\"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        \"\"\"Init discriminator.\"\"\"\n",
    "        super(Discriminator_CDAN, self).__init__()\n",
    "\n",
    "        self.restored = False\n",
    "\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(configs.features_len * configs.final_out_channels * configs.num_classes, configs.disc_hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.disc_hid_dim, configs.disc_hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.disc_hid_dim, 2)\n",
    "            # nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward the discriminator.\"\"\"\n",
    "        out = self.layer(input)\n",
    "        return out\n",
    "\n",
    "\n",
    "class codats_classifier(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(codats_classifier, self).__init__()\n",
    "        model_output_dim = configs.features_len\n",
    "        self.hidden_dim = configs.hidden_dim\n",
    "        self.logits = nn.Sequential(\n",
    "            nn.Linear(model_output_dim * configs.final_out_channels, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, configs.num_classes))\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        predictions = self.logits(x_in)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "#### Codes required by AdvSKM ##############\n",
    "class Cosine_act(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cosine_act, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return torch.cos(input)\n",
    "\n",
    "\n",
    "cos_act = Cosine_act()\n",
    "\n",
    "\n",
    "class AdvSKM_Disc(nn.Module):\n",
    "    \"\"\"Discriminator model for source domain.\"\"\"\n",
    "\n",
    "    def __init__(self, configs):\n",
    "        \"\"\"Init discriminator.\"\"\"\n",
    "        super(AdvSKM_Disc, self).__init__()\n",
    "\n",
    "        self.input_dim = configs.features_len * configs.final_out_channels\n",
    "        self.hid_dim = configs.DSKN_disc_hid\n",
    "        self.branch_1 = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hid_dim),\n",
    "            nn.Linear(self.hid_dim, self.hid_dim),\n",
    "            nn.BatchNorm1d(self.hid_dim),\n",
    "            cos_act,\n",
    "            nn.Linear(self.hid_dim, self.hid_dim // 2),\n",
    "            nn.Linear(self.hid_dim // 2, self.hid_dim // 2),\n",
    "            nn.BatchNorm1d(self.hid_dim // 2),\n",
    "            cos_act\n",
    "        )\n",
    "        self.branch_2 = nn.Sequential(\n",
    "            nn.Linear(configs.features_len * configs.final_out_channels, configs.disc_hid_dim),\n",
    "            nn.Linear(configs.disc_hid_dim, configs.disc_hid_dim),\n",
    "            nn.BatchNorm1d(configs.disc_hid_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(configs.disc_hid_dim, configs.disc_hid_dim // 2),\n",
    "            nn.Linear(configs.disc_hid_dim // 2, configs.disc_hid_dim // 2),\n",
    "            nn.BatchNorm1d(configs.disc_hid_dim // 2),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward the discriminator.\"\"\"\n",
    "        out_cos = self.branch_1(input)\n",
    "        out_rel = self.branch_2(input)\n",
    "        total_out = torch.cat((out_cos, out_rel), dim=1)\n",
    "        return total_out\n",
    "\n",
    "\n",
    "class attn_network(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(attn_network, self).__init__()\n",
    "\n",
    "        self.h_dim = configs.features_len * configs.final_out_channels\n",
    "        self.self_attn_Q = nn.Sequential(nn.Linear(in_features=self.h_dim, out_features=self.h_dim),\n",
    "                                         nn.ELU()\n",
    "                                         )\n",
    "        self.self_attn_K = nn.Sequential(nn.Linear(in_features=self.h_dim, out_features=self.h_dim),\n",
    "                                         nn.LeakyReLU()\n",
    "                                         )\n",
    "        self.self_attn_V = nn.Sequential(nn.Linear(in_features=self.h_dim, out_features=self.h_dim),\n",
    "                                         nn.LeakyReLU()\n",
    "                                         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.self_attn_Q(x)\n",
    "        K = self.self_attn_K(x)\n",
    "        V = self.self_attn_V(x)\n",
    "\n",
    "        return Q, K, V\n",
    "\n",
    "\n",
    "class Sparsemax(nn.Module):\n",
    "    \"\"\"Sparsemax function.\"\"\"\n",
    "\n",
    "    def __init__(self, dim=None):\n",
    "        \"\"\"Initialize sparsemax activation\n",
    "\n",
    "        Args:\n",
    "            dim (int, optional): The dimension over which to apply the sparsemax function.\n",
    "        \"\"\"\n",
    "        super(Sparsemax, self).__init__()\n",
    "\n",
    "        self.dim = -1 if dim is None else dim\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function.\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor. First dimension should be the batch size\n",
    "        Returns:\n",
    "            torch.Tensor: [batch_size x number_of_logits] Output tensor\n",
    "        \"\"\"\n",
    "        # Sparsemax currently only handles 2-dim tensors,\n",
    "        # so we reshape to a convenient shape and reshape back after sparsemax\n",
    "        input = input.transpose(0, self.dim)\n",
    "        original_size = input.size()\n",
    "        input = input.reshape(input.size(0), -1)\n",
    "        input = input.transpose(0, 1)\n",
    "        dim = 1\n",
    "\n",
    "        number_of_logits = input.size(dim)\n",
    "\n",
    "        # Translate input by max for numerical stability\n",
    "        input = input - torch.max(input, dim=dim, keepdim=True)[0].expand_as(input)\n",
    "\n",
    "        # Sort input in descending order.\n",
    "        # (NOTE: Can be replaced with linear time selection method described here:\n",
    "        # http://stanford.edu/~jduchi/projects/DuchiShSiCh08.html)\n",
    "        zs = torch.sort(input=input, dim=dim, descending=True)[0]\n",
    "        range = torch.arange(start=1, end=number_of_logits + 1, step=1, device=input.device, dtype=input.dtype).view(1,\n",
    "                                                                                                                     -1)\n",
    "        range = range.expand_as(zs)\n",
    "\n",
    "        # Determine sparsity of projection\n",
    "        bound = 1 + range * zs\n",
    "        cumulative_sum_zs = torch.cumsum(zs, dim)\n",
    "        is_gt = torch.gt(bound, cumulative_sum_zs).type(input.type())\n",
    "        k = torch.max(is_gt * range, dim, keepdim=True)[0]\n",
    "\n",
    "        # Compute threshold function\n",
    "        zs_sparse = is_gt * zs\n",
    "\n",
    "        # Compute taus\n",
    "        taus = (torch.sum(zs_sparse, dim, keepdim=True) - 1) / k\n",
    "        taus = taus.expand_as(input)\n",
    "\n",
    "        # Sparsemax\n",
    "        self.output = torch.max(torch.zeros_like(input), input - taus)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        output = self.output\n",
    "        output = output.transpose(0, 1)\n",
    "        output = output.reshape(original_size)\n",
    "        output = output.transpose(0, self.dim)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward function.\"\"\"\n",
    "        dim = 1\n",
    "\n",
    "        nonzeros = torch.ne(self.output, 0)\n",
    "        sum = torch.sum(grad_output * nonzeros, dim=dim) / torch.sum(nonzeros, dim=dim)\n",
    "        self.grad_input = nonzeros * (grad_output - sum.expand_as(grad_output))\n",
    "\n",
    "        return self.grad_input\n",
    "\n",
    "\n",
    "class CNN_ATTN(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super(CNN_ATTN, self).__init__()\n",
    "\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(configs.input_channels, configs.mid_channels, kernel_size=configs.kernel_size,\n",
    "                      stride=configs.stride, bias=False, padding=(configs.kernel_size // 2)),\n",
    "            nn.BatchNorm1d(configs.mid_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),\n",
    "            nn.Dropout(configs.dropout)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(configs.mid_channels, configs.mid_channels * 2, kernel_size=8, stride=1, bias=False, padding=4),\n",
    "            nn.BatchNorm1d(configs.mid_channels * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(configs.mid_channels * 2, configs.final_out_channels, kernel_size=8, stride=1, bias=False,\n",
    "                      padding=4),\n",
    "            nn.BatchNorm1d(configs.final_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(configs.features_len)\n",
    "        self.attn_network = attn_network(configs)\n",
    "        self.sparse_max = Sparsemax(dim=-1)\n",
    "        self.feat_len = configs.features_len\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        x = self.conv_block1(x_in)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        attentive_feat = self.calculate_attentive_feat(x_flat)\n",
    "        return attentive_feat\n",
    "\n",
    "    def self_attention(self, Q, K, scale=True, sparse=True, k=3):\n",
    "\n",
    "        attention_weight = torch.bmm(Q.view(Q.shape[0], self.feat_len, -1), K.view(K.shape[0], -1, self.feat_len))\n",
    "\n",
    "        attention_weight = torch.mean(attention_weight, dim=2, keepdim=True)\n",
    "\n",
    "        if scale:\n",
    "            d_k = torch.tensor(K.shape[-1]).float()\n",
    "            attention_weight = attention_weight / torch.sqrt(d_k)\n",
    "        if sparse:\n",
    "            attention_weight_sparse = self.sparse_max(torch.reshape(attention_weight, [-1, self.feat_len]))\n",
    "            attention_weight = torch.reshape(attention_weight_sparse, [-1, attention_weight.shape[1],\n",
    "                                                                       attention_weight.shape[2]])\n",
    "        else:\n",
    "            attention_weight = self.softmax(attention_weight)\n",
    "\n",
    "        return attention_weight\n",
    "\n",
    "    def attention_fn(self, Q, K, scaled=False, sparse=True, k=1):\n",
    "\n",
    "        attention_weight = torch.matmul(F.normalize(Q, p=2, dim=-1),\n",
    "                                        F.normalize(K, p=2, dim=-1).view(K.shape[0], K.shape[1], -1, self.feat_len))\n",
    "\n",
    "        if scaled:\n",
    "            d_k = torch.tensor(K.shape[-1]).float()\n",
    "            attention_weight = attention_weight / torch.sqrt(d_k)\n",
    "            attention_weight = k * torch.log(torch.tensor(self.feat_len, dtype=torch.float32)) * attention_weight\n",
    "\n",
    "        if sparse:\n",
    "            attention_weight_sparse = self.sparse_max(torch.reshape(attention_weight, [-1, self.feat_len]))\n",
    "\n",
    "            attention_weight = torch.reshape(attention_weight_sparse, attention_weight.shape)\n",
    "        else:\n",
    "            attention_weight = self.softmax(attention_weight)\n",
    "\n",
    "        return attention_weight\n",
    "\n",
    "    def calculate_attentive_feat(self, candidate_representation_xi):\n",
    "        Q_xi, K_xi, V_xi = self.attn_network(candidate_representation_xi)\n",
    "        intra_attention_weight_xi = self.self_attention(Q=Q_xi, K=K_xi, sparse=True)\n",
    "        Z_i = torch.bmm(intra_attention_weight_xi.view(intra_attention_weight_xi.shape[0], 1, -1),\n",
    "                        V_xi.view(V_xi.shape[0], self.feat_len, -1))\n",
    "        final_feature = F.normalize(Z_i, dim=-1).view(Z_i.shape[0],-1)\n",
    "\n",
    "        return final_feature\n",
    "\n"
   ],
   "id": "8f8f7974b33ed1cd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:13:10.762673Z",
     "start_time": "2024-09-25T21:13:10.760907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import numpy as np\n",
    "# import itertools\n",
    "#\n",
    "# from da.adatime.da import classifier, ReverseLayerF, Discriminator, RandomLayer, Discriminator_CDAN, \\\n",
    "#     codats_classifier, AdvSKM_Disc, CNN_ATTN\n",
    "#\n",
    "# from da.adatime.da.loss import MMD_loss, CORAL, ConditionalEntropyLoss, VAT, LMMD_loss, HoMM_loss, NTXentLoss, SupConLoss\n",
    "# from da.adatime.utils import EMA\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# from copy import deepcopy\n",
    "# import torch.nn.functional as F\n",
    "#\n",
    "#\n",
    "# def get_algorithm_class(algorithm_name):\n",
    "#     \"\"\"Return the algorithm class with the given name.\"\"\"\n",
    "#     if algorithm_name not in globals():\n",
    "#         raise NotImplementedError(\"Algorithm not found: {}\".format(algorithm_name))\n",
    "#     return globals()[algorithm_name]\n",
    "#\n",
    "#\n",
    "# class Algorithm(torch.nn.Module):\n",
    "#     \"\"\"\n",
    "#     A subclass of Algorithm implements a domain adaptation algorithm.\n",
    "#     Subclasses should implement the update() method.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, configs, backbone):\n",
    "#         super(Algorithm, self).__init__()\n",
    "#         self.configs = configs\n",
    "#\n",
    "#         self.cross_entropy = nn.CrossEntropyLoss()\n",
    "#         self.feature_extractor = backbone(configs)\n",
    "#         self.classifier = classifier(configs)\n",
    "#         self.network = nn.Sequential(self.feature_extractor, self.classifier)\n",
    "#\n",
    "#     # update function is common to all algorithms\n",
    "#     def update(self, src_loader, trg_loader, avg_meter, logger):\n",
    "#         # defining best and last model\n",
    "#         best_src_risk = float('inf')\n",
    "#         best_model = None\n",
    "#\n",
    "#         for epoch in range(1, self.hparams[\"num_epochs\"] + 1):\n",
    "#\n",
    "#             # training loop\n",
    "#             self.training_epoch(src_loader, trg_loader, avg_meter, epoch)\n",
    "#\n",
    "#             # saving the best model based on src risk\n",
    "#             if (epoch + 1) % 10 == 0 and avg_meter['Src_cls_loss'].avg < best_src_risk:\n",
    "#                 best_src_risk = avg_meter['Src_cls_loss'].avg\n",
    "#                 best_model = deepcopy(self.network.state_dict())\n",
    "#\n",
    "#             logger.debug(f'[Epoch : {epoch}/{self.hparams[\"num_epochs\"]}]')\n",
    "#             for key, val in avg_meter.items():\n",
    "#                 logger.debug(f'{key}\\t: {val.avg:2.4f}')\n",
    "#             logger.debug(f'-------------------------------------')\n",
    "#\n",
    "#         last_model = self.network.state_dict()\n",
    "#\n",
    "#         return last_model, best_model\n",
    "#\n",
    "#     # train loop vary from one method to another\n",
    "#     def training_epoch(self, *args, **kwargs):\n",
    "#         raise NotImplementedError\n",
    "#\n",
    "#\n",
    "# class NO_ADAPT(Algorithm):\n",
    "#     \"\"\"\n",
    "#     Lower bound: train on source and test on target.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#         for src_x, src_y in src_loader:\n",
    "#\n",
    "#             src_x, src_y = src_x.to(self.device), src_y.to(self.device)\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             loss = src_cls_loss\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Src_cls_loss': src_cls_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class TARGET_ONLY(Algorithm):\n",
    "#     \"\"\"\n",
    "#     Upper bound: train on target and test on target.\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         for trg_x, trg_y in trg_loader:\n",
    "#\n",
    "#             trg_x, trg_y = trg_x.to(self.device), trg_y.to(self.device)\n",
    "#\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             trg_pred = self.classifier(trg_feat)\n",
    "#\n",
    "#             trg_cls_loss = self.cross_entropy(trg_pred, trg_y)\n",
    "#\n",
    "#             loss = trg_cls_loss\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Trg_cls_loss': trg_cls_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class Deep_Coral(Algorithm):\n",
    "#     \"\"\"\n",
    "#     Deep Coral: https://arxiv.org/abs/1607.01719\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # correlation alignment loss\n",
    "#         self.coral = CORAL()\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         # add if statement\n",
    "#\n",
    "#         if len(src_loader) > len(trg_loader):\n",
    "#             joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         else:\n",
    "#             joint_loader = enumerate(zip(itertools.cycle(src_loader), trg_loader))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(self.device)\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#\n",
    "#             coral_loss = self.coral(src_feat, trg_feat)\n",
    "#\n",
    "#             loss = self.hparams[\"coral_wt\"] * coral_loss + \\\n",
    "#                    self.hparams[\"src_cls_loss_wt\"] * src_cls_loss\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'Src_cls_loss': src_cls_loss.item(),\n",
    "#                       'coral_loss': coral_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class MMDA(Algorithm):\n",
    "#     \"\"\"\n",
    "#     MMDA: https://arxiv.org/abs/1901.00282\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Aligment losses\n",
    "#         self.mmd = MMD_loss()\n",
    "#         self.coral = CORAL()\n",
    "#         self.cond_ent = ConditionalEntropyLoss()\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(self.device)\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#\n",
    "#             coral_loss = self.coral(src_feat, trg_feat)\n",
    "#             mmd_loss = self.mmd(src_feat, trg_feat)\n",
    "#             cond_ent_loss = self.cond_ent(trg_feat)\n",
    "#\n",
    "#             loss = self.hparams[\"coral_wt\"] * coral_loss + \\\n",
    "#                    self.hparams[\"mmd_wt\"] * mmd_loss + \\\n",
    "#                    self.hparams[\"cond_ent_wt\"] * cond_ent_loss + \\\n",
    "#                    self.hparams[\"src_cls_loss_wt\"] * src_cls_loss\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'Coral_loss': coral_loss.item(), 'MMD_loss': mmd_loss.item(),\n",
    "#                       'cond_ent_wt': cond_ent_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class DANN(Algorithm):\n",
    "#     \"\"\"\n",
    "#     DANN: https://arxiv.org/abs/1505.07818\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Domain Discriminator\n",
    "#         self.domain_classifier = Discriminator(configs)\n",
    "#         self.optimizer_disc = torch.optim.Adam(\n",
    "#             self.domain_classifier.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"], betas=(0.5, 0.99)\n",
    "#         )\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#         # Combine dataloaders\n",
    "#         # Method 1 (min len of both domains)\n",
    "#         # joint_loader = enumerate(zip(src_loader, trg_loader))\n",
    "#\n",
    "#         # Method 2 (max len of both domains)\n",
    "#         # joint_loader =enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         num_batches = max(len(src_loader), len(trg_loader))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(self.device)\n",
    "#\n",
    "#             p = float(step + epoch * num_batches) / self.hparams[\"num_epochs\"] + 1 / num_batches\n",
    "#             alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "#\n",
    "#             # zero grad\n",
    "#             self.optimizer.zero_grad()\n",
    "#             self.optimizer_disc.zero_grad()\n",
    "#\n",
    "#             domain_label_src = torch.ones(len(src_x)).to(self.device)\n",
    "#             domain_label_trg = torch.zeros(len(trg_x)).to(self.device)\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#\n",
    "#             # Task classification  Loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred.squeeze(), src_y)\n",
    "#\n",
    "#             # Domain classification loss\n",
    "#             # source\n",
    "#             src_feat_reversed = ReverseLayerF.apply(src_feat, alpha)\n",
    "#             src_domain_pred = self.domain_classifier(src_feat_reversed)\n",
    "#             src_domain_loss = self.cross_entropy(src_domain_pred, domain_label_src.long())\n",
    "#\n",
    "#             # target\n",
    "#             trg_feat_reversed = ReverseLayerF.apply(trg_feat, alpha)\n",
    "#             trg_domain_pred = self.domain_classifier(trg_feat_reversed)\n",
    "#             trg_domain_loss = self.cross_entropy(trg_domain_pred, domain_label_trg.long())\n",
    "#\n",
    "#             # Total domain loss\n",
    "#             domain_loss = src_domain_loss + trg_domain_loss\n",
    "#\n",
    "#             loss = self.hparams[\"src_cls_loss_wt\"] * src_cls_loss + \\\n",
    "#                    self.hparams[\"domain_loss_wt\"] * domain_loss\n",
    "#\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#             self.optimizer_disc.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'Domain_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class CDAN(Algorithm):\n",
    "#     \"\"\"\n",
    "#     CDAN: https://arxiv.org/abs/1705.10667\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Aligment Losses\n",
    "#         self.criterion_cond = ConditionalEntropyLoss().to(device)\n",
    "#\n",
    "#         self.domain_classifier = Discriminator_CDAN(configs)\n",
    "#         self.random_layer = RandomLayer([configs.features_len * configs.final_out_channels, configs.num_classes],\n",
    "#                                         configs.features_len * configs.final_out_channels)\n",
    "#         self.optimizer_disc = torch.optim.Adam(\n",
    "#             self.domain_classifier.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"])\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(self.device)\n",
    "#             # prepare true domain labels\n",
    "#             domain_label_src = torch.ones(len(src_x)).to(self.device)\n",
    "#             domain_label_trg = torch.zeros(len(trg_x)).to(self.device)\n",
    "#             domain_label_concat = torch.cat((domain_label_src, domain_label_trg), 0).long()\n",
    "#\n",
    "#             # source features and predictions\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             # target features and predictions\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             trg_pred = self.classifier(trg_feat)\n",
    "#\n",
    "#             # concatenate features and predictions\n",
    "#             feat_concat = torch.cat((src_feat, trg_feat), dim=0)\n",
    "#             pred_concat = torch.cat((src_pred, trg_pred), dim=0)\n",
    "#\n",
    "#             # Domain classification loss\n",
    "#             feat_x_pred = torch.bmm(pred_concat.unsqueeze(2), feat_concat.unsqueeze(1)).detach()\n",
    "#             disc_prediction = self.domain_classifier(feat_x_pred.view(-1, pred_concat.size(1) * feat_concat.size(1)))\n",
    "#             disc_loss = self.cross_entropy(disc_prediction, domain_label_concat)\n",
    "#\n",
    "#             # update Domain classification\n",
    "#             self.optimizer_disc.zero_grad()\n",
    "#             disc_loss.backward()\n",
    "#             self.optimizer_disc.step()\n",
    "#\n",
    "#             # prepare fake domain labels for training the feature extractor\n",
    "#             domain_label_src = torch.zeros(len(src_x)).long().to(self.device)\n",
    "#             domain_label_trg = torch.ones(len(trg_x)).long().to(self.device)\n",
    "#             domain_label_concat = torch.cat((domain_label_src, domain_label_trg), 0)\n",
    "#\n",
    "#             # Repeat predictions after updating discriminator\n",
    "#             feat_x_pred = torch.bmm(pred_concat.unsqueeze(2), feat_concat.unsqueeze(1))\n",
    "#             disc_prediction = self.domain_classifier(feat_x_pred.view(-1, pred_concat.size(1) * feat_concat.size(1)))\n",
    "#             # loss of domain discriminator according to fake labels\n",
    "#\n",
    "#             domain_loss = self.cross_entropy(disc_prediction, domain_label_concat)\n",
    "#\n",
    "#             # Task classification  Loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred.squeeze(), src_y)\n",
    "#\n",
    "#             # conditional entropy loss.\n",
    "#             loss_trg_cent = self.criterion_cond(trg_pred)\n",
    "#\n",
    "#             # total loss\n",
    "#             loss = self.hparams[\"src_cls_loss_wt\"] * src_cls_loss + self.hparams[\"domain_loss_wt\"] * domain_loss + \\\n",
    "#                    self.hparams[\"cond_ent_wt\"] * loss_trg_cent\n",
    "#\n",
    "#             # update feature extractor\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'Domain_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item(),\n",
    "#                       'cond_ent_loss': loss_trg_cent.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class DIRT(Algorithm):\n",
    "#     \"\"\"\n",
    "#     DIRT-T: https://arxiv.org/abs/1802.08735\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Aligment losses\n",
    "#         self.criterion_cond = ConditionalEntropyLoss().to(device)\n",
    "#         self.vat_loss = VAT(self.network, device).to(device)\n",
    "#         self.ema = EMA(0.998)\n",
    "#         self.ema.register(self.network)\n",
    "#\n",
    "#         # Discriminator\n",
    "#         self.domain_classifier = Discriminator(configs)\n",
    "#         self.optimizer_disc = torch.optim.Adam(\n",
    "#             self.domain_classifier.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(self.device)\n",
    "#             # prepare true domain labels\n",
    "#             domain_label_src = torch.ones(len(src_x)).to(self.device)\n",
    "#             domain_label_trg = torch.zeros(len(trg_x)).to(self.device)\n",
    "#             domain_label_concat = torch.cat((domain_label_src, domain_label_trg), 0).long()\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             # target features and predictions\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             trg_pred = self.classifier(trg_feat)\n",
    "#\n",
    "#             # concatenate features and predictions\n",
    "#             feat_concat = torch.cat((src_feat, trg_feat), dim=0)\n",
    "#\n",
    "#             # Domain classification loss\n",
    "#             disc_prediction = self.domain_classifier(feat_concat.detach())\n",
    "#             disc_loss = self.cross_entropy(disc_prediction, domain_label_concat)\n",
    "#\n",
    "#             # update Domain classification\n",
    "#             self.optimizer_disc.zero_grad()\n",
    "#             disc_loss.backward()\n",
    "#             self.optimizer_disc.step()\n",
    "#\n",
    "#             # prepare fake domain labels for training the feature extractor\n",
    "#             domain_label_src = torch.zeros(len(src_x)).long().to(self.device)\n",
    "#             domain_label_trg = torch.ones(len(trg_x)).long().to(self.device)\n",
    "#             domain_label_concat = torch.cat((domain_label_src, domain_label_trg), 0)\n",
    "#\n",
    "#             # Repeat predictions after updating discriminator\n",
    "#             disc_prediction = self.domain_classifier(feat_concat)\n",
    "#\n",
    "#             # loss of domain discriminator according to fake labels\n",
    "#             domain_loss = self.cross_entropy(disc_prediction, domain_label_concat)\n",
    "#\n",
    "#             # Task classification  Loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred.squeeze(), src_y)\n",
    "#\n",
    "#             # conditional entropy loss.\n",
    "#             loss_trg_cent = self.criterion_cond(trg_pred)\n",
    "#\n",
    "#             # Virual advariarial training loss\n",
    "#             loss_src_vat = self.vat_loss(src_x, src_pred)\n",
    "#             loss_trg_vat = self.vat_loss(trg_x, trg_pred)\n",
    "#             total_vat = loss_src_vat + loss_trg_vat\n",
    "#             # total loss\n",
    "#             loss = self.hparams[\"src_cls_loss_wt\"] * src_cls_loss + self.hparams[\"domain_loss_wt\"] * domain_loss + \\\n",
    "#                    self.hparams[\"cond_ent_wt\"] * loss_trg_cent + self.hparams[\"vat_loss_wt\"] * total_vat\n",
    "#\n",
    "#             # update exponential moving average\n",
    "#             self.ema(self.network)\n",
    "#\n",
    "#             # update feature extractor\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'Domain_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item(),\n",
    "#                       'cond_ent_loss': loss_trg_cent.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class DSAN(Algorithm):\n",
    "#     \"\"\"\n",
    "#     DSAN: https://ieeexplore.ieee.org/document/9085896\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Alignment losses\n",
    "#         self.loss_LMMD = LMMD_loss(device=device, class_num=configs.num_classes).to(device)\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             # extract target features\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             trg_pred = self.classifier(trg_feat)\n",
    "#\n",
    "#             # calculate lmmd loss\n",
    "#             domain_loss = self.loss_LMMD.get_loss(src_feat, trg_feat, src_y,\n",
    "#                                                   torch.nn.functional.softmax(trg_pred, dim=1))\n",
    "#\n",
    "#             # calculate source classification loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             # calculate the total loss\n",
    "#             loss = self.hparams[\"domain_loss_wt\"] * domain_loss + \\\n",
    "#                    self.hparams[\"src_cls_loss_wt\"] * src_cls_loss\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'LMMD_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class HoMM(Algorithm):\n",
    "#     \"\"\"\n",
    "#     HoMM: https://arxiv.org/pdf/1912.11976.pdf\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # aligment losses\n",
    "#         self.coral = CORAL()\n",
    "#         self.HoMM_loss = HoMM_loss()\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             # extract target features\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             trg_pred = self.classifier(trg_feat)\n",
    "#\n",
    "#             # calculate source classification loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             # calculate lmmd loss\n",
    "#             domain_loss = self.HoMM_loss(src_feat, trg_feat)\n",
    "#\n",
    "#             # calculate the total loss\n",
    "#             loss = self.hparams[\"domain_loss_wt\"] * domain_loss + \\\n",
    "#                    self.hparams[\"src_cls_loss_wt\"] * src_cls_loss\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'HoMM_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class DDC(Algorithm):\n",
    "#     \"\"\"\n",
    "#     DDC: https://arxiv.org/abs/1412.3474\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Aligment losses\n",
    "#         self.mmd_loss = MMD_loss()\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#             # extract source features\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             # extract target features\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#\n",
    "#             # calculate source classification loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             # calculate mmd loss\n",
    "#             domain_loss = self.mmd_loss(src_feat, trg_feat)\n",
    "#\n",
    "#             # calculate the total loss\n",
    "#             loss = self.hparams[\"domain_loss_wt\"] * domain_loss + \\\n",
    "#                    self.hparams[\"src_cls_loss_wt\"] * src_cls_loss\n",
    "#\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'MMD_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class CoDATS(Algorithm):\n",
    "#     \"\"\"\n",
    "#     CoDATS: https://arxiv.org/pdf/2005.10996.pdf\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # we replace the original classifier with codats the classifier\n",
    "#         # remember to use same name of self.classifier, as we use it for the model evaluation\n",
    "#         self.classifier = codats_classifier(configs)\n",
    "#         self.network = nn.Sequential(self.feature_extractor, self.classifier)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Domain classifier\n",
    "#         self.domain_classifier = Discriminator(configs)\n",
    "#\n",
    "#         self.optimizer_disc = torch.optim.Adam(\n",
    "#             self.domain_classifier.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"], betas=(0.5, 0.99)\n",
    "#         )\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         num_batches = max(len(src_loader), len(trg_loader))\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#\n",
    "#             p = float(step + epoch * num_batches) / self.hparams[\"num_epochs\"] + 1 / num_batches\n",
    "#             alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "#\n",
    "#             # zero grad\n",
    "#             self.optimizer.zero_grad()\n",
    "#             self.optimizer_disc.zero_grad()\n",
    "#\n",
    "#             domain_label_src = torch.ones(len(src_x)).to(self.device)\n",
    "#             domain_label_trg = torch.zeros(len(trg_x)).to(self.device)\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#\n",
    "#             # Task classification  Loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred.squeeze(), src_y)\n",
    "#\n",
    "#             # Domain classification loss\n",
    "#             # source\n",
    "#             src_feat_reversed = ReverseLayerF.apply(src_feat, alpha)\n",
    "#             src_domain_pred = self.domain_classifier(src_feat_reversed)\n",
    "#             src_domain_loss = self.cross_entropy(src_domain_pred, domain_label_src.long())\n",
    "#\n",
    "#             # target\n",
    "#             trg_feat_reversed = ReverseLayerF.apply(trg_feat, alpha)\n",
    "#             trg_domain_pred = self.domain_classifier(trg_feat_reversed)\n",
    "#             trg_domain_loss = self.cross_entropy(trg_domain_pred, domain_label_trg.long())\n",
    "#\n",
    "#             # Total domain loss\n",
    "#             domain_loss = src_domain_loss + trg_domain_loss\n",
    "#\n",
    "#             loss = self.hparams[\"src_cls_loss_wt\"] * src_cls_loss + \\\n",
    "#                    self.hparams[\"domain_loss_wt\"] * domain_loss\n",
    "#\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#             self.optimizer_disc.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'Domain_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class AdvSKM(Algorithm):\n",
    "#     \"\"\"\n",
    "#     AdvSKM: https://www.ijcai.org/proceedings/2021/0378.pdf\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Aligment losses\n",
    "#         self.mmd_loss = MMD_loss()\n",
    "#         self.AdvSKM_embedder = AdvSKM_Disc(configs).to(device)\n",
    "#         self.optimizer_disc = torch.optim.Adam(\n",
    "#             self.AdvSKM_embedder.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred = self.classifier(src_feat)\n",
    "#\n",
    "#             # extract target features\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#\n",
    "#             source_embedding_disc = self.AdvSKM_embedder(src_feat.detach())\n",
    "#             target_embedding_disc = self.AdvSKM_embedder(trg_feat.detach())\n",
    "#             mmd_loss = - self.mmd_loss(source_embedding_disc, target_embedding_disc)\n",
    "#             mmd_loss.requires_grad = True\n",
    "#\n",
    "#             # update discriminator\n",
    "#             self.optimizer_disc.zero_grad()\n",
    "#             mmd_loss.backward()\n",
    "#             self.optimizer_disc.step()\n",
    "#\n",
    "#             # calculate source classification loss\n",
    "#             src_cls_loss = self.cross_entropy(src_pred, src_y)\n",
    "#\n",
    "#             # domain loss.\n",
    "#             source_embedding_disc = self.AdvSKM_embedder(src_feat)\n",
    "#             target_embedding_disc = self.AdvSKM_embedder(trg_feat)\n",
    "#\n",
    "#             mmd_loss_adv = self.mmd_loss(source_embedding_disc, target_embedding_disc)\n",
    "#             mmd_loss_adv.requires_grad = True\n",
    "#\n",
    "#             # calculate the total loss\n",
    "#             loss = self.hparams[\"domain_loss_wt\"] * mmd_loss_adv + \\\n",
    "#                    self.hparams[\"src_cls_loss_wt\"] * src_cls_loss\n",
    "#\n",
    "#             # update optimizer\n",
    "#             self.optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'MMD_loss': mmd_loss_adv.item(), 'Src_cls_loss': src_cls_loss.item()}\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#\n",
    "# class SASA(Algorithm):\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # feature_length for classifier\n",
    "#         configs.features_len = 1\n",
    "#         self.classifier = classifier(configs)\n",
    "#         # feature length for feature extractor\n",
    "#         configs.features_len = 1\n",
    "#         self.feature_extractor = CNN_ATTN(configs)\n",
    "#         self.network = nn.Sequential(self.feature_extractor, self.classifier)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#\n",
    "#             # Extract features\n",
    "#             src_feature = self.feature_extractor(src_x)\n",
    "#             tgt_feature = self.feature_extractor(trg_x)\n",
    "#\n",
    "#             # source classification loss\n",
    "#             y_pred = self.classifier(src_feature)\n",
    "#             src_cls_loss = self.cross_entropy(y_pred, src_y)\n",
    "#\n",
    "#             # MMD loss\n",
    "#             domain_loss_intra = self.mmd_loss(src_struct=src_feature,\n",
    "#                                               tgt_struct=tgt_feature, weight=self.hparams['domain_loss_wt'])\n",
    "#\n",
    "#             # total loss\n",
    "#             total_loss = self.hparams['src_cls_loss_wt'] * src_cls_loss + domain_loss_intra\n",
    "#\n",
    "#             # remove old gradients\n",
    "#             self.optimizer.zero_grad()\n",
    "#             # calculate gradients\n",
    "#             total_loss.backward()\n",
    "#             # update the weights\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': total_loss.item(), 'MMD_loss': domain_loss_intra.item(),\n",
    "#                       'Src_cls_loss': src_cls_loss.item()}\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#     def mmd_loss(self, src_struct, tgt_struct, weight):\n",
    "#         delta = torch.mean(src_struct - tgt_struct, dim=-2)\n",
    "#         loss_value = torch.norm(delta, 2) * weight\n",
    "#         return loss_value\n",
    "#\n",
    "#\n",
    "# class CoTMix(Algorithm):\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Aligment losses\n",
    "#         self.contrastive_loss = NTXentLoss(device, hparams[\"batch_size\"], 0.2, True)\n",
    "#         self.entropy_loss = ConditionalEntropyLoss()\n",
    "#         self.sup_contrastive_loss = SupConLoss(device)\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#\n",
    "#             # ====== Temporal Mixup =====================\n",
    "#             src_dominant, trg_dominant = self.temporal_mixup(src_x, trg_x)\n",
    "#\n",
    "#             # ====== Source =====================\n",
    "#             self.optimizer.zero_grad()\n",
    "#\n",
    "#             # Src original features\n",
    "#             src_orig_feat = self.feature_extractor(src_x)\n",
    "#             src_orig_logits = self.classifier(src_orig_feat)\n",
    "#\n",
    "#             # Target original features\n",
    "#             trg_orig_feat = self.feature_extractor(trg_x)\n",
    "#             trg_orig_logits = self.classifier(trg_orig_feat)\n",
    "#\n",
    "#             # -----------  The two main losses\n",
    "#             # Cross-Entropy loss\n",
    "#             src_cls_loss = self.cross_entropy(src_orig_logits, src_y)\n",
    "#             loss = src_cls_loss * round(self.hparams[\"src_cls_weight\"], 2)\n",
    "#\n",
    "#             # Target Entropy loss\n",
    "#             trg_entropy_loss = self.entropy_loss(trg_orig_logits)\n",
    "#             loss += trg_entropy_loss * round(self.hparams[\"trg_entropy_weight\"], 2)\n",
    "#\n",
    "#             # -----------  Auxiliary losses\n",
    "#             # Extract source-dominant mixup features.\n",
    "#             src_dominant_feat = self.feature_extractor(src_dominant)\n",
    "#             src_dominant_logits = self.classifier(src_dominant_feat)\n",
    "#\n",
    "#             # supervised contrastive loss on source domain side\n",
    "#             src_concat = torch.cat([src_orig_logits.unsqueeze(1), src_dominant_logits.unsqueeze(1)], dim=1)\n",
    "#             src_supcon_loss = self.sup_contrastive_loss(src_concat, src_y)\n",
    "#             loss += src_supcon_loss * round(self.hparams[\"src_supCon_weight\"], 2)\n",
    "#\n",
    "#             # Extract target-dominant mixup features.\n",
    "#             trg_dominant_feat = self.feature_extractor(trg_dominant)\n",
    "#             trg_dominant_logits = self.classifier(trg_dominant_feat)\n",
    "#\n",
    "#             # Unsupervised contrastive loss on target domain side\n",
    "#             trg_con_loss = self.contrastive_loss(trg_orig_logits, trg_dominant_logits)\n",
    "#             loss += trg_con_loss * round(self.hparams[\"trg_cont_weight\"], 2)\n",
    "#\n",
    "#             loss.backward()\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(),\n",
    "#                       'src_cls_loss': src_cls_loss.item(),\n",
    "#                       'trg_entropy_loss': trg_entropy_loss.item(),\n",
    "#                       'src_supcon_loss': src_supcon_loss.item(),\n",
    "#                       'trg_con_loss': trg_con_loss.item()\n",
    "#                       }\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#     def temporal_mixup(self, src_x, trg_x):\n",
    "#\n",
    "#         mix_ratio = round(self.hparams[\"mix_ratio\"], 2)\n",
    "#         temporal_shift = self.hparams[\"temporal_shift\"]\n",
    "#         h = temporal_shift // 2  # half\n",
    "#\n",
    "#         src_dominant = mix_ratio * src_x + (1 - mix_ratio) * \\\n",
    "#                        torch.mean(torch.stack([torch.roll(trg_x, -i, 2) for i in range(-h, h)], 2), 2)\n",
    "#\n",
    "#         trg_dominant = mix_ratio * trg_x + (1 - mix_ratio) * \\\n",
    "#                        torch.mean(torch.stack([torch.roll(src_x, -i, 2) for i in range(-h, h)], 2), 2)\n",
    "#\n",
    "#         return src_dominant, trg_dominant\n",
    "#\n",
    "#\n",
    "# # Untied Approaches: (MCD)\n",
    "# class MCD(Algorithm):\n",
    "#     \"\"\"\n",
    "#     Maximum Classifier Discrepancy for Unsupervised Domain Adaptation\n",
    "#     MCD: https://arxiv.org/pdf/1712.02560.pdf\n",
    "#     \"\"\"\n",
    "#\n",
    "#     def __init__(self, backbone, configs, hparams, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         self.feature_extractor = backbone(configs)\n",
    "#         self.classifier = classifier(configs)\n",
    "#         self.classifier2 = classifier(configs)\n",
    "#\n",
    "#         self.network = nn.Sequential(self.feature_extractor, self.classifier)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer_fe = torch.optim.Adam(\n",
    "#             self.feature_extractor.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer_c1 = torch.optim.Adam(\n",
    "#             self.classifier.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer_c2 = torch.optim.Adam(\n",
    "#             self.classifier2.parameters(),\n",
    "#             lr=hparams[\"learning_rate\"],\n",
    "#             weight_decay=hparams[\"weight_decay\"]\n",
    "#         )\n",
    "#\n",
    "#         self.lr_scheduler_fe = StepLR(self.optimizer_fe, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         self.lr_scheduler_c1 = StepLR(self.optimizer_c1, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#         self.lr_scheduler_c2 = StepLR(self.optimizer_c2, step_size=hparams['step_size'], gamma=hparams['lr_decay'])\n",
    "#\n",
    "#         # hparams\n",
    "#         self.hparams = hparams\n",
    "#         # device\n",
    "#         self.device = device\n",
    "#\n",
    "#         # Aligment losses\n",
    "#         self.mmd_loss = MMD_loss()\n",
    "#\n",
    "#     def update(self, src_loader, trg_loader, avg_meter, logger):\n",
    "#         # defining best and last model\n",
    "#         best_src_risk = float('inf')\n",
    "#         best_model = None\n",
    "#\n",
    "#         for epoch in range(1, self.hparams[\"num_epochs\"] + 1):\n",
    "#\n",
    "#             # source pretraining loop\n",
    "#             self.pretrain_epoch(src_loader, avg_meter)\n",
    "#\n",
    "#             # training loop\n",
    "#             self.training_epoch(src_loader, trg_loader, avg_meter, epoch)\n",
    "#\n",
    "#             # saving the best model based on src risk\n",
    "#             if (epoch + 1) % 10 == 0 and avg_meter['Src_cls_loss'].avg < best_src_risk:\n",
    "#                 best_src_risk = avg_meter['Src_cls_loss'].avg\n",
    "#                 best_model = deepcopy(self.network.state_dict())\n",
    "#\n",
    "#             logger.debug(f'[Epoch : {epoch}/{self.hparams[\"num_epochs\"]}]')\n",
    "#             for key, val in avg_meter.items():\n",
    "#                 logger.debug(f'{key}\\t: {val.avg:2.4f}')\n",
    "#             logger.debug(f'-------------------------------------')\n",
    "#\n",
    "#         last_model = self.network.state_dict()\n",
    "#\n",
    "#         return last_model, best_model\n",
    "#\n",
    "#     def pretrain_epoch(self, src_loader, avg_meter):\n",
    "#         for src_x, src_y in src_loader:\n",
    "#             src_x, src_y = src_x.to(self.device), src_y.to(self.device)\n",
    "#\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred1 = self.classifier(src_feat)\n",
    "#             src_pred2 = self.classifier2(src_feat)\n",
    "#\n",
    "#             src_cls_loss1 = self.cross_entropy(src_pred1, src_y)\n",
    "#             src_cls_loss2 = self.cross_entropy(src_pred2, src_y)\n",
    "#\n",
    "#             loss = src_cls_loss1 + src_cls_loss2\n",
    "#\n",
    "#             self.optimizer_c1.zero_grad()\n",
    "#             self.optimizer_c2.zero_grad()\n",
    "#             self.optimizer_fe.zero_grad()\n",
    "#\n",
    "#             loss.backward()\n",
    "#\n",
    "#             self.optimizer_c1.step()\n",
    "#             self.optimizer_c2.step()\n",
    "#             self.optimizer_fe.step()\n",
    "#\n",
    "#             losses = {'Src_cls_loss': loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in joint_loader:\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#\n",
    "#             # extract source features\n",
    "#             src_feat = self.feature_extractor(src_x)\n",
    "#             src_pred1 = self.classifier(src_feat)\n",
    "#             src_pred2 = self.classifier2(src_feat)\n",
    "#\n",
    "#             # source losses\n",
    "#             src_cls_loss1 = self.cross_entropy(src_pred1, src_y)\n",
    "#             src_cls_loss2 = self.cross_entropy(src_pred2, src_y)\n",
    "#             loss_s = src_cls_loss1 + src_cls_loss2\n",
    "#\n",
    "#             # Freeze the feature extractor\n",
    "#             for k, v in self.feature_extractor.named_parameters():\n",
    "#                 v.requires_grad = False\n",
    "#             # update C1 and C2 to maximize their difference on target sample\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             trg_pred1 = self.classifier(trg_feat.detach())\n",
    "#             trg_pred2 = self.classifier2(trg_feat.detach())\n",
    "#\n",
    "#             loss_dis = self.discrepancy(trg_pred1, trg_pred2)\n",
    "#\n",
    "#             loss = loss_s - loss_dis\n",
    "#\n",
    "#             loss.backward()\n",
    "#             self.optimizer_c1.step()\n",
    "#             self.optimizer_c2.step()\n",
    "#\n",
    "#             self.optimizer_c1.zero_grad()\n",
    "#             self.optimizer_c2.zero_grad()\n",
    "#             self.optimizer_fe.zero_grad()\n",
    "#\n",
    "#             # Freeze the classifiers\n",
    "#             for k, v in self.classifier.named_parameters():\n",
    "#                 v.requires_grad = False\n",
    "#             for k, v in self.classifier2.named_parameters():\n",
    "#                 v.requires_grad = False\n",
    "#                 # Freeze the feature extractor\n",
    "#             for k, v in self.feature_extractor.named_parameters():\n",
    "#                 v.requires_grad = True\n",
    "#             # update feature extractor to minimize the discrepaqncy on target samples\n",
    "#             trg_feat = self.feature_extractor(trg_x)\n",
    "#             trg_pred1 = self.classifier(trg_feat)\n",
    "#             trg_pred2 = self.classifier2(trg_feat)\n",
    "#\n",
    "#             loss_dis_t = self.discrepancy(trg_pred1, trg_pred2)\n",
    "#             domain_loss = self.hparams[\"domain_loss_wt\"] * loss_dis_t\n",
    "#\n",
    "#             domain_loss.backward()\n",
    "#             self.optimizer_fe.step()\n",
    "#\n",
    "#             self.optimizer_fe.zero_grad()\n",
    "#             self.optimizer_c1.zero_grad()\n",
    "#             self.optimizer_c2.zero_grad()\n",
    "#\n",
    "#             losses = {'Total_loss': loss.item(), 'MMD_loss': domain_loss.item()}\n",
    "#\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler_fe.step()\n",
    "#         self.lr_scheduler_c1.step()\n",
    "#         self.lr_scheduler_c2.step()\n",
    "#\n",
    "#     def discrepancy(self, out1, out2):\n",
    "#\n",
    "#         return torch.mean(torch.abs(F.softmax(out1) - F.softmax(out2)))"
   ],
   "id": "defdafe0ef9b4b59",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:14:55.141302Z",
     "start_time": "2024-09-25T21:14:55.139593Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4d9c1f6cc9c7e77d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Updated SASA",
   "id": "1c06d446ac7599e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T21:15:06.982529Z",
     "start_time": "2024-09-25T21:15:06.979481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# class SASA(Algorithm):\n",
    "#\n",
    "#     def __init__(self, backbone, configs, device):\n",
    "#         super().__init__(configs, backbone)\n",
    "#\n",
    "#         # feature_length for classifier\n",
    "#         configs.features_len = 1\n",
    "#         self.classifier = classifier(configs)\n",
    "#\n",
    "#         # feature length for feature extractor\n",
    "#         configs.features_len = 1\n",
    "#         self.feature_extractor = GTN(configs)\n",
    "#         self.network = nn.Sequential(self.feature_extractor, self.classifier)\n",
    "#\n",
    "#         # optimizer and scheduler\n",
    "#         self.optimizer = torch.optim.Adam(\n",
    "#             self.network.parameters(),\n",
    "#             lr=configs.learning_rate,\n",
    "#             weight_decay=configs.weight_decay\n",
    "#         )\n",
    "#         self.lr_scheduler = StepLR(self.optimizer, step_size=configs.step_size, gamma=configs.lr_decay)\n",
    "#\n",
    "#         self.configs = configs\n",
    "#         self.device = device\n",
    "#\n",
    "#     def training_epoch(self, src_loader, trg_loader, avg_meter, epoch, stage='train'):\n",
    "#\n",
    "#         # Construct Joint Loaders\n",
    "#         joint_loader = enumerate(zip(src_loader, itertools.cycle(trg_loader)))\n",
    "#         for step, ((src_x, src_y), (trg_x, _)) in tqdm.tqdm(joint_loader, desc='Training', total=len(src_loader)):\n",
    "#             src_x, src_y, trg_x = src_x.to(self.device), src_y.to(self.device), trg_x.to(\n",
    "#                 self.device)  # extract source features\n",
    "#\n",
    "#             # Extract features\n",
    "#             src_feature = self.feature_extractor(stage, src_x)\n",
    "#             tgt_feature = self.feature_extractor(stage, trg_x)\n",
    "#\n",
    "#             # source classification loss\n",
    "#             y_pred = self.classifier(src_feature)\n",
    "#             src_cls_loss = self.cross_entropy(y_pred, src_y)\n",
    "#\n",
    "#             # MMD loss\n",
    "#             domain_loss_intra = self.mmd_loss(src_struct=src_feature,\n",
    "#                                               tgt_struct=tgt_feature, weight=self.configs.sasa_domain_loss_wt)\n",
    "#\n",
    "#             # total loss\n",
    "#             total_loss = self.configs.sasa_src_cls_loss_wt * src_cls_loss + domain_loss_intra\n",
    "#\n",
    "#             # remove old gradients\n",
    "#             self.optimizer.zero_grad()\n",
    "#             # calculate gradients\n",
    "#             total_loss.backward()\n",
    "#             # update the weights\n",
    "#             self.optimizer.step()\n",
    "#\n",
    "#             losses = {'Total_loss': total_loss.item(), 'MMD_loss': domain_loss_intra.item(),\n",
    "#                       'Src_cls_loss': src_cls_loss.item()}\n",
    "#             for key, val in losses.items():\n",
    "#                 avg_meter[key].update(val, 32)\n",
    "#\n",
    "#         self.lr_scheduler.step()\n",
    "#\n",
    "#     def mmd_loss(self, src_struct, tgt_struct, weight):\n",
    "#         delta = torch.mean(src_struct - tgt_struct, dim=-2)\n",
    "#         loss_value = torch.norm(delta, 2) * weight\n",
    "#\n",
    "#         return loss_value"
   ],
   "id": "c822cd48a45daf4e",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T15:42:17.425981Z",
     "start_time": "2024-09-27T15:42:17.424340Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8658eb0c1cac7fc5",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T15:42:17.434267Z",
     "start_time": "2024-09-27T15:42:17.432744Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2b719a0e3e83db76",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T15:42:17.436575Z",
     "start_time": "2024-09-27T15:42:17.435101Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9cc8fcf61134e5fb",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "f771640f111e8be",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
