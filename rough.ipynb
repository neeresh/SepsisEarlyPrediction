{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:41:59.365899Z",
     "start_time": "2024-07-31T21:41:58.306741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from models.custom_models.gtn import GatedTransformerNetwork\n",
    "from models.gtn.transformer import Transformer\n",
    "from utils.config import gtn_param\n",
    "from utils.loader import make_loader\n",
    "from utils.path_utils import project_root\n",
    "from utils.plot_metrics import plot_losses_and_accuracies\n",
    "\n",
    "device = 'cuda'\n",
    "config = gtn_param\n"
   ],
   "id": "11b4600521d42e9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "242ec37ffa0b11d8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cross Validation",
   "id": "8ddabcb24def64b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:58:45.179362Z",
     "start_time": "2024-07-31T21:57:53.325007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from train_gtn import initialize_experiment\n",
    "\n",
    "data_file = \"final_dataset.pickle\"\n",
    "training_examples, lengths_list, is_sepsis, writer, destination_path = initialize_experiment(data_file)\n",
    "\n",
    "sepsis = pd.Series(is_sepsis)\n",
    "positive_sepsis_idxs = sepsis[sepsis == 1].index\n",
    "negative_sepsis_idxs = sepsis[sepsis == 0].sample(frac=0.20).index\n",
    "all_samples = list(positive_sepsis_idxs) + list(negative_sepsis_idxs)\n",
    "np.random.shuffle(all_samples)\n",
    "\n",
    "print(f\"Number of positive samples: {len(positive_sepsis_idxs)}\")\n",
    "print(f\"Number of negative samples: {len(negative_sepsis_idxs)}\")\n",
    "\n",
    "# Reducing the samples to have balanced dataset\n",
    "batch_size = config['batch_size'] * torch.cuda.device_count()\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "logging.info(f\"Batch size: {batch_size}\")\n",
    "\n",
    "# Splitting dataset into train and test\n",
    "print(f\"Total samples: {len(all_samples)}\")\n",
    "\n",
    "train_indicies, temp_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)  # 80 20\n",
    "val_indicies, test_indicies = train_test_split(temp_indicies, test_size=0.5, random_state=42)  # 10 10\n",
    "\n",
    "# train_indicies, test_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)\n",
    "# train_loader, test_loader, train_indicies, test_indicies = make_loader(training_examples, lengths_list, is_sepsis,\n",
    "#                                                                        batch_size=batch_size, mode='padding',\n",
    "#                                                                        num_workers=4, train_indicies=train_indicies,\n",
    "#                                                                        test_indicies=test_indicies, include_val=True)\n",
    "\n",
    "train_loader, val_loader, test_loader, train_indicies, val_indices, test_indicies = make_loader(\n",
    "    training_examples, lengths_list, is_sepsis, batch_size=batch_size, mode='padding', num_workers=4,\n",
    "    train_indicies=train_indicies, test_indicies=test_indicies, val_indicies=val_indicies,\n",
    "    select_important_features=False, include_val=False)"
   ],
   "id": "df682875108f634c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datafile used: final_dataset.pickle\n",
      "Total number of patients: 40336\n",
      "Min recordings: 8 & Max recordings: 336\n",
      "Distribution of the SepsisLabel: \n",
      "0    37404\n",
      "1     2932\n",
      "Name: count, dtype: int64\n",
      "Number of positive samples: 2932\n",
      "Number of negative samples: 7481\n",
      "Batch size: 3\n",
      "Total samples: 10413\n",
      "Loading train and test from given indicies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding...: 100%|██████████| 8330/8330 [00:27<00:00, 304.48it/s]\n",
      "Padding...: 100%|██████████| 1042/1042 [00:03<00:00, 299.42it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 32\u001B[0m\n\u001B[1;32m     24\u001B[0m val_indicies, test_indicies \u001B[38;5;241m=\u001B[39m train_test_split(temp_indicies, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)  \u001B[38;5;66;03m# 10 10\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# train_indicies, test_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;66;03m# train_loader, test_loader, train_indicies, test_indicies = make_loader(training_examples, lengths_list, is_sepsis,\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m#                                                                        batch_size=batch_size, mode='padding',\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m#                                                                        num_workers=4, train_indicies=train_indicies,\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m#                                                                        test_indicies=test_indicies, include_val=True)\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m train_loader, val_loader, test_loader, train_indicies, val_indices, test_indicies \u001B[38;5;241m=\u001B[39m make_loader(\n\u001B[1;32m     33\u001B[0m     training_examples, lengths_list, is_sepsis, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpadding\u001B[39m\u001B[38;5;124m'\u001B[39m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     34\u001B[0m     train_indicies\u001B[38;5;241m=\u001B[39mtrain_indicies, test_indicies\u001B[38;5;241m=\u001B[39mtest_indicies, val_indicies\u001B[38;5;241m=\u001B[39mval_indicies,\n\u001B[1;32m     35\u001B[0m     select_important_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, include_val\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 6, got 4)"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7ecfb77893c693c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:51:57.149397Z",
     "start_time": "2024-07-31T21:51:55.635578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = torch.stack([train_loader.dataset[i][0] for i in range(len(train_loader.dataset))])\n",
    "labels = torch.tensor([train_loader.dataset[i][1] for i in range(len(train_loader.dataset))])\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kfold.split(data):\n",
    "    \n",
    "    train_index = torch.tensor(train_index)\n",
    "    test_index = torch.tensor(test_index)\n",
    "    \n",
    "    X_train_fold = data[train_index]\n",
    "    y_train_fold = labels[train_index]\n",
    "    X_test_fold = data[test_index]\n",
    "    y_test_fold = labels[test_index]\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train_fold, y_train_fold), batch_size=3, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test_fold, y_test_fold), batch_size=3, shuffle=False)\n",
    "    "
   ],
   "id": "8e5bd12b226d91c2",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:52:20.329957Z",
     "start_time": "2024-07-31T21:52:20.326873Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cf9b60fd596757ff",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:52:18.341874Z",
     "start_time": "2024-07-31T21:52:18.338976Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a3c799f9da660755",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:49:27.949814Z",
     "start_time": "2024-07-31T21:49:27.946561Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "beb4aa61917bf718",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T21:49:12.950302Z",
     "start_time": "2024-07-31T21:49:12.949046Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1696638fb5b8fa48",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TARNet",
   "id": "878ef6207dad6b3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:45.425151Z",
     "start_time": "2024-07-31T20:34:45.423390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from models.tarnet.multitask_transformer_class import MultitaskTransformerModel\n",
    "# from train_tarnet import load_model\n",
    "# from utils.config import tarnet_param\n"
   ],
   "id": "4966ddb06fcf56e1",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:46.953439Z",
     "start_time": "2024-07-31T20:34:46.951277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# config = tarnet_param\n",
    "# (d_input, d_channel), d_output = (336, 191), 2\n",
    "# \n",
    "# model = MultitaskTransformerModel(task_type=config['task_type'], device=config['device'],\n",
    "#                                       nclasses=d_output, seq_len=d_input, batch=16,\n",
    "#                                       input_size=d_channel, emb_size=config['emb_size'],\n",
    "#                                       nhead=config['nhead'], nhid=config['nhid'], nhid_tar=config['nhid_tar'],\n",
    "#                                       nhid_task=config['nhid_task'], nlayers=config['nlayers'],\n",
    "#                                       dropout=config['dropout'], )"
   ],
   "id": "6de76148dab21f25",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:48.536921Z",
     "start_time": "2024-07-31T20:34:48.535247Z"
    }
   },
   "cell_type": "code",
   "source": "# load_model(model, model_name='./saved_models/tarnet/tarnet_final_2_val.pkl')",
   "id": "4b7dc0a583314b40",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:50.266070Z",
     "start_time": "2024-07-31T20:34:50.263642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from train_tarnet import initialize_experiment\n",
    "# \n",
    "# # Getting Data and Loaders\n",
    "# data_file = \"final_dataset.pickle\"\n",
    "# training_examples, lengths_list, is_sepsis, writer, destination_path = initialize_experiment(data_file)\n",
    "# \n",
    "# sepsis = pd.Series(is_sepsis)\n",
    "# positive_sepsis_idxs = sepsis[sepsis == 1].index\n",
    "# negative_sepsis_idxs = sepsis[sepsis == 0].sample(frac=0.20).index\n",
    "# all_samples = list(positive_sepsis_idxs) + list(negative_sepsis_idxs)\n",
    "# np.random.shuffle(all_samples)\n",
    "# \n",
    "# logging.info(f\"Number of positive samples: {len(positive_sepsis_idxs)}\")\n",
    "# logging.info(f\"Number of negative samples: {len(negative_sepsis_idxs)}\")\n",
    "# \n",
    "# # Reducing the samples to have balanced dataset\n",
    "# batch_size = config['batch'] * torch.cuda.device_count()\n",
    "# print(f\"Batch size: {batch_size}\")\n",
    "# logging.info(f\"Batch size: {batch_size}\")\n",
    "# \n",
    "# # Splitting dataset into train and test\n",
    "# logging.info(f\"Total samples: {len(all_samples)}\")\n",
    "# \n",
    "# train_indicies, temp_indicies = train_test_split(all_samples, test_size=0.2, random_state=42)  # 80 20\n",
    "# val_indicies, test_indicies = train_test_split(temp_indicies, test_size=0.5, random_state=42)  # 10 10\n",
    "# \n",
    "# train_loader, val_loader, test_loader, train_indicies, val_indices, test_indicies = make_loader(\n",
    "#     training_examples, lengths_list, is_sepsis, batch_size=1, mode='padding', num_workers=4,\n",
    "#     train_indicies=train_indicies, test_indicies=test_indicies, val_indicies=val_indicies,\n",
    "#     select_important_features=False, include_val=True)"
   ],
   "id": "10e9c4fd2b2f5dec",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:34:51.858107Z",
     "start_time": "2024-07-31T20:34:51.856193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import math\n",
    "# import torch.nn.functional as F\n",
    "# \n",
    "# targets_list = []\n",
    "# predictions = []\n",
    "# probas = []\n",
    "# \n",
    "# def make_perfect_batch(X, num_inst, num_samples):\n",
    "#     extension = np.zeros((num_samples - num_inst, X.shape[1], X.shape[2]))\n",
    "#     X = np.concatenate((X, extension), axis=0)\n",
    "#     return X\n",
    "# \n",
    "# def tarnet_preprocessing(patient_data):\n",
    "#     # print(patient_data.shape, type(patient_data))\n",
    "#     patient_data = patient_data.detach().cpu().numpy()\n",
    "#     # print(patient_data.shape, type(patient_data))\n",
    "#     num_train_inst = patient_data.shape[0]\n",
    "#     num_train_samples = math.ceil(num_train_inst / 16) * 16  # Original model batch_size was 16\n",
    "#     patient_data = make_perfect_batch(patient_data, num_train_inst, num_train_samples)\n",
    "#     # print(patient_data.shape, type(patient_data))\n",
    "#     \n",
    "#     return torch.as_tensor(patient_data).float()\n",
    "# \n",
    "# for patient_data, targets in tqdm.tqdm(val_loader):\n",
    "#     patient_data = tarnet_preprocessing(patient_data)\n",
    "#     with torch.no_grad():\n",
    "#         patient_data = patient_data.to(device)\n",
    "#         outputs, _ = model(patient_data, task_type='classification')\n",
    "#         # outputs = outputs[0]\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         probabilities = F.softmax(outputs, dim=1)\n",
    "#     \n",
    "#         predicted_class = predicted.detach().cpu().numpy()[0]\n",
    "# \n",
    "#         predictions.append(predicted_class)\n",
    "#         targets_list.append(targets.detach().cpu().numpy()[0])\n",
    "#         probas.append(probabilities.detach().cpu().numpy()[0][predicted_class])"
   ],
   "id": "2892a08a6454f9ab",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T20:25:25.361007Z",
     "start_time": "2024-07-31T20:25:25.359639Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "feaa3cf2a7b64fd0",
   "outputs": [],
   "execution_count": 112
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
