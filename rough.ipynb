{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-05T22:27:55.648936Z",
     "start_time": "2024-09-05T22:27:55.647084Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:27:56.854256Z",
     "start_time": "2024-09-05T22:27:55.720437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from utils.path_utils import project_root\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n"
   ],
   "id": "e26363a27c9bea16",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:27:56.884441Z",
     "start_time": "2024-09-05T22:27:56.883214Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "35310e36b03c6b19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:27:56.937791Z",
     "start_time": "2024-09-05T22:27:56.931936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "parser.add_argument('--run_description', default='run1', type=str, help='Experiment Description')\n",
    "parser.add_argument('--seed', default=2023, type=int, help='seed value')\n",
    "\n",
    "parser.add_argument('--training_mode', default='pre_train', type=str, help='pre_train, fine_tune')\n",
    "parser.add_argument('--pretrain_dataset', default='SleepEEG', type=str,\n",
    "                    help='Dataset of choice: SleepEEG, FD_A, HAR, ECG')\n",
    "parser.add_argument('--target_dataset', default='Epilepsy', type=str,\n",
    "                    help='Dataset of choice: Epilepsy, FD_B, Gesture, EMG')\n",
    "\n",
    "parser.add_argument('--logs_save_dir', default='experiments_logs', type=str, help='saving directory')\n",
    "parser.add_argument('--device', default='cuda', type=str, help='cpu or cuda')\n",
    "parser.add_argument('--home_path', default=home_dir, type=str, help='Project home directory')\n",
    "parser.add_argument('--subset', action='store_true', default=False, help='use the subset of datasets')\n",
    "parser.add_argument('--log_epoch', default=5, type=int, help='print loss and metrix')\n",
    "parser.add_argument('--draw_similar_matrix', default=10, type=int, help='draw similarity matrix')\n",
    "parser.add_argument('--pretrain_lr', default=0.0001, type=float, help='pretrain learning rate')\n",
    "parser.add_argument('--lr', default=0.0001, type=float, help='learning rate')\n",
    "parser.add_argument('--use_pretrain_epoch_dir', default=None, type=str,\n",
    "                    help='choose the pretrain checkpoint to finetune')\n",
    "parser.add_argument('--pretrain_epoch', default=10, type=int, help='pretrain epochs')\n",
    "parser.add_argument('--finetune_epoch', default=300, type=int, help='finetune epochs')\n",
    "\n",
    "parser.add_argument('--masking_ratio', default=0.5, type=float, help='masking ratio')\n",
    "parser.add_argument('--positive_nums', default=3, type=int, help='positive series numbers')\n",
    "parser.add_argument('--lm', default=3, type=int, help='average masked lenght')\n",
    "\n",
    "parser.add_argument('--finetune_result_file_name', default=\"finetune_result.json\", type=str,\n",
    "                    help='finetune result json name')\n",
    "parser.add_argument('--temperature', type=float, default=0.2, help='temperature')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n"
   ],
   "id": "8f0f9109afd5d6f0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:27:56.985322Z",
     "start_time": "2024-09-05T22:27:56.984018Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "43753974148ee5d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.008239Z",
     "start_time": "2024-09-05T22:27:57.042669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def csv_to_pt():\n",
    "    patient_dir = os.path.join(project_root(), 'data', 'pt_files')\n",
    "    patient_files = sorted(os.listdir(patient_dir))\n",
    "    \n",
    "    lengths = pd.read_csv(os.path.join(project_root(), 'data', 'processed', 'lengths.txt'), header=None).values\n",
    "    is_sepsis = pd.read_csv(os.path.join(project_root(), 'data', 'processed', 'is_sepsis.txt'), header=None).values\n",
    "    \n",
    "    all_patients = {'samples': [], 'labels': []}\n",
    "    \n",
    "    max_time_step = 336\n",
    "    for idx, (file_name, length, sepsis) in tqdm.tqdm(enumerate(zip(patient_files, lengths, is_sepsis)), \n",
    "                                                      desc=\"Converting csv to .pt format: \", \n",
    "                                                      total=len(patient_files)):\n",
    "        \n",
    "        file = pd.read_csv(os.path.join(patient_dir, file_name))\n",
    "        \n",
    "        pad_width = ((0, max_time_step - len(file)), (0, 0))\n",
    "        file = np.pad(file, pad_width=pad_width, mode='constant').astype(np.float32)\n",
    "        \n",
    "        if len(file) == max_time_step:\n",
    "            all_patients['samples'].append(torch.from_numpy(file).unsqueeze(0))\n",
    "            all_patients['labels'].append(torch.tensor(sepsis[0], dtype=torch.float32).unsqueeze(0))\n",
    "        else:\n",
    "            raise ValueError(f\"Length {length} does not match length of patient {file_name} with length {len(file)}\")\n",
    "    \n",
    "    print('samples: ', type(all_patients['samples']), 'labels: ', type(all_patients['labels']))\n",
    "    \n",
    "    all_patients['samples'] = torch.cat(all_patients['samples'], dim=0)\n",
    "    all_patients['labels'] = torch.cat(all_patients['labels'], dim=0)\n",
    "    \n",
    "    return {'samples': all_patients['samples'], 'labels': all_patients['labels']}, lengths, is_sepsis\n",
    "\n",
    "all_patients, lengths, is_sepsis = csv_to_pt()\n",
    "\n",
    "# del all_patients, lengths, is_sepsis\n"
   ],
   "id": "82dd1aa314bcb4cf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting csv to .pt format: 100%|██████████| 20336/20336 [00:19<00:00, 1041.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples:  <class 'list'> labels:  <class 'list'>\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.013394Z",
     "start_time": "2024-09-05T22:28:17.012056Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dce16484e9dbbb54",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.067147Z",
     "start_time": "2024-09-05T22:28:17.062261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def geom_noise_mask_single(L, lm, masking_ratio):\n",
    "    \"\"\"\n",
    "    Randomly create a boolean mask of length `L`, consisting of subsequences of average length lm, masking with 0s a `masking_ratio`\n",
    "    proportion of the sequence L. The length of masking subsequences and intervals follow a geometric distribution.\n",
    "    Args:\n",
    "        L: length of mask and sequence to be masked\n",
    "        lm: average length of masking subsequences (streaks of 0s)\n",
    "        masking_ratio: proportion of L to be masked\n",
    "    Returns:\n",
    "        (L, ) boolean numpy array intended to mask ('drop') with 0s a sequence of length L\n",
    "    \"\"\"\n",
    "    keep_mask = np.ones(L, dtype=bool)\n",
    "    p_m = 1 / lm  # probability of each masking sequence stopping. parameter of geometric distribution.\n",
    "    p_u = p_m * masking_ratio / (\n",
    "            1 - masking_ratio)  # probability of each unmasked sequence stopping. parameter of geometric distribution.\n",
    "    p = [p_m, p_u]\n",
    "\n",
    "    # Start in state 0 with masking_ratio probability\n",
    "    state = int(np.random.rand() > masking_ratio)  # state 0 means masking, 1 means not masking\n",
    "    for i in range(L):\n",
    "        keep_mask[i] = state  # here it happens that state and masking value corresponding to state are identical\n",
    "        if np.random.rand() < p[state]:\n",
    "            state = 1 - state\n",
    "\n",
    "    return keep_mask\n",
    "\n",
    "\n",
    "def noise_mask(X, masking_ratio=0.25, lm=3, distribution='geometric', exclude_feats=None):\n",
    "    \"\"\"\n",
    "    Creates a random boolean mask of the same shape as X, with 0s at places where a feature should be masked.\n",
    "    Args:\n",
    "        X: (seq_length, feat_dim) numpy array of features corresponding to a single sample\n",
    "        masking_ratio: proportion of seq_length to be masked. At each time step, will also be the proportion of\n",
    "            feat_dim that will be masked on average\n",
    "        lm: average length of masking subsequences (streaks of 0s). Used only when `distribution` is 'geometric'.\n",
    "        distribution: whether each mask sequence element is sampled independently at random, or whether\n",
    "            sampling follows a markov chain (and thus is stateful), resulting in geometric distributions of\n",
    "            masked squences of a desired mean length `lm`\n",
    "        exclude_feats: iterable of indices corresponding to features to be excluded from masking (i.e. to remain all 1s)\n",
    "    Returns:\n",
    "        boolean numpy array with the same shape as X, with 0s at places where a feature should be masked\n",
    "    \"\"\"\n",
    "    if exclude_feats is not None:\n",
    "        exclude_feats = set(exclude_feats)\n",
    "\n",
    "    if distribution == 'geometric':  # stateful (Markov chain)\n",
    "        mask = geom_noise_mask_single(X.shape[0] * X.shape[1] * X.shape[2], lm, masking_ratio)\n",
    "        mask = mask.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "        \n",
    "    elif distribution == 'masked_tail':\n",
    "        mask = np.ones(X.shape, dtype=bool)\n",
    "        for m in range(X.shape[0]):  # feature dimension\n",
    "\n",
    "            keep_mask = np.zeros_like(mask[m, :], dtype=bool)\n",
    "            n = math.ceil(keep_mask.shape[1] * (1 - masking_ratio))\n",
    "            keep_mask[:, :n] = True\n",
    "            mask[m, :] = keep_mask  # time dimension\n",
    "            \n",
    "    elif distribution == 'masked_head':\n",
    "        mask = np.ones(X.shape, dtype=bool)\n",
    "        for m in range(X.shape[0]):  # feature dimension\n",
    "\n",
    "            keep_mask = np.zeros_like(mask[m, :], dtype=bool)\n",
    "            n = math.ceil(keep_mask.shape[1] * masking_ratio)\n",
    "            keep_mask[:, n:] = True\n",
    "            mask[m, :] = keep_mask  # time dimension\n",
    "    else:  # each position is independent Bernoulli with p = 1 - masking_ratio\n",
    "        mask = np.random.choice(np.array([True, False]), size=X.shape, replace=True,\n",
    "                                p=(1 - masking_ratio, masking_ratio))\n",
    "\n",
    "    return torch.tensor(mask)\n",
    "\n",
    "def data_transform_masked4cl(sample, masking_ratio, lm, positive_nums=None, distribution='geometric'):\n",
    "    \"\"\"Masked time series in time dimension\"\"\"\n",
    "\n",
    "    if positive_nums is None:\n",
    "        positive_nums = math.ceil(1.5 / (1 - masking_ratio))\n",
    "        \n",
    "    sample = sample.permute(0, 2, 1)  # (batch_size, channels, time_steps)\n",
    "    \n",
    "    # Creating the batch in #positive_nums sets\n",
    "    sample_repeat = sample.repeat(positive_nums, 1, 1)  # (batch_size*positive_num, channels, time steps)\n",
    "\n",
    "    mask = noise_mask(sample_repeat, masking_ratio, lm, distribution=distribution)\n",
    "    x_masked = mask * sample_repeat\n",
    "\n",
    "    return x_masked.permute(0, 2, 1), mask.permute(0, 2, 1)\n",
    "\n",
    "# data_masked_m, mask = data_transform_masked4cl(all_patients['samples'][:32], 0.5, 3, positive_nums=1, distribution='geometric')\n"
   ],
   "id": "df2ee9f255cd3528",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.106453Z",
     "start_time": "2024-09-05T22:28:17.105152Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e14802c72ae0ed5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.153247Z",
     "start_time": "2024-09-05T22:28:17.149925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class Load_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, TSlength_aligned, training_mode):\n",
    "        \n",
    "        super(Load_Dataset, self).__init__()\n",
    "        self.training_mode = training_mode\n",
    "        \n",
    "        X_train = dataset[\"samples\"]\n",
    "        y_train = dataset[\"labels\"]\n",
    "        \n",
    "        # shuffle\n",
    "        data = list(zip(X_train, y_train))\n",
    "        np.random.shuffle(data)\n",
    "        \n",
    "        X_train, y_train = zip(*data)\n",
    "        X_train, y_train = torch.stack(list(X_train), dim=0), torch.stack(list(y_train), dim=0)\n",
    "\n",
    "        if len(X_train.shape) < 3:\n",
    "            X_train = X_train.unsqueeze(2)\n",
    "\n",
    "        # if X_train.shape.index(min(X_train.shape)) != 1:  # make sure the Channels in second dim\n",
    "        #     X_train = X_train.permute(0, 2, 1)\n",
    "\n",
    "        \"\"\"Align the TS length between source and target datasets\"\"\"\n",
    "        # X_train = X_train[:, :1, :int(config.TSlength_aligned)] # take the first 178 samples\n",
    "        X_train = X_train[:, :, :int(TSlength_aligned)]\n",
    "        \n",
    "        if isinstance(X_train, np.ndarray):\n",
    "            self.x_data = torch.from_numpy(X_train)\n",
    "            self.y_data = torch.from_numpy(y_train).long()\n",
    "        else:\n",
    "            self.x_data = X_train\n",
    "            self.y_data = y_train\n",
    "\n",
    "        self.len = X_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    "
   ],
   "id": "813e977f40d98345",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.197338Z",
     "start_time": "2024-09-05T22:28:17.195942Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a1a86d99d645f058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.253697Z",
     "start_time": "2024-09-05T22:28:17.241784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.simmtm.gtn.encoder import Encoder\n",
    "from simmtm.loss import ContrastiveWeight, AggregationRebuild, AutomaticWeightedLoss\n",
    "\n",
    "\n",
    "class TFC(nn.Module):\n",
    "    def __init__(self, configs, args):\n",
    "        \n",
    "        super(TFC, self).__init__()\n",
    "        self.training_mode = 'pre_train'\n",
    "        \n",
    "        # Projecting input into deep representations\n",
    "        self.encoder_list_1 = ModuleList([Encoder(d_model=configs.d_model, d_hidden=configs.d_hidden, q=configs.q,\n",
    "                                                  v=configs.v, h=configs.h, mask=configs.mask, dropout=configs.dropout,\n",
    "                                                  device=configs.device) for _ in range(configs.N)])\n",
    "\n",
    "        self.encoder_list_2 = ModuleList([Encoder(d_model=configs.d_model, d_hidden=configs.d_hidden, q=configs.q,\n",
    "                                                  v=configs.v, h=configs.h, dropout=configs.dropout,\n",
    "                                                  device=configs.device) for _ in range(configs.N)])\n",
    "\n",
    "        self.embedding_channel = torch.nn.Linear(configs.d_channel, configs.d_model)\n",
    "        self.embedding_input = torch.nn.Linear(configs.d_input, configs.d_model)\n",
    "\n",
    "        self.gate = torch.nn.Linear(configs.d_model * configs.d_input + configs.d_model * configs.d_channel,\n",
    "                                    configs.d_output)\n",
    "\n",
    "        self.pe = configs.pe\n",
    "        self._d_input = configs.d_input\n",
    "        self._d_model = configs.d_model\n",
    "\n",
    "        # MLP Layer - To generate Projector(.); to Obtain series-wise representations\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(240128, 256),  # 240128 = encoder1 out features + encoder2 out features\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "        if self.training_mode == 'pre_train':\n",
    "            self.awl = AutomaticWeightedLoss(2)\n",
    "            self.contrastive = ContrastiveWeight(args)\n",
    "            self.aggregation = AggregationRebuild(args)\n",
    "            # self.head = nn.Linear(240128, 336)  # Reconstruction, we have 336 time steps\n",
    "            self.head = nn.Linear(240128, configs.d_input * configs.d_channel)  # Replaced to handle multi-variate\n",
    "            self.mse = torch.nn.MSELoss()\n",
    "            \n",
    "    def forward(self, stage, x_in_t, pre_train=False):\n",
    "\n",
    "        # x_in_t: (128, 336, 133)\n",
    "        encoding_1 = self.embedding_channel(x_in_t)  # (128, 336, 512)\n",
    "        input_to_gather = encoding_1 \n",
    "\n",
    "        if self.pe:\n",
    "            pe = torch.ones_like(encoding_1[0])\n",
    "            position = torch.arange(0, self._d_input).unsqueeze(-1)\n",
    "            temp = torch.Tensor(range(0, self._d_model, 2))\n",
    "            temp = temp * -(math.log(10000) / self._d_model)\n",
    "            temp = torch.exp(temp).unsqueeze(0)\n",
    "            temp = torch.matmul(position.float(), temp)  # shape:[input, d_model/2]\n",
    "            pe[:, 0::2] = torch.sin(temp)\n",
    "            pe[:, 1::2] = torch.cos(temp)\n",
    "\n",
    "            encoding_1 = encoding_1 + pe  # (128, 336, 512)\n",
    "\n",
    "        for encoder in self.encoder_list_1:\n",
    "            # encoding_1: (128, 336, 512)\n",
    "            encoding_1, score_input = encoder(encoding_1, stage)\n",
    "            \n",
    "        encoding_2 = self.embedding_input(x_in_t.transpose(-1, -2))  # encoding_2: (128, 133, 512)\n",
    "        channel_to_gather = encoding_2  \n",
    "\n",
    "        for encoder in self.encoder_list_2:\n",
    "            # encoding_2: (128, 133, 512)\n",
    "            encoding_2, score_channel = encoder(encoding_2, stage)\n",
    "\n",
    "        encoding_1 = encoding_1.reshape(encoding_1.shape[0], -1)  # (128, 172032)\n",
    "        encoding_2 = encoding_2.reshape(encoding_2.shape[0], -1)  # (128, 68096)\n",
    "        \n",
    "        encoding_concat = self.gate(torch.cat([encoding_1, encoding_2], dim=-1))  # (128, 2)\n",
    "        \n",
    "        # gate: torch.Size([128, 2])\n",
    "        gate = F.softmax(encoding_concat, dim=-1)  \n",
    "        encoding = torch.cat([encoding_1 * gate[:, 0:1], encoding_2 * gate[:, 1:2]], dim=-1)  # (128, 240128)\n",
    "        print(encoding.shape)\n",
    "        \n",
    "        # Projections\n",
    "        projections = self.dense(encoding)  # (128, 128)\n",
    "\n",
    "        if pre_train:\n",
    "            # loss_cl: torch.Size([])\n",
    "            # similarity_matrix: torch.Size([128, 128])\n",
    "            # logits: torch.Size([128, 127])\n",
    "            # positives_mask: torch.Size([128, 128])\n",
    "            loss_cl, similarity_matrix, logits, positives_mask = self.contrastive(projections)           \n",
    "            \n",
    "            # rebuild_weight_matrix: torch.Size([128, 128])\n",
    "            # agg_x: torch.Size([128, 240128])\n",
    "            rebuild_weight_matrix, agg_x = self.aggregation(similarity_matrix, encoding)\n",
    "            \n",
    "            # pred_x: torch.Size([128, 336])\n",
    "            pred_x = self.head(agg_x.reshape(agg_x.size(0), -1))\n",
    "            \n",
    "            # x_in_t.shape: torch.Size([128, 336, 133])\n",
    "            # x_in_t.reshape(x_in_t.size(0), -1): torch.Size([128, 44688])\n",
    "            loss_rb = self.mse(pred_x, x_in_t.reshape(x_in_t.size(0), -1).detach())\n",
    "            loss = self.awl(loss_cl, loss_rb)\n",
    "\n",
    "            return loss, loss_cl, loss_rb\n",
    "\n",
    "        return encoding_concat, encoding\n",
    "    "
   ],
   "id": "5df8708066259139",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.294484Z",
     "start_time": "2024-09-05T22:28:17.293017Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f16d7cef8d8db61f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.340120Z",
     "start_time": "2024-09-05T22:28:17.337046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def model_pretrain(model, model_optimizer, model_scheduler, train_loader, configs, args, device):\n",
    "    total_loss = []\n",
    "    total_cl_loss = []\n",
    "    total_rb_loss = []\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in tqdm.tqdm(enumerate(train_loader), desc=\"Pre-training model\", total=len(train_loader)):  # data shape: (batch_size, seqs, channels)\n",
    "\n",
    "        model_optimizer.zero_grad()\n",
    "        # When masking, data is reshaped to (batch_size, channel, seqs) - Inside the data_transform_masked4cl()\n",
    "        data_masked_m, mask = data_transform_masked4cl(data, args.masking_ratio, args.lm, args.positive_nums)\n",
    "        data_masked_om = torch.cat([data, data_masked_m], 0)  # (batch_size, seqs, channels)\n",
    "\n",
    "        data, labels = data.float().to('cpu'), labels.float().to('cpu')\n",
    "        data_masked_om = data_masked_om.float().to(device)\n",
    "\n",
    "        # Produce embeddings of original and masked samples  (data_masked_om = data samples + masked samples)\n",
    "        # loss, loss_cl, loss_rb = model(data_masked_om, pretrain=True)\n",
    "        # return loss, loss_cl, loss_rb\n",
    "        \n",
    "        encoding_concat, encodings = model(stage='train', x_in_t=data_masked_om, pre_train=True)\n",
    "        \n",
    "        return encoding_concat, encodings\n",
    "\n",
    "    #     loss.backward()\n",
    "    #     model_optimizer.step()\n",
    "    # \n",
    "    #     total_loss.append(loss.item())\n",
    "    #     total_cl_loss.append(loss_cl.item())\n",
    "    #     total_rb_loss.append(loss_rb.item())\n",
    "    # \n",
    "    # total_loss = torch.tensor(total_loss).mean()\n",
    "    # total_cl_loss = torch.tensor(total_cl_loss).mean()\n",
    "    # total_rb_loss = torch.tensor(total_rb_loss).mean()\n",
    "    # \n",
    "    # model_scheduler.step()\n",
    "    # \n",
    "    # return total_loss, total_cl_loss, total_rb_loss\n"
   ],
   "id": "53dd90f7b8f1d93c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.384757Z",
     "start_time": "2024-09-05T22:28:17.383121Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "70fb02e9daf22921",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:17.726964Z",
     "start_time": "2024-09-05T22:28:17.428185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sepsis_data = Load_Dataset(all_patients, TSlength_aligned=336, training_mode='pre_train')\n",
    "train_loader = torch.utils.data.DataLoader(dataset=sepsis_data, batch_size=32, shuffle=True, \n",
    "                                           drop_last=True, num_workers=4)  # (32, 336, 133)\n"
   ],
   "id": "73cf01b5a50301d5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:18.423243Z",
     "start_time": "2024-09-05T22:28:17.733772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, j in train_loader:\n",
    "    print(i.shape)\n",
    "    break"
   ],
   "id": "b3c53277fbd6e071",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 336, 40])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:18.493316Z",
     "start_time": "2024-09-05T22:28:18.491691Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "97df90518dfeaddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Args",
   "id": "66c8d4e9473a73ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:32.232826Z",
     "start_time": "2024-09-05T22:28:18.537174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from models.simmtm.model import TFC\n",
    "from models.simmtm.config import Config\n",
    "\n",
    "model = TFC(configs=Config(), args=args)\n",
    "params_group = [{'params': model.parameters()}]\n",
    "model_optimizer = torch.optim.Adam(params_group, lr=args.pretrain_lr, betas=(Config().beta1, Config().beta2),\n",
    "                                       weight_decay=0)\n",
    "model_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=model_optimizer, T_max=args.pretrain_epoch)\n",
    "encoding_concat, encodings = model_pretrain(model=model, model_optimizer=model_optimizer, model_scheduler=model_scheduler, \n",
    "               train_loader=train_loader, configs=Config(), args=args, device='cuda')\n"
   ],
   "id": "a81ae39e43d2190",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-training model:   0%|          | 0/635 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 442.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m model_optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(params_group, lr\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mpretrain_lr, betas\u001B[38;5;241m=\u001B[39m(Config()\u001B[38;5;241m.\u001B[39mbeta1, Config()\u001B[38;5;241m.\u001B[39mbeta2),\n\u001B[1;32m      7\u001B[0m                                        weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      8\u001B[0m model_scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mCosineAnnealingLR(optimizer\u001B[38;5;241m=\u001B[39mmodel_optimizer, T_max\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mpretrain_epoch)\n\u001B[0;32m----> 9\u001B[0m encoding_concat, encodings \u001B[38;5;241m=\u001B[39m model_pretrain(model\u001B[38;5;241m=\u001B[39mmodel, model_optimizer\u001B[38;5;241m=\u001B[39mmodel_optimizer, model_scheduler\u001B[38;5;241m=\u001B[39mmodel_scheduler, \n\u001B[1;32m     10\u001B[0m                train_loader\u001B[38;5;241m=\u001B[39mtrain_loader, configs\u001B[38;5;241m=\u001B[39mConfig(), args\u001B[38;5;241m=\u001B[39margs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[7], line 22\u001B[0m, in \u001B[0;36mmodel_pretrain\u001B[0;34m(model, model_optimizer, model_scheduler, train_loader, configs, args, device)\u001B[0m\n\u001B[1;32m     16\u001B[0m data_masked_om \u001B[38;5;241m=\u001B[39m data_masked_om\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Produce embeddings of original and masked samples  (data_masked_om = data samples + masked samples)\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# loss, loss_cl, loss_rb = model(data_masked_om, pretrain=True)\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# return loss, loss_cl, loss_rb\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m encoding_concat, encodings \u001B[38;5;241m=\u001B[39m model(stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, x_in_t\u001B[38;5;241m=\u001B[39mdata_masked_om, pre_train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m encoding_concat, encodings\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[6], line 74\u001B[0m, in \u001B[0;36mTFC.forward\u001B[0;34m(self, stage, x_in_t, pre_train)\u001B[0m\n\u001B[1;32m     70\u001B[0m     encoding_1 \u001B[38;5;241m=\u001B[39m encoding_1 \u001B[38;5;241m+\u001B[39m pe  \u001B[38;5;66;03m# (128, 336, 512)\u001B[39;00m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m encoder \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_list_1:\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;66;03m# encoding_1: (128, 336, 512)\u001B[39;00m\n\u001B[0;32m---> 74\u001B[0m     encoding_1, score_input \u001B[38;5;241m=\u001B[39m encoder(encoding_1, stage)\n\u001B[1;32m     76\u001B[0m encoding_2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_input(x_in_t\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m))  \u001B[38;5;66;03m# encoding_2: (128, 133, 512)\u001B[39;00m\n\u001B[1;32m     77\u001B[0m channel_to_gather \u001B[38;5;241m=\u001B[39m encoding_2  \n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/SepsisEarlyPrediction/models/simmtm/gtn/encoder.py:28\u001B[0m, in \u001B[0;36mEncoder.forward\u001B[0;34m(self, x, stage)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, stage):\n\u001B[1;32m     27\u001B[0m     residual \u001B[38;5;241m=\u001B[39m x\n\u001B[0;32m---> 28\u001B[0m     x, score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mMHA(x, stage)\n\u001B[1;32m     29\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x)\n\u001B[1;32m     30\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayerNormal_1(x \u001B[38;5;241m+\u001B[39m residual)\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/SepsisEarlyPrediction/models/gtn/multiHeadAttention.py:45\u001B[0m, in \u001B[0;36mMultiHeadAttention.forward\u001B[0;34m(self, x, stage)\u001B[0m\n\u001B[1;32m     42\u001B[0m     mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtril(mask, diagonal\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     43\u001B[0m     score \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mwhere(mask \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, score, torch\u001B[38;5;241m.\u001B[39mTensor([\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m32\u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m])\u001B[38;5;241m.\u001B[39mexpand_as(score[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice))\n\u001B[0;32m---> 45\u001B[0m score \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msoftmax(score, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     47\u001B[0m attention \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmatmul(score, V)\n\u001B[1;32m     49\u001B[0m attention_heads \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(attention\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_h, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/timeseries/lib/python3.11/site-packages/torch/nn/functional.py:1885\u001B[0m, in \u001B[0;36msoftmax\u001B[0;34m(input, dim, _stacklevel, dtype)\u001B[0m\n\u001B[1;32m   1883\u001B[0m     dim \u001B[38;5;241m=\u001B[39m _get_softmax_dim(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msoftmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim(), _stacklevel)\n\u001B[1;32m   1884\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1885\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(dim)\n\u001B[1;32m   1886\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1887\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(dim, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 442.00 MiB. GPU "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:32.295501238Z",
     "start_time": "2024-09-05T20:47:41.426244Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "56d1853d8b97d07f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:32.295914915Z",
     "start_time": "2024-09-05T20:47:41.890328Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5473a7f4ee2dfe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T22:28:32.296113248Z",
     "start_time": "2024-09-05T20:47:42.111033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# loss, loss_cl, loss_rb = model_pretrain(model=model, model_optimizer=model_optimizer, model_scheduler=model_scheduler, \n",
    "#                train_loader=train_loader, configs=Config(), args=args, device='cuda')"
   ],
   "id": "e2429f29eee36116",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e0189c3349a0f99b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
